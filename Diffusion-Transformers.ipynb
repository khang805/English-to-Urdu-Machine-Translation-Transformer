{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "yoEpF6ouQ4mB",
        "outputId": "aff44583-d75e-4ab9-e6b1-b9380c5301b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-fidelity\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (11.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (1.16.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (0.24.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-fidelity) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->torch-fidelity) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torch-fidelity) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torch-fidelity) (3.0.3)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: torch-fidelity\n",
            "Successfully installed torch-fidelity-0.3.0\n",
            "Device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 45.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10000 images (['cat', 'dog'])\n",
            "Training REG SiT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 1: 100%|██████████| 39/39 [00:05<00:00,  6.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 Avg Loss: 0.2745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2: 100%|██████████| 39/39 [00:04<00:00,  9.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 Avg Loss: -0.1602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3: 100%|██████████| 39/39 [00:04<00:00,  8.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 Avg Loss: -0.2522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4: 100%|██████████| 39/39 [00:04<00:00,  9.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 Avg Loss: -0.3036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5: 100%|██████████| 39/39 [00:04<00:00,  9.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 Avg Loss: -0.3338\n",
            "Training U-Net...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1: 100%|██████████| 39/39 [00:03<00:00, 11.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 Avg Loss: 0.9115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2: 100%|██████████| 39/39 [00:02<00:00, 14.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 Avg Loss: 0.6266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3: 100%|██████████| 39/39 [00:02<00:00, 15.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 Avg Loss: 0.4258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4: 100%|██████████| 39/39 [00:02<00:00, 15.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 Avg Loss: 0.3631\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5: 100%|██████████| 39/39 [00:03<00:00, 10.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 Avg Loss: 0.3222\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating Models on 1000 samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n",
            "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
            "100%|██████████| 91.2M/91.2M [00:00<00:00, 117MB/s]\n",
            "Extracting statistics from input 1\n",
            "Looking for samples non-recursivelty in \"./outputs_sit_reg_fixed/reg_eval_1000\" with extensions png,jpg,jpeg\n",
            "Found 1000 samples\n",
            "/usr/local/lib/python3.12/dist-packages/torch_fidelity/datasets.py:16: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes())).view(height, width, 3)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Processing samples\n",
            "Extracting statistics from input 2\n",
            "Looking for samples non-recursivelty in \"./outputs_sit_reg_fixed/real_images_1000\" with extensions png,jpg,jpeg\n",
            "Found 1000 samples\n",
            "Processing samples\n",
            "/usr/local/lib/python3.12/dist-packages/torch_fidelity/metric_fid.py:47: LinAlgWarning: Matrix is singular. The result might be inaccurate or the array might not have a square root.\n",
            "  covmean, _ = scipy.linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Evaluation Metrics: {'frechet_inception_distance': 514.3218825855131}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Frechet Inception Distance: 514.3218825855131\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Representational Alignment (Cosine Sim): 0.7913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n",
            "Extracting statistics from input 1\n",
            "Looking for samples non-recursivelty in \"./outputs_sit_reg_fixed/unet_eval_1000\" with extensions png,jpg,jpeg\n",
            "Found 1000 samples\n",
            "Processing samples\n",
            "Extracting statistics from input 2\n",
            "Looking for samples non-recursivelty in \"./outputs_sit_reg_fixed/real_images_1000\" with extensions png,jpg,jpeg\n",
            "Found 1000 samples\n",
            "Processing samples\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNET Evaluation Metrics: {'frechet_inception_distance': 505.51205294597327}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Frechet Inception Distance: 505.51205294597327\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNET Representational Alignment (Cosine Sim): 0.7881\n",
            "Evaluation complete. Results: {'reg': {'frechet_inception_distance': 514.3218825855131, 'representational_alignment': 0.7913216948509216}, 'unet': {'frechet_inception_distance': 505.51205294597327, 'representational_alignment': 0.7880967259407043}}\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# SiT + REG + U-Net Diffusion Implementation + 1000-Sample Evaluation\n",
        "# ============================\n",
        "!pip install torch-fidelity --upgrade\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Imports\n",
        "# -------------------------\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG\n",
        "# -------------------------\n",
        "class Config:\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 32\n",
        "    batch_size = 256\n",
        "    num_workers = 2\n",
        "\n",
        "    latent_hw = 16\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2  # 64\n",
        "\n",
        "    depth = 6\n",
        "    hidden_dim = 128\n",
        "    num_heads = 4\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.0\n",
        "\n",
        "    timesteps = 250\n",
        "    lr = 2e-4\n",
        "    weight_decay = 0.0\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 5\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params\n",
        "    reg_lambda = 0.5\n",
        "    beta = 0.03\n",
        "    feat_dim = 64\n",
        "    align_layer = 3\n",
        "\n",
        "    sample_n = 1000  # <-- increase for evaluation\n",
        "    out_dir = \"./outputs_sit_reg_fixed\"\n",
        "\n",
        "cfg = Config()\n",
        "torch.manual_seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# Noise Scheduler\n",
        "# -------------------------\n",
        "class NoiseScheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        self.betas = torch.linspace(1e-4, 0.02, timesteps).to(device)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "\n",
        "    def sample_t(self, batch_size):\n",
        "        return torch.randint(0, self.timesteps, (batch_size,), device=self.device, dtype=torch.long)\n",
        "\n",
        "    def add_noise(self, x0, t_int, noise=None):\n",
        "        B = x0.size(0)\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a = self.alpha_cumprod[t_int].view(B,1,1,1).sqrt()\n",
        "        one_minus_a = (1.0 - self.alpha_cumprod[t_int]).view(B,1,1,1).sqrt()\n",
        "        x_t = a * x0 + one_minus_a * noise\n",
        "        return x_t, noise\n",
        "\n",
        "    def get_v_target(self, x0, epsilon):\n",
        "        return epsilon\n",
        "\n",
        "scheduler = NoiseScheduler(cfg.timesteps, device)\n",
        "\n",
        "# -------------------------\n",
        "# CIFAR-10 subset\n",
        "# -------------------------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    class_to_idx = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {class_to_idx[c] for c in classes}\n",
        "    transform = T.Compose([\n",
        "        T.Resize((cfg.image_size,cfg.image_size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=transform)\n",
        "    indices = [i for i,(x,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# -------------------------\n",
        "# Simple VAE\n",
        "# -------------------------\n",
        "class SimpleVAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,2,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,128,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(128,latent_channels,3,1,1)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels,128,3,1,1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128,64,4,2,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,64,3,1,1), nn.ReLU(),\n",
        "            nn.Conv2d(64,3,3,1,1), nn.Tanh()\n",
        "        )\n",
        "    def encode(self,x):\n",
        "        return self.encoder(x)\n",
        "    def decode(self,z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "vae = SimpleVAE(cfg.latent_channels).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Sinusoidal embeddings\n",
        "# -------------------------\n",
        "def get_sinusoidal_timestep_embedding(t, dim):\n",
        "    t = t.float()\n",
        "    half = dim//2\n",
        "    freqs = torch.exp(-math.log(10000)*torch.arange(half, device=t.device)/(half-1))\n",
        "    args = t[:,None]*freqs[None,:]\n",
        "    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=-1)\n",
        "    if dim%2==1:\n",
        "        emb = F.pad(emb,(0,1),value=0.0)\n",
        "    return emb\n",
        "\n",
        "# -------------------------\n",
        "# Transformer blocks\n",
        "# -------------------------\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=cfg.num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = (dim//heads)**-0.5\n",
        "        self.to_qkv = nn.Linear(dim, dim*3, bias=False)\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "    def forward(self,x):\n",
        "        B,N,C = x.shape\n",
        "        qkv = self.to_qkv(x).reshape(B,N,3,self.heads,C//self.heads).permute(2,0,3,1,4)\n",
        "        q,k,v = qkv[0],qkv[1],qkv[2]\n",
        "        attn = (q@k.transpose(-2,-1))*self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out = (attn@v).transpose(1,2).reshape(B,N,C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = MultiHeadAttention(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        mlp_dim = int(dim*cfg.mlp_ratio)\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim,mlp_dim), nn.GELU(), nn.Linear(mlp_dim,dim))\n",
        "    def forward(self,x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# -------------------------\n",
        "# REG SiT\n",
        "# -------------------------\n",
        "class REGSiT(nn.Module):\n",
        "    def __init__(self, latent_patch_dim, feat_dim, hidden_dim, depth, num_patches, num_heads, mlp_ratio):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_patches = num_patches\n",
        "        self.latent_patch_dim = latent_patch_dim\n",
        "        self.feat_dim = feat_dim\n",
        "        self.cls_proj = nn.Linear(feat_dim, hidden_dim)\n",
        "        self.patch_proj = nn.Linear(latent_patch_dim, hidden_dim)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1,1+num_patches,hidden_dim))\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(hidden_dim) for _ in range(depth)])\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.patch_out = nn.Linear(hidden_dim, latent_patch_dim)\n",
        "        self.cls_out = nn.Linear(hidden_dim, feat_dim)\n",
        "        self.align_proj = nn.Linear(hidden_dim, feat_dim)\n",
        "        self.align_layer = cfg.align_layer\n",
        "\n",
        "    def forward(self, z_patched, cls_token, t_norm):\n",
        "        B = z_patched.shape[0]\n",
        "        cls_emb = self.cls_proj(cls_token).unsqueeze(1)\n",
        "        patch_emb = self.patch_proj(z_patched)\n",
        "        x = torch.cat([cls_emb, patch_emb], dim=1)\n",
        "        time_emb = get_sinusoidal_timestep_embedding(t_norm, self.hidden_dim).unsqueeze(1)\n",
        "        x = x + time_emb + self.pos_embed\n",
        "        h_n = None\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if i==self.align_layer:\n",
        "                h_n = x\n",
        "        x = self.norm(x)\n",
        "        cls_pred = self.cls_out(x[:,0])\n",
        "        patch_pred = self.patch_out(x[:,1:])\n",
        "        h_phi = self.align_proj(h_n) if h_n is not None else None\n",
        "        return patch_pred, cls_pred, h_phi\n",
        "\n",
        "reg_sit = REGSiT(cfg.latent_patch_dim, cfg.feat_dim, cfg.hidden_dim, cfg.depth, cfg.num_patches,\n",
        "                 cfg.num_heads, cfg.mlp_ratio).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Vision Foundation\n",
        "# -------------------------\n",
        "class VisionFoundation(nn.Module):\n",
        "    def __init__(self, feat_dim=cfg.feat_dim):\n",
        "        super().__init__()\n",
        "        self.feat_dim = feat_dim\n",
        "        self.patch_conv = nn.Conv2d(3, feat_dim, kernel_size=4, stride=4)\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1,1,feat_dim))\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        f = self.patch_conv(x).flatten(2).transpose(1,2)\n",
        "        cls = self.cls_token.expand(B,-1,-1)+f.mean(dim=1,keepdim=True)\n",
        "        return cls.squeeze(1), f\n",
        "\n",
        "vision = VisionFoundation(cfg.feat_dim).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# REG Model Wrapper\n",
        "# -------------------------\n",
        "class REGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "\n",
        "    def forward(self, imgs, t_int):\n",
        "        B = imgs.shape[0]\n",
        "        z_star = self.vae.encode(imgs)\n",
        "        cls_star, f_star = self.vision.extract(imgs)\n",
        "        epsilon_z = torch.randn_like(z_star)\n",
        "        epsilon_cls = torch.randn_like(cls_star)\n",
        "        zt,_ = scheduler.add_noise(z_star, t_int, noise=epsilon_z)\n",
        "        t_norm = t_int.float()/(scheduler.timesteps-1)\n",
        "        clst = (1.0-t_norm)[:,None]*cls_star + t_norm[:,None]*epsilon_cls\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size,q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t_norm)\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size,q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        v_target_z = scheduler.get_v_target(z_star, epsilon_z)\n",
        "        v_target_cls = scheduler.get_v_target(cls_star, epsilon_cls)\n",
        "        y_star = torch.cat([cls_star.unsqueeze(1), f_star], dim=1)\n",
        "        cos_sim = F.cosine_similarity(y_star.reshape(-1,cfg.feat_dim),\n",
        "                                      h_phi.reshape(-1,cfg.feat_dim), dim=-1).mean() if h_phi is not None else torch.tensor(0.0, device=imgs.device)\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.beta * F.mse_loss(v_cls, v_target_cls)\n",
        "        loss_align = -cos_sim\n",
        "        total_loss = loss_pred + cfg.reg_lambda*loss_align\n",
        "        return total_loss\n",
        "\n",
        "reg_model = REGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Simple U-Net\n",
        "# -------------------------\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self, in_channels=cfg.latent_channels, time_dim=128):\n",
        "        super().__init__()\n",
        "        self.time_dim = time_dim\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(time_dim, time_dim), nn.SiLU())\n",
        "        # project time embedding to match channels for each layer\n",
        "        self.time_d1 = nn.Linear(time_dim, 32)\n",
        "        self.time_d2 = nn.Linear(time_dim, 64)\n",
        "        self.time_mid = nn.Linear(time_dim, 64)\n",
        "        self.time_u1 = nn.Linear(time_dim, 32)\n",
        "\n",
        "        self.down1 = nn.Conv2d(in_channels,32,3,1,1)\n",
        "        self.down2 = nn.Conv2d(32,64,3,2,1)\n",
        "        self.mid = nn.Conv2d(64,64,3,1,1)\n",
        "        self.up1 = nn.ConvTranspose2d(64,32,4,2,1)\n",
        "        self.out = nn.Conv2d(32,in_channels,3,1,1)\n",
        "\n",
        "    def forward(self, x, t_norm):\n",
        "        B = x.shape[0]\n",
        "        time_emb = get_sinusoidal_timestep_embedding(t_norm, self.time_dim)\n",
        "        time_emb = self.time_mlp(time_emb)  # (B, time_dim)\n",
        "\n",
        "        d1 = F.silu(self.down1(x) + self.time_d1(time_emb).view(B,32,1,1))\n",
        "        d2 = F.silu(self.down2(d1) + self.time_d2(time_emb).view(B,64,1,1))\n",
        "        m  = F.silu(self.mid(d2) + self.time_mid(time_emb).view(B,64,1,1))\n",
        "        u1 = F.silu(self.up1(m+d2) + self.time_u1(time_emb).view(B,32,1,1))\n",
        "        out = self.out(u1 + d1)\n",
        "        return out\n",
        "\n",
        "\n",
        "unet = SimpleUNet().to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Optimizers\n",
        "# -------------------------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "\n",
        "# -------------------------\n",
        "# Training Loops\n",
        "# -------------------------\n",
        "reg_loss_history, unet_loss_history = [], []\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for imgs,_ in tqdm(dataloader, desc=f\"REG Epoch {epoch+1}\"):\n",
        "            imgs = imgs.to(device)\n",
        "            t_int = scheduler.sample_t(imgs.shape[0])\n",
        "            loss = reg_model(imgs, t_int)\n",
        "            opt_reg.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            opt_reg.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss/len(dataloader)\n",
        "        reg_loss_history.append(avg_loss)\n",
        "        print(f\"REG Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for imgs,_ in tqdm(dataloader, desc=f\"UNet Epoch {epoch+1}\"):\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            t_int = scheduler.sample_t(B)\n",
        "            z_star = vae.encode(imgs)\n",
        "            epsilon_z = torch.randn_like(z_star)\n",
        "            zt,_ = scheduler.add_noise(z_star, t_int, noise=epsilon_z)\n",
        "            t_norm = t_int.float()/(scheduler.timesteps-1)\n",
        "            v_pred = unet(zt, t_norm)\n",
        "            loss = F.mse_loss(v_pred, epsilon_z)\n",
        "            opt_unet.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            opt_unet.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss/len(dataloader)\n",
        "        unet_loss_history.append(avg_loss)\n",
        "        print(f\"UNet Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Sampling functions with batching\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def sample_in_batches(sample_fn, num_samples, batch_size=64):\n",
        "    imgs_list = []\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        b = min(batch_size, num_samples - i)\n",
        "        imgs_list.append(sample_fn(b))\n",
        "    return torch.cat(imgs_list, dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unet(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "    dt = -1.0/cfg.timesteps\n",
        "    for step in range(cfg.timesteps):\n",
        "        t_norm = torch.full((B,), float(1.0+step*dt), device=device).clamp(0,1)\n",
        "        v_z = unet(z, t_norm)\n",
        "        z = z + v_z*dt\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs+1)/2,0,1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "    cls_prior = torch.randn(B, cfg.feat_dim, device=device)\n",
        "    dt = -1.0/cfg.timesteps\n",
        "    for step in range(cfg.timesteps):\n",
        "        t_norm = torch.full((B,), float(1.0+step*dt), device=device).clamp(0,1)\n",
        "        z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size,q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        v_patch, v_cls, _ = reg_sit(z_patched, cls_prior, t_norm)\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size,q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        z = z + v_z*dt\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs+1)/2,0,1)\n",
        "\n",
        "def save_grid(imgs, path, nrow=8):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow)\n",
        "\n",
        "# -------------------------\n",
        "# Loss Curves\n",
        "# -------------------------\n",
        "def plot_loss_curves():\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.plot(reg_loss_history, label='REG Loss')\n",
        "    plt.plot(unet_loss_history, label='UNet Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(cfg.out_dir, \"loss_curves.png\"))\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation (1000 samples, batched)\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate_models(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "    # Prepare real images folder\n",
        "    real_path = os.path.join(cfg.out_dir, f\"real_images_{num_samples}\")\n",
        "    if os.path.exists(real_path):\n",
        "        shutil.rmtree(real_path)\n",
        "    os.makedirs(real_path, exist_ok=True)\n",
        "\n",
        "    # Save real images\n",
        "    cnt = 0\n",
        "    for imgs,_ in dataloader:\n",
        "        for img in imgs:\n",
        "            torchvision.utils.save_image((img+1)/2, os.path.join(real_path,f\"{cnt}.png\"))\n",
        "            cnt+=1\n",
        "            if cnt>=num_samples:\n",
        "                break\n",
        "        if cnt>=num_samples:\n",
        "            break\n",
        "\n",
        "    for model_type in ['reg','unet']:\n",
        "        # Generate images\n",
        "        if model_type=='reg':\n",
        "            imgs = sample_in_batches(sample_reg, num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir,'reg_samples.png'))\n",
        "        else:\n",
        "            imgs = sample_in_batches(sample_unet, num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir,'unet_samples.png'))\n",
        "\n",
        "        # Save generated images to folder\n",
        "        gen_path = os.path.join(cfg.out_dir, f\"{model_type}_eval_{num_samples}\")\n",
        "        if os.path.exists(gen_path):\n",
        "            shutil.rmtree(gen_path)\n",
        "        os.makedirs(gen_path, exist_ok=True)\n",
        "        for i,img in enumerate(imgs):\n",
        "            torchvision.utils.save_image(img, os.path.join(gen_path,f\"{i}.png\"))\n",
        "\n",
        "        # FID and IS metrics\n",
        "        metrics = calculate_metrics(\n",
        "        input1=gen_path,\n",
        "        input2=real_path,\n",
        "        cuda=torch.cuda.is_available(),\n",
        "        is_score=True,   # use is_score instead of isc\n",
        "        fid=True,\n",
        "        kid=False\n",
        "        )\n",
        "\n",
        "        results[model_type] = metrics\n",
        "        print(f\"{model_type.upper()} Evaluation Metrics: {metrics}\")\n",
        "\n",
        "        # Representational alignment\n",
        "        cls_gen, f_gen = vision.extract(imgs.to(device))\n",
        "        cls_real_list, f_real_list = [], []\n",
        "        got = 0\n",
        "        for real_imgs,_ in dataloader:\n",
        "            cls_r, f_r = vision.extract(real_imgs.to(device))\n",
        "            cls_real_list.append(cls_r)\n",
        "            f_real_list.append(f_r)\n",
        "            got += real_imgs.shape[0]\n",
        "            if got>=num_samples:\n",
        "                break\n",
        "        cls_real = torch.cat(cls_real_list, dim=0)[:num_samples]\n",
        "        f_real = torch.cat(f_real_list, dim=0)[:num_samples]\n",
        "        y_real = torch.cat([cls_real.unsqueeze(1), f_real], dim=1)\n",
        "        y_gen = torch.cat([cls_gen.unsqueeze(1), f_gen], dim=1)\n",
        "        cos_sim = F.cosine_similarity(y_real.reshape(num_samples,-1),\n",
        "                                      y_gen.reshape(num_samples,-1), dim=-1).mean()\n",
        "        print(f\"{model_type.upper()} Representational Alignment (Cosine Sim): {cos_sim.item():.4f}\")\n",
        "        results[model_type]['representational_alignment'] = cos_sim.item()\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# Run Training + Evaluation\n",
        "# -------------------------\n",
        "if __name__==\"__main__\":\n",
        "    print(\"Training REG SiT...\")\n",
        "    train_reg(cfg.epochs)\n",
        "    print(\"Training U-Net...\")\n",
        "    train_unet(cfg.epochs)\n",
        "    plot_loss_curves()\n",
        "\n",
        "    print(f\"Evaluating Models on {cfg.sample_n} samples...\")\n",
        "    metrics_results = evaluate_models(cfg.sample_n)\n",
        "    print(\"Evaluation complete. Results:\", metrics_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00Bzs5RC-Eyl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "EM4n4Yjf9IlE",
        "outputId": "a863ca9c-310c-4c98-c76b-6426136a7a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Number of patches: 16\n",
            "Loaded 10000 images (['cat', 'dog'])\n",
            "VAE initialized\n",
            "SiT+REG Model initialized with 3,366,672 parameters\n",
            "U-Net Model initialized with 390,276 parameters\n",
            "============================================================\n",
            "Starting Training...\n",
            "============================================================\n",
            "Training SiT + REG Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 1/5: 100%|██████████| 78/78 [00:04<00:00, 19.33it/s, loss=-0.4096]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 Avg Loss: -0.0639\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2/5: 100%|██████████| 78/78 [00:04<00:00, 15.79it/s, loss=-0.4185]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 Avg Loss: -0.4091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3/5: 100%|██████████| 78/78 [00:04<00:00, 19.49it/s, loss=-0.4357]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 Avg Loss: -0.4247\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4/5: 100%|██████████| 78/78 [00:04<00:00, 19.36it/s, loss=-0.4313]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 Avg Loss: -0.4287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5/5: 100%|██████████| 78/78 [00:04<00:00, 15.82it/s, loss=-0.4367]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 Avg Loss: -0.4326\n",
            "\n",
            "Training U-Net Baseline...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1/5: 100%|██████████| 78/78 [00:02<00:00, 26.23it/s, loss=0.7855]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 Avg Loss: 0.9051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2/5: 100%|██████████| 78/78 [00:03<00:00, 25.84it/s, loss=0.4892]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 Avg Loss: 0.6206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3/5: 100%|██████████| 78/78 [00:03<00:00, 24.82it/s, loss=0.3407]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 Avg Loss: 0.3859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4/5: 100%|██████████| 78/78 [00:03<00:00, 20.37it/s, loss=0.3467]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 Avg Loss: 0.3222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5/5: 100%|██████████| 78/78 [00:02<00:00, 26.88it/s, loss=0.3179]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 Avg Loss: 0.3005\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Evaluating on 500 samples...\n",
            "============================================================\n",
            "Generating samples for REG...\n",
            "Calculating metrics for REG...\n",
            "REG Metrics: {'inception_score_mean': 1.0005647683485557, 'inception_score_std': 4.65436743534939e-05, 'frechet_inception_distance': 525.2467047576165}\n",
            "Generating samples for UNET...\n",
            "Calculating metrics for UNET...\n",
            "UNET Metrics: {'inception_score_mean': 1.0043436448972365, 'inception_score_std': 0.0004721278316313892, 'frechet_inception_distance': 522.0237534822932}\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS:\n",
            "============================================================\n",
            "REG        | FID:   525.25 | IS:   1.00\n",
            "UNET       | FID:   522.02 | IS:   1.00\n",
            "============================================================\n",
            "Training and evaluation complete!\n",
            "Results saved to: ./outputs_sit_reg_colab\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# SiT + REG + U-Net Diffusion Implementation (Colab Compatible)\n",
        "# ============================\n",
        "!pip install torch-fidelity --upgrade -q\n",
        "!pip install einops -q\n",
        "\n",
        "# -------------------------\n",
        "# Imports\n",
        "# -------------------------\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG (Optimized for Colab)\n",
        "# -------------------------\n",
        "class Config:\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 32\n",
        "    batch_size = 128  # Reduced for Colab memory\n",
        "    num_workers = 2\n",
        "\n",
        "    # Latent space config (fixed dimensions)\n",
        "    latent_hw = 8  # 32x32 -> 8x8 after VAE\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2  # 16 patches for 8x8 with patch_size=2\n",
        "\n",
        "    # SiT architecture (optimized for Colab)\n",
        "    depth = 4  # Reduced depth\n",
        "    hidden_dim = 256\n",
        "    num_heads = 8\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.0\n",
        "\n",
        "    # Training\n",
        "    timesteps = 100  # Reduced for faster training\n",
        "    lr = 1e-4\n",
        "    weight_decay = 0.0\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 5  # Reduced epochs for demo\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params\n",
        "    reg_lambda = 0.5\n",
        "    beta = 0.03\n",
        "    feat_dim = 256  # Matches hidden_dim\n",
        "    align_layer = 1  # Early layer for alignment\n",
        "\n",
        "    sample_n = 500  # Reduced for faster evaluation\n",
        "    out_dir = \"./outputs_sit_reg_colab\"\n",
        "\n",
        "cfg = Config()\n",
        "torch.manual_seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "print(f\"Number of patches: {cfg.num_patches}\")\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# Noise Scheduler\n",
        "# -------------------------\n",
        "class NoiseScheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        self.betas = torch.linspace(1e-4, 0.02, timesteps).to(device)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alpha_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alpha_cumprod)\n",
        "\n",
        "    def sample_t(self, batch_size):\n",
        "        return torch.randint(0, self.timesteps, (batch_size,), device=self.device, dtype=torch.long)\n",
        "\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        sqrt_alpha = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "        sqrt_one_minus_alpha = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "        return sqrt_alpha * x0 + sqrt_one_minus_alpha * noise, noise\n",
        "\n",
        "    def get_velocity_target(self, x0, epsilon):\n",
        "        return epsilon\n",
        "\n",
        "scheduler = NoiseScheduler(cfg.timesteps, device)\n",
        "\n",
        "# -------------------------\n",
        "# CIFAR-10 subset\n",
        "# -------------------------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    class_to_idx = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {class_to_idx[c] for c in classes}\n",
        "    transform = T.Compose([\n",
        "        T.Resize((cfg.image_size, cfg.image_size)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=transform)\n",
        "    indices = [i for i,(x,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True,\n",
        "                       num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# -------------------------\n",
        "# Simple VAE (Fixed dimensions)\n",
        "# -------------------------\n",
        "class SimpleVAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "        # Encoder: 32x32 -> 8x8\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, 2, 1), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(), # 16->8\n",
        "            nn.Conv2d(128, latent_channels, 3, 1, 1)\n",
        "        )\n",
        "\n",
        "        # Decoder: 8x8 -> 32x32\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels, 128, 3, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),  # 8->16\n",
        "            nn.ConvTranspose2d(64, 64, 4, 2, 1), nn.ReLU(),   # 16->32\n",
        "            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "vae = SimpleVAE().to(device)\n",
        "print(\"VAE initialized\")\n",
        "\n",
        "# -------------------------\n",
        "# Sinusoidal embeddings\n",
        "# -------------------------\n",
        "def get_timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(\n",
        "        -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
        "    ).to(device=timesteps.device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2:\n",
        "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "    return embedding\n",
        "\n",
        "# -------------------------\n",
        "# Transformer blocks\n",
        "# -------------------------\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=cfg.num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = (dim // heads) ** -0.5\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.to_qkv(x).reshape(B, N, 3, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = MultiHeadAttention(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        mlp_dim = int(dim * cfg.mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# -------------------------\n",
        "# REG SiT (Fixed dimensions)\n",
        "# -------------------------\n",
        "class REGSiT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = cfg.hidden_dim\n",
        "        self.num_patches = cfg.num_patches\n",
        "\n",
        "        # Patch embedding\n",
        "        self.patch_embed = nn.Linear(cfg.latent_patch_dim, cfg.hidden_dim)\n",
        "\n",
        "        # Class token embedding (REG component)\n",
        "        self.class_embed = nn.Linear(cfg.feat_dim, cfg.hidden_dim)\n",
        "\n",
        "        # Position embeddings (FIXED: +1 for class token)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.num_patches + 1, cfg.hidden_dim))\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(cfg.hidden_dim) for _ in range(cfg.depth)\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(cfg.hidden_dim)\n",
        "\n",
        "        # Output projections\n",
        "        self.patch_out = nn.Linear(cfg.hidden_dim, cfg.latent_patch_dim)\n",
        "        self.cls_out = nn.Linear(cfg.hidden_dim, cfg.feat_dim)\n",
        "\n",
        "        # Alignment projection\n",
        "        self.align_proj = nn.Linear(cfg.hidden_dim, cfg.feat_dim)\n",
        "\n",
        "    def forward(self, z_patched, cls_token, t_norm):\n",
        "        B = z_patched.shape[0]\n",
        "\n",
        "        # Embed patches and class token\n",
        "        patch_emb = self.patch_embed(z_patched)\n",
        "        cls_emb = self.class_embed(cls_token).unsqueeze(1)\n",
        "\n",
        "        # Concatenate class token with patches\n",
        "        x = torch.cat([cls_emb, patch_emb], dim=1)\n",
        "\n",
        "        # Add position embeddings\n",
        "        x = x + self.pos_embed\n",
        "\n",
        "        # Add timestep embedding\n",
        "        time_emb = get_timestep_embedding(t_norm, self.hidden_dim).unsqueeze(1)\n",
        "        x = x + time_emb\n",
        "\n",
        "        # Transformer blocks\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if i == cfg.align_layer:\n",
        "                h_n = x  # Store for alignment\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        # Separate outputs\n",
        "        cls_pred = self.cls_out(x[:, 0])\n",
        "        patch_pred = self.patch_out(x[:, 1:])\n",
        "\n",
        "        # Alignment features\n",
        "        h_phi = self.align_proj(h_n) if 'h_n' in locals() else None\n",
        "\n",
        "        return patch_pred, cls_pred, h_phi\n",
        "\n",
        "reg_sit = REGSiT().to(device)\n",
        "print(f\"SiT+REG Model initialized with {sum(p.numel() for p in reg_sit.parameters()):,} parameters\")\n",
        "\n",
        "# -------------------------\n",
        "# Vision Foundation\n",
        "# -------------------------\n",
        "class VisionFoundation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Simple CNN for feature extraction\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.ReLU(), # 16->8\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.proj = nn.Linear(128, cfg.feat_dim)\n",
        "\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        features = self.backbone(x).view(B, -1)\n",
        "        features = self.proj(features)\n",
        "\n",
        "        # For simplicity, use same features for cls and patches\n",
        "        cls_token = features\n",
        "        patch_features = features.unsqueeze(1).repeat(1, cfg.num_patches, 1)\n",
        "\n",
        "        return cls_token, patch_features\n",
        "\n",
        "vision = VisionFoundation().to(device)\n",
        "\n",
        "# -------------------------\n",
        "# REG Model Wrapper\n",
        "# -------------------------\n",
        "class REGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "\n",
        "    def forward(self, imgs, t_int):\n",
        "        B = imgs.shape[0]\n",
        "\n",
        "        # Encode to latent space\n",
        "        z_star = self.vae.encode(imgs)\n",
        "\n",
        "        # Extract vision features\n",
        "        cls_star, f_star = self.vision.extract(imgs)\n",
        "\n",
        "        # Sample noise\n",
        "        epsilon_z = torch.randn_like(z_star)\n",
        "        epsilon_cls = torch.randn_like(cls_star)\n",
        "\n",
        "        # Add noise to both latents and class token\n",
        "        zt, _ = scheduler.add_noise(z_star, t_int, noise=epsilon_z)\n",
        "\n",
        "        # Add noise to class token\n",
        "        t_norm = t_int.float() / scheduler.timesteps\n",
        "        sqrt_alpha = scheduler.sqrt_alphas_cumprod[t_int].view(B, 1)\n",
        "        sqrt_one_minus_alpha = scheduler.sqrt_one_minus_alphas_cumprod[t_int].view(B, 1)\n",
        "        clst = sqrt_alpha * cls_star + sqrt_one_minus_alpha * epsilon_cls\n",
        "\n",
        "        # Prepare patches\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "\n",
        "        # Forward through SiT\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t_int)\n",
        "\n",
        "        # Convert patches back\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "\n",
        "        # Velocity targets\n",
        "        v_target_z = scheduler.get_velocity_target(z_star, epsilon_z)\n",
        "        v_target_cls = scheduler.get_velocity_target(cls_star, epsilon_cls)\n",
        "\n",
        "        # Prediction loss\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.beta * F.mse_loss(v_cls, v_target_cls)\n",
        "\n",
        "        # Alignment loss\n",
        "        loss_align = 0.0\n",
        "        if h_phi is not None:\n",
        "            y_star = torch.cat([cls_star.unsqueeze(1), f_star], dim=1)\n",
        "            cos_sim = F.cosine_similarity(\n",
        "                y_star.reshape(-1, cfg.feat_dim),\n",
        "                h_phi.reshape(-1, cfg.feat_dim),\n",
        "                dim=-1\n",
        "            ).mean()\n",
        "            loss_align = -cos_sim\n",
        "\n",
        "        total_loss = loss_pred + cfg.reg_lambda * loss_align\n",
        "        return total_loss\n",
        "\n",
        "reg_model = REGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Simple U-Net\n",
        "# -------------------------\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.time_dim = 128\n",
        "\n",
        "        self.enc1 = nn.Conv2d(cfg.latent_channels, 64, 3, 1, 1)\n",
        "        self.enc2 = nn.Conv2d(64, 128, 3, 2, 1)\n",
        "        self.mid = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.dec1 = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
        "        self.out = nn.Conv2d(64, cfg.latent_channels, 3, 1, 1)\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(self.time_dim, self.time_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(self.time_dim, self.time_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # Time embedding\n",
        "        t_embed = get_timestep_embedding(t, self.time_dim)\n",
        "        t_embed = self.time_embed(t_embed)\n",
        "\n",
        "        # Encoder\n",
        "        x1 = F.silu(self.enc1(x))\n",
        "        x2 = F.silu(self.enc2(x1))\n",
        "\n",
        "        # Middle\n",
        "        m = F.silu(self.mid(x2))\n",
        "\n",
        "        # Decoder\n",
        "        d1 = F.silu(self.dec1(m + x2))\n",
        "        out = self.out(d1 + x1)\n",
        "\n",
        "        return out\n",
        "\n",
        "unet = SimpleUNet().to(device)\n",
        "print(f\"U-Net Model initialized with {sum(p.numel() for p in unet.parameters()):,} parameters\")\n",
        "\n",
        "# -------------------------\n",
        "# Optimizers\n",
        "# -------------------------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr,\n",
        "                           weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr,\n",
        "                            weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "\n",
        "# -------------------------\n",
        "# Training Loops\n",
        "# -------------------------\n",
        "reg_loss_history, unet_loss_history = [], []\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"REG Epoch {epoch+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            t_int = scheduler.sample_t(imgs.shape[0])\n",
        "\n",
        "            loss = reg_model(imgs, t_int)\n",
        "\n",
        "            opt_reg.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            opt_reg.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        reg_loss_history.append(avg_loss)\n",
        "        print(f\"REG Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"UNet Epoch {epoch+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "\n",
        "            z_star = vae.encode(imgs)\n",
        "            t_int = scheduler.sample_t(B)\n",
        "            epsilon_z = torch.randn_like(z_star)\n",
        "            zt, _ = scheduler.add_noise(z_star, t_int, noise=epsilon_z)\n",
        "\n",
        "            v_pred = unet(zt, t_int)\n",
        "            loss = F.mse_loss(v_pred, epsilon_z)\n",
        "\n",
        "            opt_unet.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            opt_unet.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        unet_loss_history.append(avg_loss)\n",
        "        print(f\"UNet Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# Sampling functions\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def sample_in_batches(sample_fn, num_samples, batch_size=32):\n",
        "    imgs_list = []\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        b = min(batch_size, num_samples - i)\n",
        "        imgs_list.append(sample_fn(b))\n",
        "    return torch.cat(imgs_list, dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unet(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "\n",
        "    # Simple reverse sampling\n",
        "    for i in range(cfg.timesteps-1, -1, -1):\n",
        "        t = torch.full((B,), i, device=device, dtype=torch.long)\n",
        "        v_pred = unet(z, t)\n",
        "\n",
        "        # Simple Euler step\n",
        "        if i > 0:\n",
        "            dt = -1.0 / cfg.timesteps\n",
        "            z = z + v_pred * dt\n",
        "\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs + 1) / 2, 0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "    cls_prior = torch.randn(B, cfg.feat_dim, device=device)\n",
        "\n",
        "    # Simple reverse sampling for SiT+REG\n",
        "    for i in range(cfg.timesteps-1, -1, -1):\n",
        "        t = torch.full((B,), i, device=device, dtype=torch.long)\n",
        "\n",
        "        # Prepare patches\n",
        "        z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "\n",
        "        # Predict velocity\n",
        "        v_patch, v_cls, _ = reg_sit(z_patched, cls_prior, t)\n",
        "\n",
        "        # Convert back\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "\n",
        "        # Update\n",
        "        dt = -1.0 / cfg.timesteps\n",
        "        z = z + v_z * dt\n",
        "        cls_prior = cls_prior + v_cls * dt\n",
        "\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs + 1) / 2, 0, 1)\n",
        "\n",
        "def save_grid(imgs, path, nrow=8):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow, padding=2)\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def evaluate_models(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "\n",
        "    # Prepare real images\n",
        "    real_path = os.path.join(cfg.out_dir, f\"real_images_{num_samples}\")\n",
        "    if os.path.exists(real_path):\n",
        "        shutil.rmtree(real_path)\n",
        "    os.makedirs(real_path, exist_ok=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for imgs, _ in dataloader:\n",
        "        for img in imgs:\n",
        "            torchvision.utils.save_image((img + 1) / 2, os.path.join(real_path, f\"{cnt:05d}.png\"))\n",
        "            cnt += 1\n",
        "            if cnt >= num_samples:\n",
        "                break\n",
        "        if cnt >= num_samples:\n",
        "            break\n",
        "\n",
        "    for model_type in ['reg', 'unet']:\n",
        "        print(f\"Generating samples for {model_type.upper()}...\")\n",
        "\n",
        "        # Generate images\n",
        "        if model_type == 'reg':\n",
        "            imgs = sample_in_batches(sample_reg, num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir, 'reg_samples.png'), nrow=10)\n",
        "        else:\n",
        "            imgs = sample_in_batches(sample_unet, num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir, 'unet_samples.png'), nrow=10)\n",
        "\n",
        "        # Save generated images\n",
        "        gen_path = os.path.join(cfg.out_dir, f\"{model_type}_eval_{num_samples}\")\n",
        "        if os.path.exists(gen_path):\n",
        "            shutil.rmtree(gen_path)\n",
        "        os.makedirs(gen_path, exist_ok=True)\n",
        "\n",
        "        for i, img in enumerate(imgs):\n",
        "            torchvision.utils.save_image(img, os.path.join(gen_path, f\"{i:05d}.png\"))\n",
        "\n",
        "        # Calculate metrics\n",
        "        print(f\"Calculating metrics for {model_type.upper()}...\")\n",
        "        try:\n",
        "            metrics = calculate_metrics(\n",
        "                input1=gen_path,\n",
        "                input2=real_path,\n",
        "                cuda=torch.cuda.is_available(),\n",
        "                isc=True,\n",
        "                fid=True,\n",
        "                kid=False,\n",
        "                verbose=False\n",
        "            )\n",
        "            results[model_type] = metrics\n",
        "            print(f\"{model_type.upper()} Metrics: {metrics}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metrics: {e}\")\n",
        "            results[model_type] = {'frechet_inception_distance': float('inf'), 'inception_score_mean': 0.0}\n",
        "\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# Plotting\n",
        "# -------------------------\n",
        "def plot_loss_curves():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if reg_loss_history:\n",
        "        plt.plot(reg_loss_history, label='SiT+REG Loss', linewidth=2)\n",
        "    if unet_loss_history:\n",
        "        plt.plot(unet_loss_history, label='U-Net Loss', linewidth=2)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(os.path.join(cfg.out_dir, \"loss_curves.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------\n",
        "# Main Execution\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Starting Training...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Train models\n",
        "    print(\"Training SiT + REG Model...\")\n",
        "    train_reg(cfg.epochs)\n",
        "\n",
        "    print(\"\\nTraining U-Net Baseline...\")\n",
        "    train_unet(cfg.epochs)\n",
        "\n",
        "    # Plot results\n",
        "    plot_loss_curves()\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Evaluating on {cfg.sample_n} samples...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    metrics_results = evaluate_models()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    print(\"=\" * 60)\n",
        "    for model_type, metrics in metrics_results.items():\n",
        "        fid = metrics.get('frechet_inception_distance', float('inf'))\n",
        "        is_score = metrics.get('inception_score_mean', 0.0)\n",
        "        print(f\"{model_type.upper():<10} | FID: {fid:8.2f} | IS: {is_score:6.2f}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Training and evaluation complete!\")\n",
        "    print(f\"Results saved to: {cfg.out_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5B6LTTXbC2Cp",
        "outputId": "d340ad6e-8571-403b-81ed-4c69361bc3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Number of patches: 16\n",
            "Loaded 10000 images (['cat', 'dog'])\n",
            "Pre-training VAE...\n",
            "VAE pre-training complete\n",
            "Improved SiT+REG Model initialized with 5,470,224 parameters\n",
            "Improved U-Net Model initialized with 2,508,548 parameters\n",
            "============================================================\n",
            "Starting IMPROVED Training...\n",
            "============================================================\n",
            "Training SiT + REG Model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 1/20: 100%|██████████| 78/78 [00:05<00:00, 15.35it/s, loss=0.3315]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 Avg Loss: 0.7430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2/20: 100%|██████████| 78/78 [00:06<00:00, 12.70it/s, loss=0.1761]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 Avg Loss: 0.2099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3/20: 100%|██████████| 78/78 [00:05<00:00, 15.60it/s, loss=0.1321]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 Avg Loss: 0.1388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4/20: 100%|██████████| 78/78 [00:05<00:00, 13.76it/s, loss=0.0932]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 Avg Loss: 0.1079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5/20: 100%|██████████| 78/78 [00:05<00:00, 14.60it/s, loss=0.0896]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 Avg Loss: 0.0875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 6/20: 100%|██████████| 78/78 [00:05<00:00, 15.17it/s, loss=0.0755]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 6 Avg Loss: 0.0747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 7/20: 100%|██████████| 78/78 [00:05<00:00, 13.04it/s, loss=0.0659]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 7 Avg Loss: 0.0664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 8/20: 100%|██████████| 78/78 [00:05<00:00, 15.38it/s, loss=0.0654]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 8 Avg Loss: 0.0596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 9/20: 100%|██████████| 78/78 [00:05<00:00, 13.24it/s, loss=0.0466]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 9 Avg Loss: 0.0546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 10/20: 100%|██████████| 78/78 [00:04<00:00, 15.62it/s, loss=0.0634]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 10 Avg Loss: 0.0502\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 11/20: 100%|██████████| 78/78 [00:05<00:00, 15.01it/s, loss=0.0476]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 11 Avg Loss: 0.0462\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 12/20: 100%|██████████| 78/78 [00:05<00:00, 13.43it/s, loss=0.0460]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 12 Avg Loss: 0.0445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 13/20: 100%|██████████| 78/78 [00:05<00:00, 15.06it/s, loss=0.0475]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 13 Avg Loss: 0.0408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 14/20: 100%|██████████| 78/78 [00:05<00:00, 13.03it/s, loss=0.0381]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 14 Avg Loss: 0.0379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 15/20: 100%|██████████| 78/78 [00:05<00:00, 15.40it/s, loss=0.0335]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 15 Avg Loss: 0.0362\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 16/20: 100%|██████████| 78/78 [00:05<00:00, 14.03it/s, loss=0.0298]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 16 Avg Loss: 0.0345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 17/20: 100%|██████████| 78/78 [00:05<00:00, 14.28it/s, loss=0.0329]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 17 Avg Loss: 0.0332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 18/20: 100%|██████████| 78/78 [00:05<00:00, 15.42it/s, loss=0.0283]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 18 Avg Loss: 0.0325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 19/20: 100%|██████████| 78/78 [00:06<00:00, 12.86it/s, loss=0.0349]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 19 Avg Loss: 0.0314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 20/20: 100%|██████████| 78/78 [00:04<00:00, 15.66it/s, loss=0.0283]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 20 Avg Loss: 0.0297\n",
            "\n",
            "Training U-Net Baseline...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1/20: 100%|██████████| 78/78 [00:03<00:00, 19.71it/s, loss=0.3865]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 Avg Loss: 0.7066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2/20: 100%|██████████| 78/78 [00:03<00:00, 19.61it/s, loss=0.2650]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 Avg Loss: 0.3093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3/20: 100%|██████████| 78/78 [00:03<00:00, 22.87it/s, loss=0.1848]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 Avg Loss: 0.2167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4/20: 100%|██████████| 78/78 [00:03<00:00, 22.40it/s, loss=0.1696]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 Avg Loss: 0.1922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5/20: 100%|██████████| 78/78 [00:04<00:00, 16.96it/s, loss=0.1866]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 Avg Loss: 0.1810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6/20: 100%|██████████| 78/78 [00:03<00:00, 22.67it/s, loss=0.1831]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6 Avg Loss: 0.1656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7/20: 100%|██████████| 78/78 [00:03<00:00, 22.46it/s, loss=0.1821]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7 Avg Loss: 0.1590\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8/20: 100%|██████████| 78/78 [00:03<00:00, 22.51it/s, loss=0.1225]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8 Avg Loss: 0.1427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9/20: 100%|██████████| 78/78 [00:04<00:00, 18.22it/s, loss=0.1465]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9 Avg Loss: 0.1298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10/20: 100%|██████████| 78/78 [00:03<00:00, 23.33it/s, loss=0.1130]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10 Avg Loss: 0.1132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11/20: 100%|██████████| 78/78 [00:03<00:00, 23.31it/s, loss=0.0878]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11 Avg Loss: 0.0998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12/20: 100%|██████████| 78/78 [00:04<00:00, 18.05it/s, loss=0.0850]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12 Avg Loss: 0.0885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13/20: 100%|██████████| 78/78 [00:03<00:00, 22.19it/s, loss=0.0826]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13 Avg Loss: 0.0770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14/20: 100%|██████████| 78/78 [00:03<00:00, 22.61it/s, loss=0.0643]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14 Avg Loss: 0.0712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15/20: 100%|██████████| 78/78 [00:03<00:00, 22.66it/s, loss=0.0751]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15 Avg Loss: 0.0695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16/20: 100%|██████████| 78/78 [00:04<00:00, 17.71it/s, loss=0.0784]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16 Avg Loss: 0.0613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17/20: 100%|██████████| 78/78 [00:03<00:00, 23.73it/s, loss=0.0650]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17 Avg Loss: 0.0553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18/20: 100%|██████████| 78/78 [00:03<00:00, 22.72it/s, loss=0.0433]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18 Avg Loss: 0.0545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19/20: 100%|██████████| 78/78 [00:03<00:00, 19.83it/s, loss=0.0720]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19 Avg Loss: 0.0504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20/20: 100%|██████████| 78/78 [00:03<00:00, 20.74it/s, loss=0.0426]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20 Avg Loss: 0.0466\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Evaluating on 500 samples...\n",
            "============================================================\n",
            "\n",
            "Generating samples for REG...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 189.61it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 169.54it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 188.67it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 173.04it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 192.34it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 173.39it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 190.03it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 183.37it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 177.20it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 190.87it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 170.39it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 190.70it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 171.24it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 190.46it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 173.20it/s]\n",
            "REG Sampling: 100%|██████████| 1000/1000 [00:05<00:00, 194.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG samples saved!\n",
            "Calculating metrics for REG...\n",
            "REG Metrics: FID=389.30, IS=1.57\n",
            "\n",
            "Generating samples for UNET...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:02<00:00, 464.99it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:02<00:00, 483.40it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 558.40it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 559.41it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 544.35it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 563.90it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 541.58it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:02<00:00, 440.06it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 560.14it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 561.84it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 559.68it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 573.96it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 553.09it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:02<00:00, 474.28it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:02<00:00, 492.90it/s]\n",
            "U-Net Sampling: 100%|██████████| 1000/1000 [00:01<00:00, 554.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "U-Net samples saved!\n",
            "Calculating metrics for UNET...\n",
            "UNET Metrics: FID=288.86, IS=1.94\n",
            "\n",
            "============================================================\n",
            "FINAL RESULTS:\n",
            "============================================================\n",
            "REG        | FID:   389.30 | IS:   1.57\n",
            "UNET       | FID:   288.86 | IS:   1.94\n",
            "============================================================\n",
            "Training and evaluation complete!\n",
            "Check ./outputs_sit_reg_fixed for generated images!\n"
          ]
        }
      ],
      "source": [
        "# ============================\n",
        "# SiT + REG + U-Net Diffusion Implementation (Fixed Image Generation)\n",
        "# ============================\n",
        "!pip install torch-fidelity --upgrade -q\n",
        "!pip install einops -q\n",
        "\n",
        "# -------------------------\n",
        "# Imports\n",
        "# -------------------------\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_fidelity import calculate_metrics\n",
        "import numpy as np\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG (Optimized for proper training)\n",
        "# -------------------------\n",
        "class Config:\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 32\n",
        "    batch_size = 128\n",
        "    num_workers = 2\n",
        "\n",
        "    # Latent space config\n",
        "    latent_hw = 8\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2\n",
        "\n",
        "    # SiT architecture\n",
        "    depth = 6\n",
        "    hidden_dim = 256\n",
        "    num_heads = 8\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Training - CRITICAL FIXES\n",
        "    timesteps = 1000  # Increased for better training\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-3  # Added for stability\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 20  # Increased for convergence\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params\n",
        "    reg_lambda = 0.1  # Reduced to not overwhelm main loss\n",
        "    beta = 0.01  # Reduced class token weight\n",
        "    feat_dim = 256\n",
        "    align_layer = 2\n",
        "\n",
        "    sample_n = 500\n",
        "    out_dir = \"./outputs_sit_reg_fixed\"\n",
        "\n",
        "cfg = Config()\n",
        "torch.manual_seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "print(f\"Number of patches: {cfg.num_patches}\")\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED Noise Scheduler (DDPM style)\n",
        "# -------------------------\n",
        "class ImprovedNoiseScheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "\n",
        "        # Linear beta schedule as in original DDPM\n",
        "        self.betas = torch.linspace(0.0001, 0.02, timesteps).to(device)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.alpha_cumprod_prev = F.pad(self.alpha_cumprod[:-1], (1, 0), value=1.0)\n",
        "\n",
        "        # Calculations for diffusion\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alpha_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alpha_cumprod)\n",
        "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
        "\n",
        "        # Calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "        self.posterior_variance = self.betas * (1. - self.alpha_cumprod_prev) / (1. - self.alpha_cumprod)\n",
        "\n",
        "    def sample_t(self, batch_size):\n",
        "        return torch.randint(0, self.timesteps, (batch_size,), device=self.device, dtype=torch.long)\n",
        "\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "\n",
        "        sqrt_alpha_cumprod = self.sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "        sqrt_one_minus_alpha_cumprod = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "\n",
        "        return sqrt_alpha_cumprod * x0 + sqrt_one_minus_alpha_cumprod * noise, noise\n",
        "\n",
        "    def get_velocity_target(self, x0, epsilon):\n",
        "        \"\"\"v-prediction target\"\"\"\n",
        "        return epsilon\n",
        "\n",
        "scheduler = ImprovedNoiseScheduler(cfg.timesteps, device)\n",
        "\n",
        "# -------------------------\n",
        "# CIFAR-10 subset\n",
        "# -------------------------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    class_to_idx = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {class_to_idx[c] for c in classes}\n",
        "    transform = T.Compose([\n",
        "        T.Resize((cfg.image_size, cfg.image_size)),\n",
        "        T.RandomHorizontalFlip(p=0.5),  # Added augmentation\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=transform)\n",
        "    indices = [i for i,(x,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True,\n",
        "                       num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED VAE with better training\n",
        "# -------------------------\n",
        "class ImprovedVAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder: 32x32 -> 8x8\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(), # 16->8\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(256, latent_channels, 3, 1, 1)\n",
        "        )\n",
        "\n",
        "        # Decoder: 8x8 -> 32x32\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels, 256, 3, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),  # 8->16\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),   # 16->32\n",
        "            nn.Conv2d(64, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "vae = ImprovedVAE().to(device)\n",
        "\n",
        "# Pre-train VAE briefly for better initialization\n",
        "print(\"Pre-training VAE...\")\n",
        "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "vae.train()\n",
        "for epoch in range(3):  # Quick pre-training\n",
        "    for imgs, _ in dataloader:\n",
        "        imgs = imgs.to(device)\n",
        "        z = vae.encode(imgs)\n",
        "        recon = vae.decode(z)\n",
        "        loss = F.mse_loss(recon, imgs)\n",
        "        vae_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        vae_optimizer.step()\n",
        "print(\"VAE pre-training complete\")\n",
        "\n",
        "# -------------------------\n",
        "# Sinusoidal embeddings\n",
        "# -------------------------\n",
        "def get_timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(\n",
        "        -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
        "    ).to(device=timesteps.device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2:\n",
        "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "    return embedding\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED Transformer blocks with better stability\n",
        "# -------------------------\n",
        "class ImprovedMultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=cfg.num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = (dim // heads) ** -0.5\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.Dropout(cfg.dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.to_qkv(x).reshape(B, N, 3, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class ImprovedTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = ImprovedMultiHeadAttention(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        mlp_dim = int(dim * cfg.mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(cfg.dropout),\n",
        "            nn.Linear(mlp_dim, dim),\n",
        "            nn.Dropout(cfg.dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre-norm architecture for better stability\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED REG SiT\n",
        "# -------------------------\n",
        "class ImprovedREGSiT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = cfg.hidden_dim\n",
        "        self.num_patches = cfg.num_patches\n",
        "\n",
        "        # Patch embedding with better initialization\n",
        "        self.patch_embed = nn.Linear(cfg.latent_patch_dim, cfg.hidden_dim)\n",
        "\n",
        "        # Class token embedding\n",
        "        self.class_embed = nn.Linear(cfg.feat_dim, cfg.hidden_dim)\n",
        "\n",
        "        # Position embeddings\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.num_patches + 1, cfg.hidden_dim))\n",
        "\n",
        "        # Time embedding with MLP\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_dim, cfg.hidden_dim * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(cfg.hidden_dim * 4, cfg.hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ImprovedTransformerBlock(cfg.hidden_dim) for _ in range(cfg.depth)\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(cfg.hidden_dim)\n",
        "\n",
        "        # Output projections\n",
        "        self.patch_out = nn.Linear(cfg.hidden_dim, cfg.latent_patch_dim)\n",
        "        self.cls_out = nn.Linear(cfg.hidden_dim, cfg.feat_dim)\n",
        "\n",
        "        # Alignment projection\n",
        "        self.align_proj = nn.Linear(cfg.hidden_dim, cfg.feat_dim)\n",
        "\n",
        "        # Initialize properly\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            nn.init.constant_(module.bias, 0)\n",
        "            nn.init.constant_(module.weight, 1.0)\n",
        "\n",
        "    def forward(self, z_patched, cls_token, t):\n",
        "        B = z_patched.shape[0]\n",
        "\n",
        "        # Embed patches and class token\n",
        "        patch_emb = self.patch_embed(z_patched)\n",
        "        cls_emb = self.class_embed(cls_token).unsqueeze(1)\n",
        "\n",
        "        # Concatenate\n",
        "        x = torch.cat([cls_emb, patch_emb], dim=1)\n",
        "\n",
        "        # Add position embeddings\n",
        "        x = x + self.pos_embed\n",
        "\n",
        "        # Add timestep embedding\n",
        "        t_embed = get_timestep_embedding(t, self.hidden_dim)\n",
        "        t_embed = self.time_embed(t_embed).unsqueeze(1)\n",
        "        x = x + t_embed\n",
        "\n",
        "        # Transformer blocks with feature storage\n",
        "        intermediate_features = []\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if i == cfg.align_layer:\n",
        "                intermediate_features.append(x)\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        # Separate outputs\n",
        "        cls_pred = self.cls_out(x[:, 0])\n",
        "        patch_pred = self.patch_out(x[:, 1:])\n",
        "\n",
        "        # Alignment features\n",
        "        h_phi = self.align_proj(intermediate_features[0]) if intermediate_features else None\n",
        "\n",
        "        return patch_pred, cls_pred, h_phi\n",
        "\n",
        "reg_sit = ImprovedREGSiT().to(device)\n",
        "print(f\"Improved SiT+REG Model initialized with {sum(p.numel() for p in reg_sit.parameters()):,} parameters\")\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED Vision Foundation\n",
        "# -------------------------\n",
        "class ImprovedVisionFoundation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Better feature extractor\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(), # 16->8\n",
        "            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.ReLU(), # 8->4\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.proj = nn.Linear(256, cfg.feat_dim)\n",
        "\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        features = self.backbone(x).view(B, -1)\n",
        "        features = F.normalize(self.proj(features), dim=-1)  # Normalized features\n",
        "\n",
        "        cls_token = features\n",
        "        patch_features = features.unsqueeze(1).repeat(1, cfg.num_patches, 1)\n",
        "\n",
        "        return cls_token, patch_features\n",
        "\n",
        "vision = ImprovedVisionFoundation().to(device)\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED REG Model Wrapper\n",
        "# -------------------------\n",
        "class ImprovedREGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "\n",
        "    def forward(self, imgs, t_int):\n",
        "        B = imgs.shape[0]\n",
        "\n",
        "        # Encode to latent space WITH GRADIENTS\n",
        "        z_star = self.vae.encode(imgs)\n",
        "\n",
        "        # Extract vision features\n",
        "        cls_star, f_star = self.vision.extract(imgs)\n",
        "\n",
        "        # Sample noise\n",
        "        epsilon_z = torch.randn_like(z_star)\n",
        "        epsilon_cls = torch.randn_like(cls_star)\n",
        "\n",
        "        # Add noise to both latents and class token\n",
        "        zt, _ = scheduler.add_noise(z_star, t_int, noise=epsilon_z)\n",
        "\n",
        "        # Add noise to class token using same schedule\n",
        "        sqrt_alpha = scheduler.sqrt_alphas_cumprod[t_int].view(B, 1)\n",
        "        sqrt_one_minus_alpha = scheduler.sqrt_one_minus_alphas_cumprod[t_int].view(B, 1)\n",
        "        clst = sqrt_alpha * cls_star + sqrt_one_minus_alpha * epsilon_cls\n",
        "\n",
        "        # Prepare patches\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "\n",
        "        # Forward through SiT\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t_int)\n",
        "\n",
        "        # Convert patches back\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "\n",
        "        # Velocity targets\n",
        "        v_target_z = scheduler.get_velocity_target(z_star, epsilon_z)\n",
        "        v_target_cls = scheduler.get_velocity_target(cls_star, epsilon_cls)\n",
        "\n",
        "        # Prediction loss (MAIN OBJECTIVE)\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.beta * F.mse_loss(v_cls, v_target_cls)\n",
        "\n",
        "        # Alignment loss (REGULARIZATION)\n",
        "        loss_align = 0.0\n",
        "        if h_phi is not None:\n",
        "            y_star = torch.cat([cls_star.unsqueeze(1), f_star], dim=1)\n",
        "            # Use MSE for alignment for more stable training\n",
        "            loss_align = F.mse_loss(h_phi, y_star.detach())\n",
        "\n",
        "        total_loss = loss_pred + cfg.reg_lambda * loss_align\n",
        "        return total_loss\n",
        "\n",
        "reg_model = ImprovedREGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED U-Net\n",
        "# -------------------------\n",
        "class ImprovedUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.time_dim = 256\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(self.time_dim, self.time_dim * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(self.time_dim * 4, self.time_dim)\n",
        "        )\n",
        "\n",
        "        # Encoder with skip connections\n",
        "        self.enc1 = nn.Conv2d(cfg.latent_channels, 64, 3, 1, 1)\n",
        "        self.enc2 = nn.Conv2d(64, 128, 3, 2, 1)\n",
        "        self.enc3 = nn.Conv2d(128, 256, 3, 2, 1)\n",
        "\n",
        "        self.mid = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        self.dec1 = nn.ConvTranspose2d(256, 128, 4, 2, 1)\n",
        "        self.dec2 = nn.ConvTranspose2d(256, 64, 4, 2, 1)  # + skip from enc2\n",
        "        self.out = nn.Conv2d(128, cfg.latent_channels, 3, 1, 1)  # + skip from enc1\n",
        "\n",
        "        # Time projections\n",
        "        self.time_projs = nn.ModuleList([\n",
        "            nn.Linear(self.time_dim, 64),\n",
        "            nn.Linear(self.time_dim, 128),\n",
        "            nn.Linear(self.time_dim, 256),\n",
        "            nn.Linear(self.time_dim, 256),\n",
        "            nn.Linear(self.time_dim, 128),\n",
        "            nn.Linear(self.time_dim, 64)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        B = x.shape[0]\n",
        "\n",
        "        # Time embedding\n",
        "        t_embed = get_timestep_embedding(t, self.time_dim)\n",
        "        t_embed = self.time_embed(t_embed)\n",
        "\n",
        "        # Encoder with skip connections\n",
        "        x1 = F.silu(self.enc1(x) + self.time_projs[0](t_embed).view(B, 64, 1, 1))\n",
        "        x2 = F.silu(self.enc2(x1) + self.time_projs[1](t_embed).view(B, 128, 1, 1))\n",
        "        x3 = F.silu(self.enc3(x2) + self.time_projs[2](t_embed).view(B, 256, 1, 1))\n",
        "\n",
        "        # Middle\n",
        "        m = F.silu(self.mid(x3) + self.time_projs[3](t_embed).view(B, 256, 1, 1))\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d1 = F.silu(self.dec1(m) + self.time_projs[4](t_embed).view(B, 128, 1, 1))\n",
        "        d1 = torch.cat([d1, x2], dim=1)  # Skip connection\n",
        "\n",
        "        d2 = F.silu(self.dec2(d1) + self.time_projs[5](t_embed).view(B, 64, 1, 1))\n",
        "        d2 = torch.cat([d2, x1], dim=1)  # Skip connection\n",
        "\n",
        "        out = self.out(d2)\n",
        "        return out\n",
        "\n",
        "unet = ImprovedUNet().to(device)\n",
        "print(f\"Improved U-Net Model initialized with {sum(p.numel() for p in unet.parameters()):,} parameters\")\n",
        "\n",
        "# -------------------------\n",
        "# Optimizers\n",
        "# -------------------------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr,\n",
        "                           weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr,\n",
        "                            weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED Training with better monitoring\n",
        "# -------------------------\n",
        "reg_loss_history, unet_loss_history = [], []\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, total_pred, total_align = 0.0, 0.0, 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"REG Epoch {epoch+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            t_int = scheduler.sample_t(imgs.shape[0])\n",
        "\n",
        "            loss = reg_model(imgs, t_int)\n",
        "\n",
        "            opt_reg.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            opt_reg.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        reg_loss_history.append(avg_loss)\n",
        "        print(f\"REG Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"UNet Epoch {epoch+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                z_star = vae.encode(imgs)\n",
        "\n",
        "            t_int = scheduler.sample_t(B)\n",
        "            epsilon_z = torch.randn_like(z_star)\n",
        "            zt, _ = scheduler.add_noise(z_star, t_int, noise=epsilon_z)\n",
        "\n",
        "            v_pred = unet(zt, t_int)\n",
        "            loss = F.mse_loss(v_pred, epsilon_z)\n",
        "\n",
        "            opt_unet.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            opt_unet.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        unet_loss_history.append(avg_loss)\n",
        "        print(f\"UNet Epoch {epoch+1} Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# -------------------------\n",
        "# IMPROVED Sampling (DDPM style)\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def sample_in_batches(sample_fn, num_samples, batch_size=32):\n",
        "    imgs_list = []\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        b = min(batch_size, num_samples - i)\n",
        "        imgs_list.append(sample_fn(b))\n",
        "    return torch.cat(imgs_list, dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unet(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "\n",
        "    # Proper DDPM sampling\n",
        "    for i in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"U-Net Sampling\"):\n",
        "        t = torch.full((B,), i, device=device, dtype=torch.long)\n",
        "\n",
        "        # Predict noise\n",
        "        epsilon_pred = unet(z, t)\n",
        "\n",
        "        # Compute coefficients\n",
        "        alpha = scheduler.alphas[t].view(-1, 1, 1, 1)\n",
        "        alpha_cumprod = scheduler.alpha_cumprod[t].view(-1, 1, 1, 1)\n",
        "        alpha_cumprod_prev = scheduler.alpha_cumprod_prev[t].view(-1, 1, 1, 1)\n",
        "\n",
        "        if i > 0:\n",
        "            noise = torch.randn_like(z)\n",
        "        else:\n",
        "            noise = 0\n",
        "\n",
        "        # DDPM reverse process\n",
        "        z = (1 / torch.sqrt(alpha)) * (\n",
        "            z - ((1 - alpha) / torch.sqrt(1 - alpha_cumprod)) * epsilon_pred\n",
        "        ) + torch.sqrt(scheduler.posterior_variance[t]).view(-1, 1, 1, 1) * noise\n",
        "\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs + 1) / 2, 0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "    cls_prior = torch.randn(B, cfg.feat_dim, device=device)\n",
        "\n",
        "    # DDPM sampling for SiT+REG\n",
        "    for i in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"REG Sampling\"):\n",
        "        t = torch.full((B,), i, device=device, dtype=torch.long)\n",
        "\n",
        "        # Prepare patches\n",
        "        z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "\n",
        "        # Predict velocity\n",
        "        v_patch, v_cls, _ = reg_sit(z_patched, cls_prior, t)\n",
        "\n",
        "        # Convert back to spatial\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "\n",
        "        # Use velocity for DDPM sampling\n",
        "        alpha = scheduler.alphas[t].view(-1, 1, 1, 1)\n",
        "        alpha_cumprod = scheduler.alpha_cumprod[t].view(-1, 1, 1, 1)\n",
        "\n",
        "        if i > 0:\n",
        "            noise = torch.randn_like(z)\n",
        "        else:\n",
        "            noise = 0\n",
        "\n",
        "        # Update using velocity (v-prediction)\n",
        "        z = (1 / torch.sqrt(alpha)) * (\n",
        "            z - ((1 - alpha) / torch.sqrt(1 - alpha_cumprod)) * v_z\n",
        "        ) + torch.sqrt(scheduler.posterior_variance[t]).view(-1, 1, 1, 1) * noise\n",
        "\n",
        "        # Update class token\n",
        "        cls_prior = cls_prior - v_cls * 0.01\n",
        "\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs + 1) / 2, 0, 1)\n",
        "\n",
        "def save_grid(imgs, path, nrow=8):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow, padding=2)\n",
        "\n",
        "# -------------------------\n",
        "# Training and Evaluation\n",
        "# -------------------------\n",
        "def plot_loss_curves():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    if reg_loss_history:\n",
        "        plt.plot(reg_loss_history, label='SiT+REG Loss', linewidth=2)\n",
        "    if unet_loss_history:\n",
        "        plt.plot(unet_loss_history, label='U-Net Loss', linewidth=2)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss Curves')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(os.path.join(cfg.out_dir, \"loss_curves.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_models(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "\n",
        "    # Prepare real images\n",
        "    real_path = os.path.join(cfg.out_dir, f\"real_images_{num_samples}\")\n",
        "    if os.path.exists(real_path):\n",
        "        shutil.rmtree(real_path)\n",
        "    os.makedirs(real_path, exist_ok=True)\n",
        "\n",
        "    cnt = 0\n",
        "    for imgs, _ in dataloader:\n",
        "        for img in imgs:\n",
        "            torchvision.utils.save_image((img + 1) / 2, os.path.join(real_path, f\"{cnt:05d}.png\"))\n",
        "            cnt += 1\n",
        "            if cnt >= num_samples:\n",
        "                break\n",
        "        if cnt >= num_samples:\n",
        "            break\n",
        "\n",
        "    for model_type in ['reg', 'unet']:\n",
        "        print(f\"\\nGenerating samples for {model_type.upper()}...\")\n",
        "\n",
        "        # Generate images\n",
        "        if model_type == 'reg':\n",
        "            imgs = sample_in_batches(sample_reg, num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir, 'reg_samples.png'), nrow=10)\n",
        "            print(\"REG samples saved!\")\n",
        "        else:\n",
        "            imgs = sample_in_batches(sample_unet, num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir, 'unet_samples.png'), nrow=10)\n",
        "            print(\"U-Net samples saved!\")\n",
        "\n",
        "        # Save generated images\n",
        "        gen_path = os.path.join(cfg.out_dir, f\"{model_type}_eval_{num_samples}\")\n",
        "        if os.path.exists(gen_path):\n",
        "            shutil.rmtree(gen_path)\n",
        "        os.makedirs(gen_path, exist_ok=True)\n",
        "\n",
        "        for i, img in enumerate(imgs):\n",
        "            torchvision.utils.save_image(img, os.path.join(gen_path, f\"{i:05d}.png\"))\n",
        "\n",
        "        # Calculate metrics\n",
        "        print(f\"Calculating metrics for {model_type.upper()}...\")\n",
        "        try:\n",
        "            metrics = calculate_metrics(\n",
        "                input1=gen_path,\n",
        "                input2=real_path,\n",
        "                cuda=torch.cuda.is_available(),\n",
        "                isc=True,\n",
        "                fid=True,\n",
        "                kid=False,\n",
        "                verbose=False\n",
        "            )\n",
        "            results[model_type] = metrics\n",
        "            print(f\"{model_type.upper()} Metrics: FID={metrics['frechet_inception_distance']:.2f}, IS={metrics['inception_score_mean']:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metrics: {e}\")\n",
        "            results[model_type] = {'frechet_inception_distance': float('inf'), 'inception_score_mean': 0.0}\n",
        "\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# Main Execution\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Starting IMPROVED Training...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Train models\n",
        "    print(\"Training SiT + REG Model...\")\n",
        "    train_reg(cfg.epochs)\n",
        "\n",
        "    print(\"\\nTraining U-Net Baseline...\")\n",
        "    train_unet(cfg.epochs)\n",
        "\n",
        "    # Plot results\n",
        "    plot_loss_curves()\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Evaluating on {cfg.sample_n} samples...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    metrics_results = evaluate_models()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    print(\"=\" * 60)\n",
        "    for model_type, metrics in metrics_results.items():\n",
        "        fid = metrics.get('frechet_inception_distance', float('inf'))\n",
        "        is_score = metrics.get('inception_score_mean', 0.0)\n",
        "        print(f\"{model_type.upper():<10} | FID: {fid:8.2f} | IS: {is_score:6.2f}\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Training and evaluation complete!\")\n",
        "    print(f\"Check {cfg.out_dir} for generated images!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vcdZh1TvGeQs",
        "outputId": "1c46e9fa-5c4a-40d4-f332-7dd95cfca4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Paper file (for reference): /mnt/data/Research paper Diffusion Transformers.pdf\n",
            "Loaded 10000 images (['cat', 'dog'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "VAE pretrain 1/2: 100%|██████████| 78/78 [00:05<00:00, 15.32it/s, loss=0.0282]\n",
            "VAE pretrain 2/2: 100%|██████████| 78/78 [00:05<00:00, 15.52it/s, loss=0.0189]\n",
            "/tmp/ipython-input-1600487281.py:440: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE pretrain done\n",
            "REG SiT params: 5470224\n",
            "==================================================\n",
            "Starting training (SiT+REG and U-Net baseline) on Colab T4 friendly config\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rREG Epoch 1/20:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-1600487281.py:455: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "REG Epoch 1/20: 100%|██████████| 78/78 [00:06<00:00, 12.09it/s, loss=0.1706, pred=0.1554, align=0.5070]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 avg: 0.6726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2/20: 100%|██████████| 78/78 [00:06<00:00, 12.01it/s, loss=0.1074, pred=0.0970, align=0.3452]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 avg: 0.1369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3/20: 100%|██████████| 78/78 [00:06<00:00, 12.43it/s, loss=0.1194, pred=0.1119, align=0.2480]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 avg: 0.1006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4/20: 100%|██████████| 78/78 [00:06<00:00, 11.73it/s, loss=0.0845, pred=0.0791, align=0.1828]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 avg: 0.0850\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5/20: 100%|██████████| 78/78 [00:06<00:00, 12.47it/s, loss=0.0616, pred=0.0571, align=0.1478]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 avg: 0.0744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 6/20: 100%|██████████| 78/78 [00:06<00:00, 11.63it/s, loss=0.0509, pred=0.0475, align=0.1142]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 6 avg: 0.0688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 7/20: 100%|██████████| 78/78 [00:06<00:00, 12.73it/s, loss=0.0627, pred=0.0598, align=0.0991]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 7 avg: 0.0679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 8/20: 100%|██████████| 78/78 [00:06<00:00, 11.53it/s, loss=0.0605, pred=0.0579, align=0.0868]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 8 avg: 0.0651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 9/20: 100%|██████████| 78/78 [00:06<00:00, 12.85it/s, loss=0.0538, pred=0.0515, align=0.0772]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 9 avg: 0.0582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 10/20: 100%|██████████| 78/78 [00:06<00:00, 11.42it/s, loss=0.0510, pred=0.0490, align=0.0689]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 10 avg: 0.0556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 11/20: 100%|██████████| 78/78 [00:05<00:00, 13.14it/s, loss=0.0543, pred=0.0523, align=0.0640]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 11 avg: 0.0596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 12/20: 100%|██████████| 78/78 [00:06<00:00, 11.36it/s, loss=0.0497, pred=0.0479, align=0.0628]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 12 avg: 0.0557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 13/20: 100%|██████████| 78/78 [00:05<00:00, 13.22it/s, loss=0.0483, pred=0.0466, align=0.0575]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 13 avg: 0.0521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 14/20: 100%|██████████| 78/78 [00:06<00:00, 11.24it/s, loss=0.0545, pred=0.0527, align=0.0599]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 14 avg: 0.0600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 15/20: 100%|██████████| 78/78 [00:06<00:00, 12.98it/s, loss=0.0720, pred=0.0704, align=0.0564]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 15 avg: 0.0554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 16/20: 100%|██████████| 78/78 [00:06<00:00, 11.55it/s, loss=0.0608, pred=0.0591, align=0.0550]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 16 avg: 0.0541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 17/20: 100%|██████████| 78/78 [00:05<00:00, 13.06it/s, loss=0.0487, pred=0.0470, align=0.0540]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 17 avg: 0.0515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 18/20: 100%|██████████| 78/78 [00:06<00:00, 11.59it/s, loss=0.0456, pred=0.0441, align=0.0501]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 18 avg: 0.0466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 19/20: 100%|██████████| 78/78 [00:06<00:00, 12.94it/s, loss=0.0629, pred=0.0614, align=0.0489]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 19 avg: 0.0426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 20/20: 100%|██████████| 78/78 [00:06<00:00, 11.57it/s, loss=0.0599, pred=0.0584, align=0.0488]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 20 avg: 0.0475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rUNet Epoch 1/20:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-1600487281.py:484: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "UNet Epoch 1/20: 100%|██████████| 78/78 [00:03<00:00, 19.85it/s, loss=0.4011]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 avg: 0.6135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2/20: 100%|██████████| 78/78 [00:04<00:00, 18.15it/s, loss=0.3193]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 avg: 0.3416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3/20: 100%|██████████| 78/78 [00:04<00:00, 16.24it/s, loss=0.2123]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 avg: 0.2585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4/20: 100%|██████████| 78/78 [00:04<00:00, 18.60it/s, loss=0.2020]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 avg: 0.2252\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5/20: 100%|██████████| 78/78 [00:04<00:00, 18.10it/s, loss=0.1497]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 avg: 0.1831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6/20: 100%|██████████| 78/78 [00:05<00:00, 14.98it/s, loss=0.1391]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6 avg: 0.1534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7/20: 100%|██████████| 78/78 [00:04<00:00, 18.85it/s, loss=0.1238]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7 avg: 0.1416\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8/20: 100%|██████████| 78/78 [00:04<00:00, 18.38it/s, loss=0.1157]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8 avg: 0.1199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9/20: 100%|██████████| 78/78 [00:05<00:00, 15.24it/s, loss=0.1051]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9 avg: 0.1081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10/20: 100%|██████████| 78/78 [00:04<00:00, 18.18it/s, loss=0.0920]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10 avg: 0.0921\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11/20: 100%|██████████| 78/78 [00:04<00:00, 18.38it/s, loss=0.1105]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11 avg: 0.0825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12/20: 100%|██████████| 78/78 [00:05<00:00, 14.96it/s, loss=0.0663]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12 avg: 0.0748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13/20: 100%|██████████| 78/78 [00:04<00:00, 18.33it/s, loss=0.0546]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13 avg: 0.0695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14/20: 100%|██████████| 78/78 [00:04<00:00, 16.76it/s, loss=0.0601]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14 avg: 0.0651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15/20: 100%|██████████| 78/78 [00:04<00:00, 16.97it/s, loss=0.0569]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15 avg: 0.0607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16/20: 100%|██████████| 78/78 [00:04<00:00, 18.42it/s, loss=0.0444]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16 avg: 0.0528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17/20: 100%|██████████| 78/78 [00:05<00:00, 15.19it/s, loss=0.0883]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17 avg: 0.0536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18/20: 100%|██████████| 78/78 [00:04<00:00, 17.64it/s, loss=0.0483]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18 avg: 0.0464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19/20: 100%|██████████| 78/78 [00:04<00:00, 18.70it/s, loss=0.0395]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19 avg: 0.0470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20/20: 100%|██████████| 78/78 [00:05<00:00, 15.31it/s, loss=0.0362]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20 avg: 0.0431\n",
            "\n",
            "========================================\n",
            "Evaluating on 500 samples\n",
            "========================================\n",
            "\n",
            "Generating samples for REG...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics (this may take a bit)...\n",
            "REG Metrics: FID=462.51, IS=1.37\n",
            "\n",
            "Generating samples for UNET...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics (this may take a bit)...\n",
            "UNET Metrics: FID=324.59, IS=2.14\n",
            "\n",
            "FINAL RESULTS:\n",
            "REG      | FID:   462.51 | IS:   1.37\n",
            "UNET     | FID:   324.59 | IS:   2.14\n",
            "Done! Check ./outputs_sit_reg_colab for outputs (images, loss plot).\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Colab-ready single-file SiT + REG + U-Net pipeline (optimized for Colab T4)\n",
        "# Usage: paste into a single Colab cell and run (Runtime: GPU)\n",
        "# References:\n",
        "# - Paper path (uploaded by you): /mnt/data/Research paper Diffusion Transformers.pdf\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Install & imports\n",
        "# ---------------------------\n",
        "!pip install -q torch-fidelity einops tqdm\n",
        "# (torch is preinstalled in Colab GPU runtime)\n",
        "\n",
        "import os, math, random, shutil, time\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "# Path to uploaded paper (for your reference)\n",
        "PAPER_PATH = \"/mnt/data/Research paper Diffusion Transformers.pdf\"\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Configuration (T4-friendly)\n",
        "# ---------------------------\n",
        "class Config:\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 32\n",
        "    batch_size = 128               # T4-friendly for small model\n",
        "    num_workers = 2\n",
        "\n",
        "    # Latent / patch config (paper uses VAE latents; simpler small variant here)\n",
        "    latent_hw = 8                  # 8 x 8 latent spatial (fits T4)\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2\n",
        "\n",
        "    # SiT-small variant (downscaled)\n",
        "    depth = 6\n",
        "    hidden_dim = 256\n",
        "    num_heads = 8\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Training\n",
        "    timesteps = 250                # Paper uses 250 for evaluation; training also OK\n",
        "    lr = 2e-4\n",
        "    weight_decay = 1e-2\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 20                    # increase for better quality\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params\n",
        "    reg_lambda = 0.03              # follow paper-ish small weight\n",
        "    beta_cls = 0.03                # weight for class token v-prediction\n",
        "    feat_dim = 256                 # class token dimension after vision proj\n",
        "    align_layer = 2\n",
        "\n",
        "    # Eval / output\n",
        "    sample_n = 500                 # number of samples to generate for metrics (reduce if slow)\n",
        "    out_dir = \"./outputs_sit_reg_colab\"\n",
        "    ema_decay = 0.9999\n",
        "\n",
        "cfg = Config()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "torch.manual_seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "print(\"Paper file (for reference):\", PAPER_PATH)\n",
        "\n",
        "# ---------------------------\n",
        "# 2) Noise scheduler (simple linear beta like DDPM but we use v-pred objective)\n",
        "#    and helpers for v-target conversion\n",
        "# ---------------------------\n",
        "class Scheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        # linear beta from small to moderate\n",
        "        self.betas = torch.linspace(1e-4, 0.02, timesteps, device=device)\n",
        "        self.alphas = 1.0 - self.betas\n",
        "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.alpha_cumprod_prev = F.pad(self.alpha_cumprod[:-1], (1,0), value=1.0)\n",
        "        self.sqrt_alphas_cumprod = torch.sqrt(self.alpha_cumprod)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alpha_cumprod)\n",
        "        self.posterior_variance = self.betas * (1. - self.alpha_cumprod_prev) / (1. - self.alpha_cumprod)\n",
        "\n",
        "    def sample_t(self, batch_size):\n",
        "        return torch.randint(0, self.timesteps, (batch_size,), device=self.device, dtype=torch.long)\n",
        "\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a = self.sqrt_alphas_cumprod[t].view(-1,1,1,1)\n",
        "        b = self.sqrt_one_minus_alphas_cumprod[t].view(-1,1,1,1)\n",
        "        return a * x0 + b * noise, noise\n",
        "\n",
        "    def v_target(self, x0, eps):\n",
        "        # For v-prediction used in many recent works, the target is epsilon (we use epsilon)\n",
        "        return eps\n",
        "\n",
        "scheduler = Scheduler(cfg.timesteps, device)\n",
        "\n",
        "# ---------------------------\n",
        "# 3) CIFAR-10 two-class subset loader\n",
        "# ---------------------------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    class_to_idx = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {class_to_idx[c] for c in classes}\n",
        "    transform = T.Compose([\n",
        "        T.Resize((cfg.image_size, cfg.image_size)),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=transform)\n",
        "    indices = [i for i,(_,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True,\n",
        "                        num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Lightweight VAE (encoder -> small latents; decoder -> reconstruct)\n",
        "#    Paper uses strong pretrained VAE; for colab we'll train small VAE quickly\n",
        "# ---------------------------\n",
        "class SmallVAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "        # encoder 32x32 -> 8x8\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(), # 16->8\n",
        "            nn.Conv2d(256, latent_channels, 3, 1, 1)\n",
        "        )\n",
        "        # decoder 8x8 -> 32x32\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels, 256, 3, 1,1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(), # 8->16\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),  # 16->32\n",
        "            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.enc(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.dec(z)\n",
        "\n",
        "vae = SmallVAE().to(device)\n",
        "\n",
        "# quick pretrain of VAE (small)\n",
        "def pretrain_vae(epochs=3):\n",
        "    opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    vae.train()\n",
        "    for ep in range(epochs):\n",
        "        pbar = tqdm(dataloader, desc=f\"VAE pretrain {ep+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            z = vae.encode(imgs)\n",
        "            recon = vae.decode(z)\n",
        "            loss = F.mse_loss(recon, imgs)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            pbar.set_postfix({'loss':f\"{loss.item():.4f}\"})\n",
        "    print(\"VAE pretrain done\")\n",
        "\n",
        "pretrain_vae(epochs=2)  # brief pretraining\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Sinusoidal timestep embedding\n",
        "# ---------------------------\n",
        "def get_timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(-math.log(max_period) * torch.arange(half, dtype=torch.float32, device=timesteps.device) / half)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2:\n",
        "        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n",
        "    return emb\n",
        "\n",
        "# ---------------------------\n",
        "# 6) Improved Transformer blocks (pre-norm), MultiHeadAttention\n",
        "# ---------------------------\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, dim, heads):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        self.to_qkv = nn.Linear(dim, dim*3, bias=False)\n",
        "        self.scale = (dim // heads) ** -0.5\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,N,C = x.shape\n",
        "        qkv = self.to_qkv(x).reshape(B,N,3,self.heads, C//self.heads).permute(2,0,3,1,4)\n",
        "        q,k,v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2,-1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out = (attn @ v).transpose(1,2).reshape(B,N,C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = MultiHeadSelfAttention(dim, cfg.num_heads)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        mlp_dim = int(dim * cfg.mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_dim, dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# ---------------------------\n",
        "# 7) SiT + REG model (downscaled)\n",
        "# ---------------------------\n",
        "class REGSiT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = cfg.hidden_dim\n",
        "        self.patch_embed = nn.Linear(cfg.latent_patch_dim, cfg.hidden_dim)\n",
        "        self.class_embed = nn.Linear(cfg.feat_dim, cfg.hidden_dim)\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.num_patches + 1, cfg.hidden_dim))\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.Linear(cfg.hidden_dim, cfg.hidden_dim*4),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(cfg.hidden_dim*4, cfg.hidden_dim)\n",
        "        )\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg.hidden_dim) for _ in range(cfg.depth)])\n",
        "        self.norm = nn.LayerNorm(cfg.hidden_dim)\n",
        "        self.patch_out = nn.Linear(cfg.hidden_dim, cfg.latent_patch_dim)\n",
        "        self.cls_out = nn.Linear(cfg.hidden_dim, cfg.feat_dim)\n",
        "        self.align_proj = nn.Linear(cfg.hidden_dim, cfg.feat_dim)  # maps hidden to feat space\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.zeros_(m.bias); nn.init.ones_(m.weight)\n",
        "\n",
        "    def forward(self, z_patched, cls_token, t):\n",
        "        B = z_patched.shape[0]\n",
        "        patch_emb = self.patch_embed(z_patched)  # b, n, dim\n",
        "        cls_emb = self.class_embed(cls_token).unsqueeze(1)  # b,1,dim\n",
        "        x = torch.cat([cls_emb, patch_emb], dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        t_emb = get_timestep_embedding(t, self.hidden_dim)\n",
        "        t_emb = self.time_mlp(t_emb).unsqueeze(1)\n",
        "        x = x + t_emb\n",
        "        intermediate = None\n",
        "        for i, blk in enumerate(self.blocks):\n",
        "            x = blk(x)\n",
        "            if i == cfg.align_layer:\n",
        "                intermediate = x   # (B, N+1, hidden)\n",
        "        x = self.norm(x)\n",
        "        cls_pred = self.cls_out(x[:,0])\n",
        "        patch_pred = self.patch_out(x[:,1:])\n",
        "        hphi = self.align_proj(intermediate) if intermediate is not None else None\n",
        "        return patch_pred, cls_pred, hphi\n",
        "\n",
        "reg_sit = REGSiT().to(device)\n",
        "print(\"REG SiT params:\", sum(p.numel() for p in reg_sit.parameters()))\n",
        "\n",
        "# ---------------------------\n",
        "# 8) Vision foundation small extractor (simulate pretrained class token)\n",
        "#    In the paper they use DINOv2; here we use a small frozen conv + linear to produce a class token.\n",
        "# ---------------------------\n",
        "class VisionFoundation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,2,1), nn.BatchNorm2d(64), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(64,128,3,2,1), nn.BatchNorm2d(128), nn.ReLU(), # 16->8\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.proj = nn.Linear(128, cfg.feat_dim)\n",
        "        # we don't train this \"foundation\" to simulate frozen pre-trained model behavior\n",
        "        for p in self.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        feats = self.backbone(x).view(B, -1)\n",
        "        cls = F.normalize(self.proj(feats), dim=-1)\n",
        "        # produce patch features placeholder (repeat cls across patches) for alignment targets\n",
        "        patch_feats = cls.unsqueeze(1).repeat(1, cfg.num_patches, 1)\n",
        "        return cls, patch_feats\n",
        "\n",
        "vision = VisionFoundation().to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# 9) REG training wrapper (computes loss)\n",
        "# ---------------------------\n",
        "class REGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "\n",
        "    def forward(self, imgs, t):\n",
        "        B = imgs.shape[0]\n",
        "        # encode latents\n",
        "        z_star = self.vae.encode(imgs)  # B, C, H, W (e.g. 4,8,8)\n",
        "        # produce class token and patch targets\n",
        "        cls_star, f_star = self.vision.extract(imgs)  # cls: B, feat_dim; f_star: B, num_patches, feat_dim\n",
        "        # sample noises for both\n",
        "        eps_z = torch.randn_like(z_star)\n",
        "        eps_cls = torch.randn_like(cls_star)\n",
        "        # add noise per scheduler\n",
        "        zt, _ = scheduler.add_noise(z_star, t, noise=eps_z)\n",
        "        # class token noising (use sqrt forms)\n",
        "        a = scheduler.sqrt_alphas_cumprod[t].view(B,1)\n",
        "        b = scheduler.sqrt_one_minus_alphas_cumprod[t].view(B,1)\n",
        "        clst = a * cls_star + b * eps_cls\n",
        "\n",
        "        # patchify zt: b c (h p) (w q) -> b (h w) (c p q)\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        # forward\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t)\n",
        "        # reconstruct v_z shape\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        # v-targets (we use eps as target here for velocity pred)\n",
        "        v_target_z = scheduler.v_target(z_star, eps_z)\n",
        "        v_target_cls = scheduler.v_target(cls_star, eps_cls)\n",
        "\n",
        "        # prediction loss (image + class token)\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.beta_cls * F.mse_loss(v_cls, v_target_cls)\n",
        "\n",
        "        # alignment loss: align h_phi (projected) with y_star = concat(cls*, f*)\n",
        "        loss_align = 0.0\n",
        "        if h_phi is not None:\n",
        "            # h_phi is B, N+1, feat_dim (our align_proj produced that)\n",
        "            # y_star: concat cls*, f_star along token dim\n",
        "            y_star = torch.cat([cls_star.unsqueeze(1), f_star], dim=1)  # B, N+1, feat_dim\n",
        "            loss_align = F.mse_loss(h_phi, y_star.detach())\n",
        "\n",
        "        total = loss_pred + cfg.reg_lambda * loss_align\n",
        "        return total, loss_pred.item(), loss_align.item() if isinstance(loss_align, torch.Tensor) else float(loss_align)\n",
        "\n",
        "reg_model = REGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# 10) U-Net baseline (small)\n",
        "# ---------------------------\n",
        "class SmallUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.time_dim = 256\n",
        "        self.time_embed = nn.Sequential(nn.Linear(self.time_dim, self.time_dim*4), nn.SiLU(), nn.Linear(self.time_dim*4, self.time_dim))\n",
        "        self.enc1 = nn.Conv2d(cfg.latent_channels, 64, 3, 1,1)\n",
        "        self.enc2 = nn.Conv2d(64,128,4,2,1)\n",
        "        self.enc3 = nn.Conv2d(128,256,4,2,1)\n",
        "        self.mid = nn.Conv2d(256,256,3,1,1)\n",
        "        self.dec1 = nn.ConvTranspose2d(256,128,4,2,1)\n",
        "        self.dec2 = nn.ConvTranspose2d(256,64,4,2,1)\n",
        "        self.out = nn.Conv2d(128, cfg.latent_channels, 3,1,1)\n",
        "        self.time_projs = nn.ModuleList([nn.Linear(self.time_dim,64), nn.Linear(self.time_dim,128), nn.Linear(self.time_dim,256), nn.Linear(self.time_dim,256), nn.Linear(self.time_dim,128), nn.Linear(self.time_dim,64)])\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        B = x.shape[0]\n",
        "        t_emb = get_timestep_embedding(t, self.time_dim)\n",
        "        t_emb = self.time_embed(t_emb)\n",
        "        x1 = F.silu(self.enc1(x) + self.time_projs[0](t_emb).view(B,64,1,1))\n",
        "        x2 = F.silu(self.enc2(x1) + self.time_projs[1](t_emb).view(B,128,1,1))\n",
        "        x3 = F.silu(self.enc3(x2) + self.time_projs[2](t_emb).view(B,256,1,1))\n",
        "        m = F.silu(self.mid(x3) + self.time_projs[3](t_emb).view(B,256,1,1))\n",
        "        d1 = F.silu(self.dec1(m) + self.time_projs[4](t_emb).view(B,128,1,1))\n",
        "        d1 = torch.cat([d1, x2], dim=1)\n",
        "        d2 = F.silu(self.dec2(d1) + self.time_projs[5](t_emb).view(B,64,1,1))\n",
        "        d2 = torch.cat([d2, x1], dim=1)\n",
        "        out = self.out(d2)\n",
        "        return out\n",
        "\n",
        "unet = SmallUNet().to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# 11) Optimizers & EMA & AMP\n",
        "# ---------------------------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "\n",
        "# EMA wrappers\n",
        "def make_ema(model):\n",
        "    ema = {}\n",
        "    for name, p in model.named_parameters():\n",
        "        if p.requires_grad:\n",
        "            ema[name] = p.detach().cpu().clone()\n",
        "    return ema\n",
        "\n",
        "def load_ema_to_model(model, ema):\n",
        "    for name, p in model.named_parameters():\n",
        "        if name in ema:\n",
        "            p.data.copy_(ema[name].to(p.device))\n",
        "\n",
        "def update_ema(model, ema, decay):\n",
        "    for name, p in model.named_parameters():\n",
        "        if name in ema:\n",
        "            ema[name].mul_(decay).add_(p.detach().cpu(), alpha=1.0-decay)\n",
        "\n",
        "ema_reg = make_ema(reg_model)\n",
        "ema_unet = make_ema(unet)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# ---------------------------\n",
        "# 12) Training loops\n",
        "# ---------------------------\n",
        "reg_loss_history, unet_loss_history = [], []\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for ep in range(epochs):\n",
        "        total = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"REG Epoch {ep+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            t = scheduler.sample_t(imgs.shape[0])\n",
        "            with torch.cuda.amp.autocast():\n",
        "                loss, lp, la = reg_model(imgs, t)\n",
        "            opt_reg.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_reg)\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_reg)\n",
        "            scaler.update()\n",
        "            update_ema(reg_model, ema_reg, cfg.ema_decay)\n",
        "            total += loss.item()\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'pred':f\"{lp:.4f}\", 'align':f\"{la:.4f}\"})\n",
        "        avg = total / len(dataloader)\n",
        "        reg_loss_history.append(avg)\n",
        "        print(f\"REG Epoch {ep+1} avg: {avg:.4f}\")\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for ep in range(epochs):\n",
        "        total = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"UNet Epoch {ep+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            # encode z_star no grad for unet training\n",
        "            with torch.no_grad():\n",
        "                z_star = vae.encode(imgs)\n",
        "            t = scheduler.sample_t(B)\n",
        "            eps = torch.randn_like(z_star)\n",
        "            zt, _ = scheduler.add_noise(z_star, t, noise=eps)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                v_pred = unet(zt, t)\n",
        "                loss = F.mse_loss(v_pred, eps)\n",
        "            opt_unet.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_unet)\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_unet)\n",
        "            scaler.update()\n",
        "            update_ema(unet, ema_unet, cfg.ema_decay)\n",
        "            total += loss.item()\n",
        "            pbar.set_postfix({'loss':f\"{loss.item():.4f}\"})\n",
        "        avg = total / len(dataloader)\n",
        "        unet_loss_history.append(avg)\n",
        "        print(f\"UNet Epoch {ep+1} avg: {avg:.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 13) Sampling (Euler-Maruyama style / v-prediction)\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def sample_unet(num_samples, batch_size=32):\n",
        "    parts = []\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        b = min(batch_size, num_samples-i)\n",
        "        z = torch.randn(b, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "        # use EMA weights for unet\n",
        "        unet_saved = {n:p.detach().cpu().clone() for n,p in unet.named_parameters() if p.requires_grad}\n",
        "        load_ema_to_model(unet, ema_unet)\n",
        "        for i_t in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"U-Net Sampling\", leave=False):\n",
        "            t = torch.full((b,), i_t, device=device, dtype=torch.long)\n",
        "            eps_pred = unet(z, t)\n",
        "            alpha = scheduler.alphas[t].view(-1,1,1,1)\n",
        "            alpha_cum = scheduler.alpha_cumprod[t].view(-1,1,1,1)\n",
        "            if i_t>0:\n",
        "                noise = torch.randn_like(z)\n",
        "            else:\n",
        "                noise = 0\n",
        "            z = (1/torch.sqrt(alpha))*( z - ((1-alpha)/torch.sqrt(1-alpha_cum))*eps_pred ) + torch.sqrt(scheduler.posterior_variance[t]).view(-1,1,1,1)*noise\n",
        "        imgs = vae.decode(z)\n",
        "        parts.append(torch.clamp((imgs+1)/2,0,1).cpu())\n",
        "        # restore unet weights\n",
        "        load_ema_to_model(unet, ema_unet)\n",
        "    return torch.cat(parts, dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(num_samples, batch_size=32):\n",
        "    parts=[]\n",
        "    # create starting z and class prior\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        b = min(batch_size, num_samples-i)\n",
        "        z = torch.randn(b, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "        cls_prior = torch.randn(b, cfg.feat_dim, device=device)\n",
        "        # use EMA weights for sit\n",
        "        sit_saved = {n:p.detach().cpu().clone() for n,p in reg_sit.named_parameters() if p.requires_grad}\n",
        "        # load ema into sit\n",
        "        load_ema_to_model(reg_sit, ema_reg)\n",
        "        for i_t in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"REG Sampling\", leave=False):\n",
        "            t = torch.full((b,), i_t, device=device, dtype=torch.long)\n",
        "            # prepare patches\n",
        "            z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                                  p=cfg.patch_size, q=cfg.patch_size,\n",
        "                                  h=cfg.latent_hw//cfg.patch_size,\n",
        "                                  w=cfg.latent_hw//cfg.patch_size)\n",
        "            v_patch, v_cls, _ = reg_sit(z_patched, cls_prior, t)\n",
        "            v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                            p=cfg.patch_size, q=cfg.patch_size,\n",
        "                            h=cfg.latent_hw//cfg.patch_size,\n",
        "                            w=cfg.latent_hw//cfg.patch_size,\n",
        "                            c=cfg.latent_channels)\n",
        "            alpha = scheduler.alphas[t].view(-1,1,1,1)\n",
        "            alpha_cum = scheduler.alpha_cumprod[t].view(-1,1,1,1)\n",
        "            if i_t>0:\n",
        "                noise = torch.randn_like(z)\n",
        "            else:\n",
        "                noise = 0\n",
        "            z = (1/torch.sqrt(alpha))*( z - ((1-alpha)/torch.sqrt(1-alpha_cum))*v_z ) + torch.sqrt(scheduler.posterior_variance[t]).view(-1,1,1,1)*noise\n",
        "            # update class token (small step)\n",
        "            cls_prior = cls_prior - 0.01 * v_cls\n",
        "        imgs = vae.decode(z)\n",
        "        parts.append(torch.clamp((imgs+1)/2,0,1).cpu())\n",
        "        # restore sit weights from EMA (we used EMA already)\n",
        "    return torch.cat(parts, dim=0)\n",
        "\n",
        "def save_grid(imgs, path, nrow=10):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow, padding=2)\n",
        "\n",
        "# ---------------------------\n",
        "# 14) Metrics evaluation (torch-fidelity)\n",
        "# ---------------------------\n",
        "def evaluate_models(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "    real_path = os.path.join(cfg.out_dir, \"real_images\")\n",
        "    if os.path.exists(real_path): shutil.rmtree(real_path)\n",
        "    os.makedirs(real_path, exist_ok=True)\n",
        "    # gather real images\n",
        "    cnt=0\n",
        "    for imgs,_ in dataloader:\n",
        "        for im in imgs:\n",
        "            torchvision.utils.save_image((im+1)/2, os.path.join(real_path, f\"{cnt:05d}.png\"))\n",
        "            cnt+=1\n",
        "            if cnt>=num_samples:\n",
        "                break\n",
        "        if cnt>=num_samples: break\n",
        "\n",
        "    for model_type in ['reg','unet']:\n",
        "        print(f\"\\nGenerating samples for {model_type.upper()}...\")\n",
        "        if model_type=='reg':\n",
        "            gen = sample_reg(num_samples, batch_size=64)\n",
        "            save_grid(gen, os.path.join(cfg.out_dir, 'reg_samples.png'), nrow=10)\n",
        "        else:\n",
        "            gen = sample_unet(num_samples, batch_size=64)\n",
        "            save_grid(gen, os.path.join(cfg.out_dir, 'unet_samples.png'), nrow=10)\n",
        "\n",
        "        gen_path = os.path.join(cfg.out_dir, f\"{model_type}_eval\")\n",
        "        if os.path.exists(gen_path): shutil.rmtree(gen_path)\n",
        "        os.makedirs(gen_path, exist_ok=True)\n",
        "        for i, img in enumerate(gen):\n",
        "            torchvision.utils.save_image(img, os.path.join(gen_path, f\"{i:05d}.png\"))\n",
        "        print(\"Calculating metrics (this may take a bit)...\")\n",
        "        try:\n",
        "            metrics = calculate_metrics(input1=gen_path, input2=real_path, cuda=torch.cuda.is_available(), isc=True, fid=True, kid=False, verbose=False)\n",
        "            results[model_type] = metrics\n",
        "            print(f\"{model_type.upper()} Metrics: FID={metrics['frechet_inception_distance']:.2f}, IS={metrics['inception_score_mean']:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\"Metric computation error:\", e)\n",
        "            results[model_type] = {'frechet_inception_distance': float('inf'), 'inception_score_mean': 0.0}\n",
        "    return results\n",
        "\n",
        "# ---------------------------\n",
        "# 15) Plot helper\n",
        "# ---------------------------\n",
        "def plot_loss():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    if reg_loss_history: plt.plot(reg_loss_history, label='SiT+REG')\n",
        "    if unet_loss_history: plt.plot(unet_loss_history, label='U-Net')\n",
        "    plt.legend(); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.grid(True)\n",
        "    plt.savefig(os.path.join(cfg.out_dir,\"loss.png\"), dpi=200)\n",
        "\n",
        "# ---------------------------\n",
        "# 16) Main execution\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*50)\n",
        "    print(\"Starting training (SiT+REG and U-Net baseline) on Colab T4 friendly config\")\n",
        "    print(\"=\"*50)\n",
        "    # TRAIN\n",
        "    train_reg(cfg.epochs)\n",
        "    train_unet(cfg.epochs)\n",
        "    # Save losses\n",
        "    plot_loss()\n",
        "    # Evaluate and compute FID/IS\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Evaluating on {cfg.sample_n} samples\")\n",
        "    print(\"=\"*40)\n",
        "    metrics = evaluate_models(cfg.sample_n)\n",
        "    print(\"\\nFINAL RESULTS:\")\n",
        "    for m,met in metrics.items():\n",
        "        fid = met.get('frechet_inception_distance', float('inf'))\n",
        "        is_ = met.get('inception_score_mean', 0.0)\n",
        "        print(f\"{m.upper():<8} | FID: {fid:8.2f} | IS: {is_:6.2f}\")\n",
        "    print(\"Done! Check\", cfg.out_dir, \"for outputs (images, loss plot).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZzxzMBLOkOmB",
        "outputId": "a8dc5e74-8d88-4e59-b7f2-93f6a7b7015f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loaded 10000 images (['cat', 'dog'])\n",
            "Pretraining VAE (2 epochs)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-967729455.py:379: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE warmup done\n",
            "==================================================\n",
            "Starting training (REG + U-Net) - uses v-pred, REG entanglement, EMA, CFG\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rREG Epoch 1/20:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-967729455.py:390: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
            "REG Epoch 1/20: 100%|██████████| 78/78 [00:08<00:00,  9.42it/s, loss=0.4121, pred=0.3191, align=0.1859]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 avg: 0.9735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2/20: 100%|██████████| 78/78 [00:07<00:00, 10.21it/s, loss=0.3192, pred=0.2473, align=0.1437]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 avg: 0.3498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3/20: 100%|██████████| 78/78 [00:08<00:00,  9.29it/s, loss=0.2848, pred=0.2228, align=0.1240]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 avg: 0.2833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4/20: 100%|██████████| 78/78 [00:08<00:00,  9.62it/s, loss=0.2220, pred=0.1698, align=0.1044]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 avg: 0.2371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5/20: 100%|██████████| 78/78 [00:08<00:00,  9.53it/s, loss=0.1893, pred=0.1427, align=0.0932]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 avg: 0.2056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 6/20: 100%|██████████| 78/78 [00:08<00:00,  9.26it/s, loss=0.1512, pred=0.1091, align=0.0843]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 6 avg: 0.1810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 7/20: 100%|██████████| 78/78 [00:07<00:00,  9.91it/s, loss=0.1803, pred=0.1421, align=0.0763]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 7 avg: 0.1714\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 8/20: 100%|██████████| 78/78 [00:08<00:00,  9.08it/s, loss=0.1372, pred=0.1031, align=0.0682]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 8 avg: 0.1549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 9/20: 100%|██████████| 78/78 [00:08<00:00,  9.36it/s, loss=0.1410, pred=0.1071, align=0.0678]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 9 avg: 0.1325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 10/20: 100%|██████████| 78/78 [00:07<00:00, 10.00it/s, loss=0.1168, pred=0.0900, align=0.0535]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 10 avg: 0.1190\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 11/20: 100%|██████████| 78/78 [00:07<00:00,  9.84it/s, loss=0.1099, pred=0.0864, align=0.0469]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 11 avg: 0.1112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 12/20: 100%|██████████| 78/78 [00:08<00:00,  9.44it/s, loss=0.1044, pred=0.0842, align=0.0404]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 12 avg: 0.0988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 13/20: 100%|██████████| 78/78 [00:07<00:00, 10.47it/s, loss=0.0741, pred=0.0546, align=0.0391]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 13 avg: 0.0926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 14/20: 100%|██████████| 78/78 [00:08<00:00,  9.44it/s, loss=0.0789, pred=0.0604, align=0.0370]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 14 avg: 0.0862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 15/20: 100%|██████████| 78/78 [00:08<00:00,  9.39it/s, loss=0.0845, pred=0.0674, align=0.0343]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 15 avg: 0.0809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 16/20: 100%|██████████| 78/78 [00:07<00:00, 10.47it/s, loss=0.0776, pred=0.0615, align=0.0322]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 16 avg: 0.0785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 17/20: 100%|██████████| 78/78 [00:08<00:00,  9.30it/s, loss=0.0910, pred=0.0749, align=0.0321]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 17 avg: 0.0740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 18/20: 100%|██████████| 78/78 [00:08<00:00,  9.53it/s, loss=0.0866, pred=0.0698, align=0.0336]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 18 avg: 0.0723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 19/20: 100%|██████████| 78/78 [00:07<00:00, 10.43it/s, loss=0.0684, pred=0.0524, align=0.0320]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 19 avg: 0.0705\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 20/20: 100%|██████████| 78/78 [00:08<00:00,  9.46it/s, loss=0.0847, pred=0.0697, align=0.0300]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 20 avg: 0.0694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rUNet Epoch 1/20:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-967729455.py:421: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
            "UNet Epoch 1/20: 100%|██████████| 78/78 [00:04<00:00, 17.27it/s, loss=0.5872]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 avg: 0.7945\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2/20: 100%|██████████| 78/78 [00:05<00:00, 14.33it/s, loss=0.4622]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 avg: 0.5019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3/20: 100%|██████████| 78/78 [00:04<00:00, 17.32it/s, loss=0.3626]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 avg: 0.4041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4/20: 100%|██████████| 78/78 [00:04<00:00, 17.08it/s, loss=0.3482]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 avg: 0.3583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5/20: 100%|██████████| 78/78 [00:05<00:00, 14.30it/s, loss=0.2742]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 avg: 0.3115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6/20: 100%|██████████| 78/78 [00:04<00:00, 17.12it/s, loss=0.2675]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6 avg: 0.2831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7/20: 100%|██████████| 78/78 [00:04<00:00, 15.64it/s, loss=0.2549]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7 avg: 0.2641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8/20: 100%|██████████| 78/78 [00:04<00:00, 15.98it/s, loss=0.2359]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8 avg: 0.2408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9/20: 100%|██████████| 78/78 [00:04<00:00, 17.34it/s, loss=0.2367]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9 avg: 0.2260\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10/20: 100%|██████████| 78/78 [00:05<00:00, 14.11it/s, loss=0.2009]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10 avg: 0.2052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11/20: 100%|██████████| 78/78 [00:04<00:00, 17.51it/s, loss=0.2212]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11 avg: 0.1920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12/20: 100%|██████████| 78/78 [00:04<00:00, 17.20it/s, loss=0.1610]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12 avg: 0.1843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13/20: 100%|██████████| 78/78 [00:05<00:00, 14.44it/s, loss=0.1645]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13 avg: 0.1770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14/20: 100%|██████████| 78/78 [00:04<00:00, 17.55it/s, loss=0.1602]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14 avg: 0.1751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15/20: 100%|██████████| 78/78 [00:05<00:00, 15.32it/s, loss=0.1665]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15 avg: 0.1715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16/20: 100%|██████████| 78/78 [00:04<00:00, 16.11it/s, loss=0.1724]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16 avg: 0.1611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17/20: 100%|██████████| 78/78 [00:04<00:00, 17.40it/s, loss=0.2104]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17 avg: 0.1659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18/20: 100%|██████████| 78/78 [00:05<00:00, 14.30it/s, loss=0.1440]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18 avg: 0.1572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19/20: 100%|██████████| 78/78 [00:04<00:00, 17.31it/s, loss=0.1420]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19 avg: 0.1629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20/20: 100%|██████████| 78/78 [00:04<00:00, 17.05it/s, loss=0.1674]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20 avg: 0.1617\n",
            "Applying EMA to models for sampling...\n",
            "Evaluating samples...\n",
            "\n",
            "Generating samples for REG...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Sampling: 100%|██████████| 250/250 [00:10<00:00, 24.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for REG...\n",
            "REG Metrics: FID=385.44, IS=1.86\n",
            "\n",
            "Generating samples for UNET...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Sampling: 100%|██████████| 250/250 [00:03<00:00, 77.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics for UNET...\n",
            "UNET Metrics: FID=440.39, IS=1.89\n",
            "FINAL RESULTS:\n",
            "REG      | FID: 385.44 | IS: 1.86\n",
            "UNET     | FID: 440.39 | IS: 1.89\n",
            "Done. Check ./outputs_reg_fixed\n"
          ]
        }
      ],
      "source": [
        "# Updated SiT+REG + U-Net script (Colab T4-friendly)\n",
        "# - Uses v-prediction, Euler-Maruyama sampling, REG entanglement, EMA, CFG\n",
        "# - Based on \"Representation Entanglement for Generation\" (see citations above)\n",
        "\n",
        "# NOTE: run in a single cell. Install dependencies first in Colab if needed:\n",
        "# !pip install torch-fidelity einops --upgrade -q\n",
        "\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For FID/IS\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "# -------------------------\n",
        "# CONFIG (edit for memory/batch)\n",
        "# -------------------------\n",
        "class CFG:\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 32\n",
        "    batch_size = 128             # T4 friendly: try 128; if OOM reduce to 64\n",
        "    num_workers = 2\n",
        "\n",
        "    latent_hw = 8\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2\n",
        "\n",
        "    # SiT architecture (small)\n",
        "    depth = 6\n",
        "    hidden_dim = 256\n",
        "    num_heads = 8\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Training (paper recommends AdamW 1e-4, batch 256; scaled here)\n",
        "    timesteps = 250              # paper uses 250 sampling steps for evaluation. Use same for sampling.\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-3\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 20\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params from paper: β and λ (scaled / kept same intent)\n",
        "    reg_beta = 0.03\n",
        "    reg_lambda = 0.5\n",
        "    feat_dim = 256\n",
        "    align_layer = 4               # paper aligns at layer 4 for SiT-B/2\n",
        "    sample_n = 500\n",
        "    out_dir = \"./outputs_reg_fixed\"\n",
        "    ema_decay = 0.9999\n",
        "    cfg_guidance_scale = 2.0      # default CFG; you can tune (paper uses CFG w up to 4)\n",
        "\n",
        "cfg = CFG()\n",
        "torch.manual_seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# -------------------------\n",
        "# Noise / interpolant schedule (paper uses α_t = 1-t, σ_t = t in a normalized [0,1] time)\n",
        "# We'll map discrete t in [0, timesteps-1] to continuous τ in [0,1].\n",
        "# -------------------------\n",
        "class PaperScheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        # continuous time tau = t / (T-1), alpha(tau)=1-tau, sigma(tau)=tau\n",
        "        taus = torch.linspace(0.0, 1.0, timesteps, device=self.device)\n",
        "        self.alpha = (1.0 - taus).to(device)\n",
        "        self.sigma = taus.to(device)\n",
        "        # helper terms for v-prediction mapping (for v-target = epsilon)\n",
        "        self.sqrt_alpha = torch.sqrt(self.alpha).to(device)\n",
        "        self.sqrt_one_minus_alpha = torch.sqrt(1.0 - self.alpha).to(device)\n",
        "    def sample_t(self, batch):\n",
        "        return torch.randint(0, self.timesteps, (batch,), device=self.device, dtype=torch.long)\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        # returns x_t and noise\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a = self.alpha[t].view(-1,1,1,1)\n",
        "        s = self.sigma[t].view(-1,1,1,1)\n",
        "        return a * x0 + s * noise, noise\n",
        "    def to_cont(self, t):\n",
        "        return t / (self.timesteps - 1)\n",
        "\n",
        "scheduler = PaperScheduler(cfg.timesteps, device)\n",
        "\n",
        "# -------------------------\n",
        "# Data\n",
        "# -------------------------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    class_to_idx = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {class_to_idx[c] for c in classes}\n",
        "    transform = T.Compose([\n",
        "        T.Resize((cfg.image_size, cfg.image_size)),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))   # map in [-1,1] for VAE tanh decoder\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=transform)\n",
        "    indices = [i for i,(x,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True,\n",
        "                        num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# -------------------------\n",
        "# Small VAE (encoder->latent_hw x latent_hw -> decoder)\n",
        "# -------------------------\n",
        "class SmallVAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),  # 32->16\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(), # 16->8\n",
        "            nn.Conv2d(256, latent_channels, 3, 1, 1)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels, 256, 3, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(), # 8->16\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),  # 16->32\n",
        "            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()\n",
        "        )\n",
        "    def encode(self, x): return self.encoder(x)\n",
        "    def decode(self, z): return self.decoder(z)\n",
        "\n",
        "vae = SmallVAE().to(device)\n",
        "\n",
        "# Quick VAE warmup like you did (3 epochs)\n",
        "vae_opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "vae.train()\n",
        "print(\"Pretraining VAE (2 epochs)...\")\n",
        "for ep in range(2):\n",
        "    for imgs, _ in dataloader:\n",
        "        imgs = imgs.to(device)\n",
        "        z = vae.encode(imgs)\n",
        "        recon = vae.decode(z)\n",
        "        loss = F.mse_loss(recon, imgs)\n",
        "        vae_opt.zero_grad(); loss.backward(); vae_opt.step()\n",
        "print(\"VAE warmup done\")\n",
        "\n",
        "# -------------------------\n",
        "# Small SiT (REG) and Vision foundation\n",
        "# -------------------------\n",
        "class MHA(nn.Module):\n",
        "    def __init__(self, dim, heads=cfg.num_heads):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.to_qkv = nn.Linear(dim, dim*3, bias=False)\n",
        "        self.scale = (dim//heads)**-0.5\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "    def forward(self, x):\n",
        "        B,N,C = x.shape\n",
        "        qkv = self.to_qkv(x).view(B,N,3,self.heads,C//self.heads).permute(2,0,3,1,4)\n",
        "        q,k,v = qkv[0], qkv[1], qkv[2]\n",
        "        attn = (q @ k.transpose(-2,-1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        out = (attn @ v).transpose(1,2).reshape(B,N,C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(dim)\n",
        "        self.attn = MHA(dim)\n",
        "        self.ln2 = nn.LayerNorm(dim)\n",
        "        mlp_dim = int(dim * cfg.mlp_ratio)\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, mlp_dim), nn.GELU(), nn.Linear(mlp_dim, dim))\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class REGSiT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        Dp = cfg.latent_patch_dim\n",
        "        Hd = cfg.hidden_dim\n",
        "        self.patch_embed = nn.Linear(Dp, Hd)\n",
        "        self.class_embed = nn.Linear(cfg.feat_dim, Hd)\n",
        "        self.pos = nn.Parameter(torch.zeros(1, cfg.num_patches+1, Hd))\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(Hd, Hd*4), nn.SiLU(), nn.Linear(Hd*4, Hd))\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(Hd) for _ in range(cfg.depth)])\n",
        "        self.norm = nn.LayerNorm(Hd)\n",
        "        self.patch_out = nn.Linear(Hd, Dp)\n",
        "        self.cls_out = nn.Linear(Hd, cfg.feat_dim)\n",
        "        self.align_proj = nn.Linear(Hd, cfg.feat_dim)\n",
        "        self.apply(self._init_weights)\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None: nn.init.constant_(m.bias, 0.)\n",
        "    def forward(self, z_patched, cls_token, t):\n",
        "        B = z_patched.shape[0]\n",
        "        patch_emb = self.patch_embed(z_patched)\n",
        "        cls_emb = self.class_embed(cls_token).unsqueeze(1)\n",
        "        x = torch.cat([cls_emb, patch_emb], dim=1) + self.pos\n",
        "        # timestep embedding (simple)\n",
        "        t_emb = get_timestep_embedding(t, cfg.hidden_dim).to(x.device)\n",
        "        t_emb = self.time_mlp(t_emb).unsqueeze(1)\n",
        "        x = x + t_emb\n",
        "        inter = None\n",
        "        for i, b in enumerate(self.blocks):\n",
        "            x = b(x)\n",
        "            if i == cfg.align_layer:\n",
        "                inter = x\n",
        "        x = self.norm(x)\n",
        "        cls_pred = self.cls_out(x[:,0])\n",
        "        patch_pred = self.patch_out(x[:,1:])\n",
        "        h_phi = self.align_proj(inter) if inter is not None else None\n",
        "        return patch_pred, cls_pred, h_phi\n",
        "\n",
        "def get_timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    # sinusoidal embedding (standard)\n",
        "    half = dim//2\n",
        "    freqs = torch.exp(-math.log(max_period) * torch.arange(0, half, dtype=torch.float32) / half).to(device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2 == 1:\n",
        "        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n",
        "    return emb\n",
        "\n",
        "reg_sit = REGSiT().to(device)\n",
        "\n",
        "# Vision foundation: small CNN producing class token + dense patch features\n",
        "class SmallVision(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3,64,3,2,1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64,128,3,2,1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.proj = nn.Linear(128, cfg.feat_dim)\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        f = self.backbone(x).view(B,-1)\n",
        "        feat = F.normalize(self.proj(f), dim=-1)\n",
        "        cls = feat\n",
        "        patch = feat.unsqueeze(1).repeat(1, cfg.num_patches, 1)\n",
        "        return cls, patch\n",
        "\n",
        "vision = SmallVision().to(device)\n",
        "\n",
        "# -------------------------\n",
        "# REG model wrapper computing loss (v-pred + alignment)\n",
        "# -------------------------\n",
        "class REGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "    def forward(self, imgs, t_idx):\n",
        "        B = imgs.shape[0]\n",
        "        z_star = self.vae.encode(imgs)              # z*: (B,C,H,W)\n",
        "        cls_star, dense_star = self.vision.extract(imgs)  # cls_star: (B,feat_dim)\n",
        "        # sample noises\n",
        "        eps_z = torch.randn_like(z_star)\n",
        "        eps_cls = torch.randn_like(cls_star)\n",
        "        # add noise using paper schedule (alpha/sigma)\n",
        "        zt, _ = scheduler.add_noise(z_star, t_idx, noise=eps_z)\n",
        "        a = scheduler.alpha[t_idx].view(B,1)\n",
        "        s = scheduler.sigma[t_idx].view(B,1)\n",
        "        clst = (a * cls_star + s * eps_cls)\n",
        "        # patchify zt\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        # forward sit\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t_idx)\n",
        "        # reconstruct v_z spatial\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        # v-targets (paper uses v-target = epsilon)  \n",
        "        v_target_z = eps_z\n",
        "        v_target_cls = eps_cls\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.reg_beta * F.mse_loss(v_cls, v_target_cls)\n",
        "        loss_align = 0.0\n",
        "        if h_phi is not None:\n",
        "            # make y_star: concat cls and dense features (paper aligns to this)\n",
        "            y_star = torch.cat([cls_star.unsqueeze(1), dense_star], dim=1)\n",
        "            loss_align = F.mse_loss(h_phi, y_star.detach())\n",
        "        total_loss = loss_pred + cfg.reg_lambda * loss_align\n",
        "        # returning components for logging\n",
        "        return total_loss, loss_pred.detach().item(), loss_align if isinstance(loss_align, torch.Tensor) else torch.tensor(loss_align)\n",
        "\n",
        "reg_model = REGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Small U-Net baseline (v-pred)\n",
        "# -------------------------\n",
        "class SimpleUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.time_dim = 256\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(self.time_dim, self.time_dim*4), nn.SiLU(), nn.Linear(self.time_dim*4, self.time_dim))\n",
        "        self.enc1 = nn.Conv2d(cfg.latent_channels, 64, 3, 1,1)\n",
        "        self.enc2 = nn.Conv2d(64,128,4,2,1)\n",
        "        self.enc3 = nn.Conv2d(128,256,4,2,1)\n",
        "        self.mid = nn.Conv2d(256,256,3,1,1)\n",
        "        self.dec1 = nn.ConvTranspose2d(256,128,4,2,1)\n",
        "        self.dec2 = nn.ConvTranspose2d(256,64,4,2,1)\n",
        "        self.out = nn.Conv2d(128, cfg.latent_channels, 3,1,1)\n",
        "        self.timings = nn.ModuleList([nn.Linear(self.time_dim, k) for k in (64,128,256,256,128,64)])\n",
        "    def forward(self, x, t):\n",
        "        B=x.shape[0]\n",
        "        t_emb = get_timestep_embedding(t, self.time_dim).to(x.device)\n",
        "        t_emb = self.time_mlp(t_emb)\n",
        "        x1 = F.silu(self.enc1(x) + self.timings[0](t_emb).view(B,64,1,1))\n",
        "        x2 = F.silu(self.enc2(x1) + self.timings[1](t_emb).view(B,128,1,1))\n",
        "        x3 = F.silu(self.enc3(x2) + self.timings[2](t_emb).view(B,256,1,1))\n",
        "        m = F.silu(self.mid(x3) + self.timings[3](t_emb).view(B,256,1,1))\n",
        "        d1 = F.silu(self.dec1(m) + self.timings[4](t_emb).view(B,128,1,1))\n",
        "        d1 = torch.cat([d1, x2], dim=1)\n",
        "        d2 = F.silu(self.dec2(d1) + self.timings[5](t_emb).view(B,64,1,1))\n",
        "        d2 = torch.cat([d2, x1], dim=1)\n",
        "        out = self.out(d2)\n",
        "        return out\n",
        "\n",
        "unet = SimpleUNet().to(device)\n",
        "\n",
        "# -------------------------\n",
        "# Optimizers, EMA, schedulers\n",
        "# -------------------------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr, betas=cfg.betas, weight_decay=cfg.weight_decay)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr, betas=cfg.betas, weight_decay=cfg.weight_decay)\n",
        "sched_reg = torch.optim.lr_scheduler.CosineAnnealingLR(opt_reg, T_max=cfg.epochs)\n",
        "sched_unet = torch.optim.lr_scheduler.CosineAnnealingLR(opt_unet, T_max=cfg.epochs)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay):\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.shadow = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
        "    def update(self, model):\n",
        "        for k,v in model.state_dict().items():\n",
        "            self.shadow[k] = (self.decay * self.shadow[k] + (1.0-self.decay) * v.detach().cpu()).clone()\n",
        "    def apply_to(self, model):\n",
        "        model.load_state_dict({k: self.shadow[k].to(next(model.parameters()).device) for k in model.state_dict().keys()})\n",
        "\n",
        "ema_reg = EMA(reg_model, cfg.ema_decay)\n",
        "ema_unet = EMA(unet, cfg.ema_decay)\n",
        "\n",
        "# -------------------------\n",
        "# Training loops (use AMP)\n",
        "# -------------------------\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total, total_pred, total_align = 0.0, 0.0, 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"REG Epoch {epoch+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            t_idx = scheduler.sample_t(B)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                loss, loss_pred, loss_align = reg_model(imgs, t_idx)\n",
        "            opt_reg.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_reg)\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_reg)\n",
        "            scaler.update()\n",
        "            ema_reg.update(reg_model)\n",
        "            total += loss.item()\n",
        "            total_pred += loss_pred\n",
        "            total_align += (loss_align.item() if isinstance(loss_align, torch.Tensor) else float(loss_align))\n",
        "            pbar.set_postfix({'loss':f'{loss.item():.4f}','pred':f'{loss_pred:.4f}','align':f'{(loss_align.item() if isinstance(loss_align, torch.Tensor) else float(loss_align)):.4f}'})\n",
        "        sched_reg.step()\n",
        "        print(f\"REG Epoch {epoch+1} avg: {total/len(dataloader):.4f}\")\n",
        "        # save checkpoint occasionally\n",
        "        torch.save({'epoch':epoch+1, 'model':reg_model.state_dict(), 'opt':opt_reg.state_dict()}, os.path.join(cfg.out_dir, f\"reg_epoch_{epoch+1}.pt\"))\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for epoch in range(epochs):\n",
        "        total = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"UNet Epoch {epoch+1}/{epochs}\")\n",
        "        for imgs, _ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            with torch.no_grad():\n",
        "                z_star = vae.encode(imgs)\n",
        "            t_idx = scheduler.sample_t(B)\n",
        "            eps = torch.randn_like(z_star)\n",
        "            zt, _ = scheduler.add_noise(z_star, t_idx, noise=eps)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                v_pred = unet(zt, t_idx)\n",
        "                loss = F.mse_loss(v_pred, eps)   # v-pred target epsilon\n",
        "            opt_unet.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_unet)\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_unet)\n",
        "            scaler.update()\n",
        "            ema_unet.update(unet)\n",
        "            total += loss.item()\n",
        "            pbar.set_postfix({'loss':f'{loss.item():.4f}'})\n",
        "        sched_unet.step()\n",
        "        print(f\"UNet Epoch {epoch+1} avg: {total/len(dataloader):.4f}\")\n",
        "        torch.save({'epoch':epoch+1, 'model':unet.state_dict(), 'opt':opt_unet.state_dict()}, os.path.join(cfg.out_dir, f\"unet_epoch_{epoch+1}.pt\"))\n",
        "\n",
        "# -------------------------\n",
        "# Euler-Maruyama sampler for v-pred (paper) with CFG for REG\n",
        "# (Reference: Table 12 and sampler description). :contentReference[oaicite:9]{index=9}\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def em_step_v(z, v_pred, t_idx, t_prev_idx):\n",
        "    # z: current latent; v_pred: predicted v (epsilon) at time t\n",
        "    # follow discrete Euler-Maruyama reverse update for v-pred (paper formulation)\n",
        "    alpha_t = scheduler.alpha[t_idx].view(-1,1,1,1)\n",
        "    sigma_t = scheduler.sigma[t_idx].view(-1,1,1,1)\n",
        "    alpha_prev = scheduler.alpha[t_prev_idx].view(-1,1,1,1)\n",
        "    sigma_prev = scheduler.sigma[t_prev_idx].view(-1,1,1,1)\n",
        "    # Use v-pred to estimate clean x0: x0_hat = (z - sigma_t * v_pred) / alpha_t\n",
        "    x0_hat = (z - sigma_t * v_pred) / (alpha_t + 1e-12)\n",
        "    # deterministic prediction for next z_prev (Euler-Maruyama reverse)\n",
        "    # using discrete form: z_prev = alpha_prev * x0_hat + sigma_prev * noise\n",
        "    if (t_prev_idx==t_idx).all():\n",
        "        # last step (t=0)\n",
        "        return alpha_prev * x0_hat\n",
        "    noise = torch.randn_like(z)\n",
        "    z_prev = alpha_prev * x0_hat + sigma_prev * noise\n",
        "    return z_prev\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unet(num_samples):\n",
        "    B = num_samples\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "    for i in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"UNet Sampling\"):\n",
        "        t = torch.full((B,), i, device=device, dtype=torch.long)\n",
        "        v = unet(z, t)\n",
        "        t_prev = torch.clamp(t-1, min=0)\n",
        "        z = em_step_v(z, v, t, t_prev)\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs + 1)/2, 0, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(num_samples, cfg_guidance=1.0):\n",
        "    B = num_samples\n",
        "    # z prior and class prior\n",
        "    z = torch.randn(B, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "    cls = torch.randn(B, cfg.feat_dim, device=device)\n",
        "    for i in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"REG Sampling\"):\n",
        "        t = torch.full((B,), i, device=device, dtype=torch.long)\n",
        "        # patchify z\n",
        "        z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        # Predict velocity (v) for both patches and class token\n",
        "        v_patch, v_cls, _ = reg_sit(z_patched, cls, t)\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        # apply classifier-free guidance on class token: amplify v_cls\n",
        "        v_cls = v_cls * cfg_guidance\n",
        "        t_prev = torch.clamp(t-1, min=0)\n",
        "        z = em_step_v(z, v_z, t, t_prev)\n",
        "        # update class token by small gradient-step-like update (paper used a small update)\n",
        "        cls = cls - 0.01 * v_cls\n",
        "    imgs = vae.decode(z)\n",
        "    return torch.clamp((imgs + 1)/2, 0, 1)\n",
        "\n",
        "# -------------------------\n",
        "# Evaluation utilities\n",
        "# -------------------------\n",
        "def save_grid(imgs, path, nrow=10):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow, padding=2)\n",
        "def evaluate_models(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "    # prepare real images set\n",
        "    real_path = os.path.join(cfg.out_dir, f\"real_{num_samples}\")\n",
        "    if os.path.exists(real_path): shutil.rmtree(real_path)\n",
        "    os.makedirs(real_path, exist_ok=True)\n",
        "    cnt = 0\n",
        "    for imgs,_ in dataloader:\n",
        "        for im in imgs:\n",
        "            torchvision.utils.save_image((im+1)/2, os.path.join(real_path, f\"{cnt:05d}.png\"))\n",
        "            cnt += 1\n",
        "            if cnt >= num_samples: break\n",
        "        if cnt >= num_samples: break\n",
        "\n",
        "    for model_type in ['reg', 'unet']:\n",
        "        print(f\"\\nGenerating samples for {model_type.upper()}...\")\n",
        "        if model_type == 'reg':\n",
        "            imgs = sample_reg(num_samples, cfg_guidance=cfg.cfg_guidance_scale)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir, 'reg_samples.png'), nrow=10)\n",
        "        else:\n",
        "            imgs = sample_unet(num_samples)\n",
        "            save_grid(imgs, os.path.join(cfg.out_dir, 'unet_samples.png'), nrow=10)\n",
        "\n",
        "        gen_path = os.path.join(cfg.out_dir, f\"{model_type}_eval_{num_samples}\")\n",
        "        if os.path.exists(gen_path): shutil.rmtree(gen_path)\n",
        "        os.makedirs(gen_path, exist_ok=True)\n",
        "        for i,img in enumerate(imgs):\n",
        "            torchvision.utils.save_image(img, os.path.join(gen_path, f\"{i:05d}.png\"))\n",
        "\n",
        "        print(f\"Calculating metrics for {model_type.upper()}...\")\n",
        "        try:\n",
        "            metrics = calculate_metrics(input1=gen_path, input2=real_path, cuda=torch.cuda.is_available(), isc=True, fid=True, kid=False, verbose=False)\n",
        "            results[model_type] = metrics\n",
        "            print(f\"{model_type.upper()} Metrics: FID={metrics['frechet_inception_distance']:.2f}, IS={metrics['inception_score_mean']:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\"Metric calc error:\", e)\n",
        "            results[model_type] = {'frechet_inception_distance': float('inf'), 'inception_score_mean': 0.0}\n",
        "    return results\n",
        "\n",
        "# -------------------------\n",
        "# Main run: train both, then evaluate\n",
        "# -------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*50)\n",
        "    print(\"Starting training (REG + U-Net) - uses v-pred, REG entanglement, EMA, CFG\")\n",
        "    print(\"=\"*50)\n",
        "    train_reg(cfg.epochs)\n",
        "    train_unet(cfg.epochs)\n",
        "    # apply EMA weights before sampling\n",
        "    print(\"Applying EMA to models for sampling...\")\n",
        "    ema_reg.apply_to(reg_model)\n",
        "    ema_unet.apply_to(unet)\n",
        "    print(\"Evaluating samples...\")\n",
        "    results = evaluate_models()\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    for k,m in results.items():\n",
        "        print(f\"{k.upper():<8} | FID: {m.get('frechet_inception_distance', float('inf')):.2f} | IS: {m.get('inception_score_mean',0.0):.2f}\")\n",
        "    print(\"Done. Check\", cfg.out_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "09RWRYgbnOVQ",
        "outputId": "7c660b2f-ec29-481b-99b6-1c6e1ce4bf1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loaded 10000 images (['cat', 'dog'])\n",
            "Pretraining VAE (2 epochs)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "VAE warmup 1/2: 100%|██████████| 78/78 [00:19<00:00,  4.04it/s, loss=0.0123]\n",
            "VAE warmup 2/2: 100%|██████████| 78/78 [00:20<00:00,  3.89it/s, loss=0.0073]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE warmup done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4012335488.py:380: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SiT params: 40355344\n",
            "============================================================\n",
            "START TRAINING: SiT+REG and U-Net (improved config)\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rREG Epoch 1/5:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-4012335488.py:394: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
            "REG Epoch 1/5: 100%|██████████| 78/78 [00:26<00:00,  2.99it/s, loss=0.4775, pred=0.3923, align=0.1704]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 avg 1.4329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2/5: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.3524, pred=0.2891, align=0.1267]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 avg 0.4246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3/5: 100%|██████████| 78/78 [00:27<00:00,  2.83it/s, loss=0.1884, pred=0.1423, align=0.0923]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 avg 0.2435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4/5: 100%|██████████| 78/78 [00:26<00:00,  2.98it/s, loss=0.1629, pred=0.1330, align=0.0598]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 avg 0.1352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5/5: 100%|██████████| 78/78 [00:26<00:00,  2.97it/s, loss=0.1063, pred=0.0617, align=0.0893]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 avg 0.1114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rUNet Epoch 1/5:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-4012335488.py:420: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
            "UNet Epoch 1/5: 100%|██████████| 78/78 [00:06<00:00, 12.27it/s, loss=0.3633]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 avg 0.5942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2/5: 100%|██████████| 78/78 [00:06<00:00, 11.91it/s, loss=0.2509]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 avg 0.2641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3/5: 100%|██████████| 78/78 [00:06<00:00, 12.34it/s, loss=0.1427]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 avg 0.1834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4/5: 100%|██████████| 78/78 [00:06<00:00, 11.90it/s, loss=0.1317]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 avg 0.1432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5/5: 100%|██████████| 78/78 [00:06<00:00, 12.37it/s, loss=0.1122]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 avg 0.1171\n",
            "Applying EMA and evaluating with CFG...\n",
            "Generating reg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics (may take a while)...\n",
            "reg FID=445.54, IS=1.73\n",
            "Generating unet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics (may take a while)...\n",
            "unet FID=445.30, IS=1.70\n",
            "FINAL RESULTS:\n",
            "REG    | FID:   445.54 | IS:   1.73\n",
            "UNET   | FID:   445.30 | IS:   1.70\n",
            "Done. Outputs in ./outputs_improved\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Improved SiT+REG + U-Net (Colab/T4-ready) with fixed latent_hw and AMP\n",
        "\n",
        "import os, math, random, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "class CFG:\n",
        "    # Data\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 64\n",
        "    batch_size = 128\n",
        "    num_workers = 2\n",
        "\n",
        "    # Latent / patch\n",
        "    latent_hw = 16           # FIXED: match VAE output\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2\n",
        "\n",
        "    # SiT\n",
        "    depth = 12\n",
        "    hidden_dim = 512\n",
        "    num_heads = 8\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.1\n",
        "\n",
        "    # U-Net baseline\n",
        "    unet_base = 128\n",
        "    unet_mult = [1,2,2,4]\n",
        "\n",
        "    # Training\n",
        "    timesteps = 250\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-2\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 5\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params\n",
        "    reg_beta = 0.03\n",
        "    reg_lambda = 0.5\n",
        "    feat_dim = 256\n",
        "    align_layer = 6\n",
        "\n",
        "    # Eval / sampling\n",
        "    sample_n = 500\n",
        "    out_dir = \"./outputs_improved\"\n",
        "    ema_decay = 0.999\n",
        "    cfg_guidance_scale = 4.0\n",
        "\n",
        "cfg = CFG()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "torch.manual_seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------- utilities ----------\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return betas.clamp(1e-6, 0.999)\n",
        "\n",
        "# ---------- Scheduler ----------\n",
        "class Scheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        betas = cosine_beta_schedule(timesteps).to(device)\n",
        "        self.betas = betas\n",
        "        self.alphas = 1.0 - betas\n",
        "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.alpha_cumprod_prev = F.pad(self.alpha_cumprod[:-1], (1,0), value=1.0)\n",
        "        self.sqrt_alpha_cumprod = torch.sqrt(self.alpha_cumprod)\n",
        "        self.sqrt_one_minus_alpha_cumprod = torch.sqrt(1.0 - self.alpha_cumprod)\n",
        "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
        "        self.posterior_variance = betas * (1. - self.alpha_cumprod_prev) / (1. - self.alpha_cumprod)\n",
        "\n",
        "    def sample_t(self, n):\n",
        "        return torch.randint(0, self.timesteps, (n,), device=self.device, dtype=torch.long)\n",
        "\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a = self.sqrt_alpha_cumprod[t].view(-1,1,1,1)\n",
        "        b = self.sqrt_one_minus_alpha_cumprod[t].view(-1,1,1,1)\n",
        "        return a * x0 + b * noise, noise\n",
        "\n",
        "    def v_target(self, x0, eps):\n",
        "        return eps\n",
        "\n",
        "scheduler = Scheduler(cfg.timesteps, device)\n",
        "\n",
        "# ---------- Data ----------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    idx_map = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {idx_map[c] for c in classes}\n",
        "    tfs = T.Compose([\n",
        "        T.Resize((cfg.image_size, cfg.image_size)),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=tfs)\n",
        "    indices = [i for i,(_,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# ---------- VAE ----------\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "        # Encoder 64 -> 16\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, latent_channels, 3, 1, 1)\n",
        "        )\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels, 256, 3, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()\n",
        "        )\n",
        "    def encode(self, x): return self.enc(x)\n",
        "    def decode(self, z): return self.dec(z)\n",
        "\n",
        "vae = VAE().to(device)\n",
        "vae_opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Pretraining VAE (2 epochs)...\")\n",
        "vae.train()\n",
        "for ep in range(2):\n",
        "    pbar = tqdm(dataloader, desc=f\"VAE warmup {ep+1}/2\")\n",
        "    for imgs,_ in pbar:\n",
        "        imgs = imgs.to(device)\n",
        "        z = vae.encode(imgs)\n",
        "        recon = vae.decode(z)\n",
        "        loss = F.mse_loss(recon, imgs)\n",
        "        vae_opt.zero_grad(); loss.backward(); vae_opt.step()\n",
        "        pbar.set_postfix({'loss':f\"{loss.item():.4f}\"})\n",
        "print(\"VAE warmup done\")\n",
        "\n",
        "# ---------- timestep embedding ----------\n",
        "def timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(-math.log(max_period) * torch.arange(half, dtype=torch.float32) / half).to(device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2: emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n",
        "    return emb\n",
        "\n",
        "# ---------- Transformer blocks ----------\n",
        "class MHA(nn.Module):\n",
        "    def __init__(self, dim, heads): super().__init__(); self.heads=heads; self.to_qkv=nn.Linear(dim,dim*3,bias=False); self.scale=(dim//heads)**-0.5; self.to_out=nn.Linear(dim,dim)\n",
        "    def forward(self,x):\n",
        "        B,N,C=x.shape\n",
        "        qkv=self.to_qkv(x).reshape(B,N,3,self.heads,C//self.heads).permute(2,0,3,1,4)\n",
        "        q,k,v=qkv[0],qkv[1],qkv[2]\n",
        "        attn=(q@k.transpose(-2,-1))*self.scale\n",
        "        attn=attn.softmax(dim=-1)\n",
        "        out=(attn@v).transpose(1,2).reshape(B,N,C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm1=nn.LayerNorm(dim)\n",
        "        self.attn=MHA(dim, cfg.num_heads)\n",
        "        self.norm2=nn.LayerNorm(dim)\n",
        "        mlp_dim=int(dim*cfg.mlp_ratio)\n",
        "        self.mlp=nn.Sequential(nn.Linear(dim,mlp_dim), nn.GELU(), nn.Linear(mlp_dim,dim))\n",
        "    def forward(self,x):\n",
        "        x=x+self.attn(self.norm1(x))\n",
        "        x=x+self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# ---------- REGSiT ----------\n",
        "class REGSiT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_dim=cfg.hidden_dim\n",
        "        self.patch_embed=nn.Linear(cfg.latent_patch_dim,self.hidden_dim)\n",
        "        self.class_embed=nn.Linear(cfg.feat_dim,self.hidden_dim)\n",
        "        self.pos=nn.Parameter(torch.zeros(1,cfg.num_patches+1,self.hidden_dim))\n",
        "        self.time_mlp=nn.Sequential(nn.Linear(self.hidden_dim,self.hidden_dim*4), nn.SiLU(), nn.Linear(self.hidden_dim*4,self.hidden_dim))\n",
        "        self.blocks=nn.ModuleList([TransformerBlock(self.hidden_dim) for _ in range(cfg.depth)])\n",
        "        self.norm=nn.LayerNorm(self.hidden_dim)\n",
        "        self.patch_out=nn.Linear(self.hidden_dim,cfg.latent_patch_dim)\n",
        "        self.cls_out=nn.Linear(self.hidden_dim,cfg.feat_dim)\n",
        "        self.align_proj=nn.Linear(self.hidden_dim,cfg.feat_dim)\n",
        "        self._init_weights()\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.zeros_(m.bias); nn.init.ones_(m.weight)\n",
        "    def forward(self, z_patched, cls_token, t):\n",
        "        B=z_patched.shape[0]\n",
        "        patch_emb=self.patch_embed(z_patched)\n",
        "        cls_emb=self.class_embed(cls_token).unsqueeze(1)\n",
        "        x=torch.cat([cls_emb,patch_emb],dim=1)+self.pos\n",
        "        t_emb=timestep_embedding(t,self.hidden_dim).to(x.device)\n",
        "        t_emb=self.time_mlp(t_emb).unsqueeze(1)\n",
        "        x=x+t_emb\n",
        "        intermediate=None\n",
        "        for i,blk in enumerate(self.blocks):\n",
        "            x=blk(x)\n",
        "            if i==cfg.align_layer: intermediate=x\n",
        "        x=self.norm(x)\n",
        "        cls_pred=self.cls_out(x[:,0])\n",
        "        patch_pred=self.patch_out(x[:,1:])\n",
        "        h_phi=self.align_proj(intermediate) if intermediate is not None else None\n",
        "        return patch_pred, cls_pred, h_phi\n",
        "\n",
        "reg_sit=REGSiT().to(device)\n",
        "print(\"SiT params:\", sum(p.numel() for p in reg_sit.parameters()))\n",
        "\n",
        "# ---------- rest of code (VisionFoundation, REGModel, UNet, EMA, training, sampling, evaluation) ----------\n",
        "# Keep your original code, but everywhere `latent_hw` is used, it is now 16\n",
        "# Update GradScaler / autocast:\n",
        "# scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "# with torch.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "\n",
        "\n",
        "# ---------- Vision foundation (small frozen conv, produce class token and patch targets) ----------\n",
        "class VisionFoundation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.proj = nn.Linear(128, cfg.feat_dim)\n",
        "        for p in self.parameters(): p.requires_grad = False\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        f = self.backbone(x).view(B,-1)\n",
        "        feat = F.normalize(self.proj(f), dim=-1)\n",
        "        cls = feat\n",
        "        patch = feat.unsqueeze(1).repeat(1, cfg.num_patches, 1)\n",
        "        return cls, patch\n",
        "\n",
        "vision = VisionFoundation().to(device)\n",
        "\n",
        "# ---------- REG wrapper computing loss ----------\n",
        "class REGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "    def forward(self, imgs, t_idx):\n",
        "        B = imgs.shape[0]\n",
        "        z_star = self.vae.encode(imgs)\n",
        "        cls_star, f_star = self.vision.extract(imgs)\n",
        "        eps_z = torch.randn_like(z_star)\n",
        "        eps_cls = torch.randn_like(cls_star)\n",
        "        zt, _ = scheduler.add_noise(z_star, t_idx, noise=eps_z)\n",
        "        # class noise: use same coef forms as scheduler\n",
        "        a = scheduler.sqrt_alpha_cumprod[t_idx].view(B,1)\n",
        "        b = scheduler.sqrt_one_minus_alpha_cumprod[t_idx].view(B,1)\n",
        "        clst = a * cls_star + b * eps_cls\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t_idx)\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        v_target_z = scheduler.v_target(z_star, eps_z)\n",
        "        v_target_cls = scheduler.v_target(cls_star, eps_cls)\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.reg_beta * F.mse_loss(v_cls, v_target_cls)\n",
        "        loss_align = torch.tensor(0.0, device=device)\n",
        "        if h_phi is not None:\n",
        "            y_star = torch.cat([cls_star.unsqueeze(1), f_star], dim=1)\n",
        "            loss_align = F.mse_loss(h_phi, y_star.detach())\n",
        "        total_loss = loss_pred + cfg.reg_lambda * loss_align\n",
        "        return total_loss, loss_pred.detach().item(), loss_align.detach().item()\n",
        "\n",
        "reg_model = REGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# ---------- U-Net baseline (wider) ----------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, 1, 1), nn.GroupNorm(8, out_ch), nn.SiLU())\n",
        "    def forward(self,x): return self.net(x)\n",
        "\n",
        "class UNetSmall(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = cfg.unet_base\n",
        "        self.time_dim = 256\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(self.time_dim, self.time_dim*4), nn.SiLU(), nn.Linear(self.time_dim*4, self.time_dim))\n",
        "        chs = [base * m for m in cfg.unet_mult]\n",
        "        self.enc1 = ConvBlock(cfg.latent_channels, chs[0])\n",
        "        self.enc2 = ConvBlock(chs[0], chs[1])\n",
        "        self.enc3 = ConvBlock(chs[1], chs[2])\n",
        "        self.mid = ConvBlock(chs[2], chs[2])\n",
        "        self.dec1 = nn.ConvTranspose2d(chs[2], chs[1], 4, 2, 1)\n",
        "        self.dec2 = nn.ConvTranspose2d(chs[1]*2, chs[0], 4, 2, 1)\n",
        "        self.out = nn.Conv2d(chs[0]*2, cfg.latent_channels, 3, 1, 1)\n",
        "        self.time_projs = nn.ModuleList([nn.Linear(self.time_dim, c) for c in (chs[0], chs[1], chs[2], chs[2], chs[1], chs[0])])\n",
        "    def forward(self, x, t):\n",
        "        B = x.shape[0]\n",
        "        t_emb = timestep_embedding(t, self.time_dim).to(x.device)\n",
        "        t_emb = self.time_mlp(t_emb)\n",
        "        x1 = F.silu(self.enc1(x) + self.time_projs[0](t_emb).view(B, -1, 1, 1))\n",
        "        x2 = F.silu(self.enc2(F.avg_pool2d(x1,2)) + self.time_projs[1](t_emb).view(B, -1, 1, 1))\n",
        "        x3 = F.silu(self.enc3(F.avg_pool2d(x2,2)) + self.time_projs[2](t_emb).view(B, -1, 1, 1))\n",
        "        m = F.silu(self.mid(x3) + self.time_projs[3](t_emb).view(B, -1, 1, 1))\n",
        "        d1 = F.silu(self.dec1(m) + self.time_projs[4](t_emb).view(B, -1, 1, 1))\n",
        "        d1 = torch.cat([d1, x2], dim=1)\n",
        "        d2 = F.silu(self.dec2(d1) + self.time_projs[5](t_emb).view(B, -1, 1, 1))\n",
        "        d2 = torch.cat([d2, x1], dim=1)\n",
        "        out = self.out(d2)\n",
        "        return out\n",
        "\n",
        "unet = UNetSmall().to(device)\n",
        "\n",
        "# ---------- Optimizers, EMA, AMP ----------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        for k, v in model.state_dict().items():\n",
        "            if v.dtype.is_floating_point:  # only float tensors\n",
        "                self.shadow[k] = v.detach().cpu().clone()\n",
        "\n",
        "    def update(self, model):\n",
        "        for k, v in model.state_dict().items():\n",
        "            if v.dtype.is_floating_point:\n",
        "                self.shadow[k].mul_(self.decay)\n",
        "                self.shadow[k].add_(v.detach().cpu(), alpha=1.0 - self.decay)\n",
        "\n",
        "    def apply_to(self, model):\n",
        "        ms = model.state_dict()\n",
        "        for k, v in self.shadow.items():\n",
        "            ms[k].copy_(v.to(ms[k].device))\n",
        "\n",
        "ema_reg = EMA(reg_model, cfg.ema_decay)\n",
        "ema_unet = EMA(unet, cfg.ema_decay)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "# ---------- Training loops ----------\n",
        "reg_loss_hist, unet_loss_hist = [], []\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for ep in range(epochs):\n",
        "        total, tot_pred, tot_align = 0.0, 0.0, 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"REG Epoch {ep+1}/{epochs}\")\n",
        "        for imgs,_ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            t_idx = scheduler.sample_t(B)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                loss, lp, la = reg_model(imgs, t_idx)\n",
        "            opt_reg.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_reg)\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_reg); scaler.update()\n",
        "            ema_reg.update(reg_model)\n",
        "            total += loss.item(); tot_pred += lp; tot_align += la\n",
        "            pbar.set_postfix({'loss':f\"{loss.item():.4f}\", 'pred':f\"{lp:.4f}\", 'align':f\"{la:.4f}\"})\n",
        "        avg = total / len(dataloader)\n",
        "        reg_loss_hist.append(avg)\n",
        "        print(f\"REG Epoch {ep+1} avg {avg:.4f}\")\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for ep in range(epochs):\n",
        "        total = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"UNet Epoch {ep+1}/{epochs}\")\n",
        "        for imgs,_ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            with torch.no_grad(): z_star = vae.encode(imgs)\n",
        "            t_idx = scheduler.sample_t(B)\n",
        "            eps = torch.randn_like(z_star)\n",
        "            zt, _ = scheduler.add_noise(z_star, t_idx, noise=eps)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                v_pred = unet(zt, t_idx)\n",
        "                loss = F.mse_loss(v_pred, eps)\n",
        "            opt_unet.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_unet)\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_unet); scaler.update()\n",
        "            ema_unet.update(unet)\n",
        "            total += loss.item()\n",
        "            pbar.set_postfix({'loss':f\"{loss.item():.4f}\"})\n",
        "        avg = total / len(dataloader)\n",
        "        unet_loss_hist.append(avg)\n",
        "        print(f\"UNet Epoch {ep+1} avg {avg:.4f}\")\n",
        "\n",
        "# ---------- EM sampler (v-pred) ----------\n",
        "@torch.no_grad()\n",
        "def em_update(z, v_pred, t_idx, t_prev_idx):\n",
        "    # z: (B,C,H,W), v_pred: same\n",
        "    alpha = scheduler.alpha_cumprod[t_idx].view(-1,1,1,1)\n",
        "    alpha_prev = scheduler.alpha_cumprod[t_prev_idx].view(-1,1,1,1)\n",
        "    sigma = scheduler.sqrt_one_minus_alpha_cumprod[t_idx].view(-1,1,1,1)\n",
        "    sigma_prev = scheduler.sqrt_one_minus_alpha_cumprod[t_prev_idx].view(-1,1,1,1)\n",
        "    # x0_hat estimate for v-pred: x0 = (z - sigma * v) / alpha\n",
        "    x0_hat = (z - sigma * v_pred) / (alpha + 1e-12)\n",
        "    if (t_prev_idx==t_idx).all():\n",
        "        return alpha_prev * x0_hat\n",
        "    noise = torch.randn_like(z)\n",
        "    z_prev = alpha_prev * x0_hat + sigma_prev * noise\n",
        "    return z_prev\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unet(n, batch_size=64):\n",
        "    all_imgs = []\n",
        "    for i in range(0, n, batch_size):\n",
        "        b = min(batch_size, n - i)\n",
        "        z = torch.randn(b, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "        for t in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"UNet Sampling\", leave=False):\n",
        "            t_idx = torch.full((b,), t, device=device, dtype=torch.long)\n",
        "            v = unet(z, t_idx)\n",
        "            t_prev = torch.clamp(t_idx - 1, min=0)\n",
        "            z = em_update(z, v, t_idx, t_prev)\n",
        "        imgs = vae.decode(z)\n",
        "        all_imgs.append(torch.clamp((imgs + 1)/2, 0, 1).cpu())\n",
        "    return torch.cat(all_imgs, dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(n, cfg_guidance=cfg.cfg_guidance_scale, batch_size=64):\n",
        "    all_imgs = []\n",
        "    for i in range(0, n, batch_size):\n",
        "        b = min(batch_size, n - i)\n",
        "        z = torch.randn(b, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "        cls = torch.randn(b, cfg.feat_dim, device=device)\n",
        "        for t in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"REG Sampling\", leave=False):\n",
        "            t_idx = torch.full((b,), t, device=device, dtype=torch.long)\n",
        "            z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                                  p=cfg.patch_size, q=cfg.patch_size,\n",
        "                                  h=cfg.latent_hw//cfg.patch_size,\n",
        "                                  w=cfg.latent_hw//cfg.patch_size)\n",
        "            v_patch, v_cls, _ = reg_sit(z_patched, cls, t_idx)\n",
        "            v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                            p=cfg.patch_size, q=cfg.patch_size,\n",
        "                            h=cfg.latent_hw//cfg.patch_size,\n",
        "                            w=cfg.latent_hw//cfg.patch_size,\n",
        "                            c=cfg.latent_channels)\n",
        "            # classifier-free guidance: scale v_cls\n",
        "            v_cls = v_cls * cfg_guidance\n",
        "            t_prev = torch.clamp(t_idx - 1, min=0)\n",
        "            z = em_update(z, v_z, t_idx, t_prev)\n",
        "            # update class token\n",
        "            cls = cls - 0.01 * v_cls\n",
        "        imgs = vae.decode(z)\n",
        "        all_imgs.append(torch.clamp((imgs + 1)/2, 0, 1).cpu())\n",
        "    return torch.cat(all_imgs, dim=0)\n",
        "\n",
        "# ---------- Evaluation ----------\n",
        "def save_grid(imgs, path, nrow=10):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow, padding=2)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "    real_dir = os.path.join(cfg.out_dir, f\"real_{num_samples}\")\n",
        "    if os.path.exists(real_dir): shutil.rmtree(real_dir)\n",
        "    os.makedirs(real_dir, exist_ok=True)\n",
        "    cnt = 0\n",
        "    for imgs,_ in dataloader:\n",
        "        for im in imgs:\n",
        "            torchvision.utils.save_image((im+1)/2, os.path.join(real_dir, f\"{cnt:05d}.png\"))\n",
        "            cnt += 1\n",
        "            if cnt >= num_samples: break\n",
        "        if cnt >= num_samples: break\n",
        "\n",
        "    for typ in ['reg','unet']:\n",
        "        print(\"Generating\", typ)\n",
        "        if typ == 'reg':\n",
        "            ema_reg.apply_to(reg_model)\n",
        "            gen = sample_reg(num_samples, cfg_guidance=cfg.cfg_guidance_scale, batch_size=64)\n",
        "            save_grid(gen, os.path.join(cfg.out_dir, \"reg_samples.png\"), nrow=10)\n",
        "        else:\n",
        "            ema_unet.apply_to(unet)\n",
        "            gen = sample_unet(num_samples, batch_size=64)\n",
        "            save_grid(gen, os.path.join(cfg.out_dir, \"unet_samples.png\"), nrow=10)\n",
        "        gen_dir = os.path.join(cfg.out_dir, f\"{typ}_gen\")\n",
        "        if os.path.exists(gen_dir): shutil.rmtree(gen_dir)\n",
        "        os.makedirs(gen_dir, exist_ok=True)\n",
        "        for i,im in enumerate(gen):\n",
        "            torchvision.utils.save_image(im, os.path.join(gen_dir, f\"{i:05d}.png\"))\n",
        "        print(\"Calculating metrics (may take a while)...\")\n",
        "        try:\n",
        "            metrics = calculate_metrics(input1=gen_dir, input2=real_dir, cuda=torch.cuda.is_available(), isc=True, fid=True, kid=False, verbose=False)\n",
        "            results[typ] = metrics\n",
        "            print(f\"{typ} FID={metrics['frechet_inception_distance']:.2f}, IS={metrics['inception_score_mean']:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\"Metric error:\", e)\n",
        "            results[typ] = {'frechet_inception_distance': float('inf'), 'inception_score_mean': 0.0}\n",
        "    return results\n",
        "\n",
        "# ---------- Plot losses ----------\n",
        "def plot_losses():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    if reg_loss_hist: plt.plot(reg_loss_hist, label='SiT+REG')\n",
        "    if unet_loss_hist: plt.plot(unet_loss_hist, label='U-Net')\n",
        "    plt.legend(); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.grid(True)\n",
        "    plt.savefig(os.path.join(cfg.out_dir, \"losses.png\"), dpi=200)\n",
        "\n",
        "# ---------- MAIN ----------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\"START TRAINING: SiT+REG and U-Net (improved config)\")\n",
        "    print(\"=\"*60)\n",
        "    # Train\n",
        "    train_reg(cfg.epochs)\n",
        "    train_unet(cfg.epochs)\n",
        "    plot_losses()\n",
        "    print(\"Applying EMA and evaluating with CFG...\")\n",
        "    ema_reg.apply_to(reg_model)\n",
        "    ema_unet.apply_to(unet)\n",
        "    results = evaluate(cfg.sample_n)\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    for k,v in results.items():\n",
        "        fid = v.get('frechet_inception_distance', float('inf'))\n",
        "        is_ = v.get('inception_score_mean', 0.0)\n",
        "        print(f\"{k.upper():<6} | FID: {fid:8.2f} | IS: {is_:6.2f}\")\n",
        "    print(\"Done. Outputs in\", cfg.out_dir)\n",
        "\n",
        "# ---------- END ----------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "PAni0zuMtNVt",
        "outputId": "41664ba4-e2b7-4ac5-923a-5dd695de5b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Loaded 10000 images (['cat', 'dog'])\n",
            "Pretraining VAE (2 epochs)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "VAE warmup 1/2: 100%|██████████| 78/78 [00:21<00:00,  3.70it/s, loss=0.0122]\n",
            "VAE warmup 2/2: 100%|██████████| 78/78 [00:19<00:00,  4.03it/s, loss=0.0073]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VAE warmup done\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1031646778.py:380: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SiT params: 40355344\n",
            "============================================================\n",
            "START TRAINING: SiT+REG and U-Net (improved config)\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 1/100:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-1031646778.py:394: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
            "REG Epoch 1/100: 100%|██████████| 78/78 [00:26<00:00,  3.00it/s, loss=0.5023, pred=0.4297, align=0.1452]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 1 avg 1.4225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 2/100: 100%|██████████| 78/78 [00:27<00:00,  2.89it/s, loss=0.3965, pred=0.3229, align=0.1472]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 2 avg 0.4177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 3/100: 100%|██████████| 78/78 [00:27<00:00,  2.88it/s, loss=0.2222, pred=0.1472, align=0.1499]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 3 avg 0.2982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 4/100: 100%|██████████| 78/78 [00:26<00:00,  2.97it/s, loss=0.1475, pred=0.1126, align=0.0699]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 4 avg 0.1405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 5/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0944, pred=0.0621, align=0.0645]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 5 avg 0.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 6/100: 100%|██████████| 78/78 [00:26<00:00,  2.95it/s, loss=0.0753, pred=0.0547, align=0.0413]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 6 avg 0.0842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 7/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0907, pred=0.0670, align=0.0475]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 7 avg 0.0790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 8/100: 100%|██████████| 78/78 [00:26<00:00,  2.90it/s, loss=0.0859, pred=0.0576, align=0.0565]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 8 avg 0.0800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 9/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0649, pred=0.0461, align=0.0376]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 9 avg 0.0752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 10/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0708, pred=0.0560, align=0.0297]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 10 avg 0.0681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 11/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0623, pred=0.0519, align=0.0207]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 11 avg 0.0686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 12/100: 100%|██████████| 78/78 [00:26<00:00,  2.95it/s, loss=0.0657, pred=0.0510, align=0.0294]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 12 avg 0.0644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 13/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0553, pred=0.0380, align=0.0347]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 13 avg 0.0638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 14/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0512, pred=0.0395, align=0.0232]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 14 avg 0.0679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 15/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0475, pred=0.0385, align=0.0181]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 15 avg 0.0587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 16/100: 100%|██████████| 78/78 [00:26<00:00,  2.90it/s, loss=0.0626, pred=0.0467, align=0.0317]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 16 avg 0.0656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 17/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0641, pred=0.0559, align=0.0164]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 17 avg 0.0579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 18/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0478, pred=0.0392, align=0.0172]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 18 avg 0.0541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 19/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0455, pred=0.0373, align=0.0165]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 19 avg 0.0497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 20/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0735, pred=0.0598, align=0.0273]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 20 avg 0.0554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 21/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0730, pred=0.0455, align=0.0549]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 21 avg 0.0564\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 22/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0444, pred=0.0341, align=0.0207]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 22 avg 0.0488\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 23/100: 100%|██████████| 78/78 [00:26<00:00,  2.90it/s, loss=0.0479, pred=0.0389, align=0.0180]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 23 avg 0.0506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 24/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0373, pred=0.0302, align=0.0143]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 24 avg 0.0494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 25/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0386, pred=0.0301, align=0.0169]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 25 avg 0.0464\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 26/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0378, pred=0.0295, align=0.0166]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 26 avg 0.0443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 27/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0426, pred=0.0337, align=0.0179]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 27 avg 0.0467\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 28/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0566, pred=0.0367, align=0.0398]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 28 avg 0.0528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 29/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0382, pred=0.0298, align=0.0168]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 29 avg 0.0452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 30/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0367, pred=0.0298, align=0.0137]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 30 avg 0.0425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 31/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0871, pred=0.0534, align=0.0674]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 31 avg 0.0446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 32/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0383, pred=0.0239, align=0.0288]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 32 avg 0.0384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 33/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0576, pred=0.0342, align=0.0468]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 33 avg 0.0431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 34/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0389, pred=0.0328, align=0.0121]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 34 avg 0.0381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 35/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0444, pred=0.0281, align=0.0328]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 35 avg 0.0381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 36/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0230, pred=0.0179, align=0.0101]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 36 avg 0.0361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 37/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0220, pred=0.0182, align=0.0076]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 37 avg 0.0316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 38/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0380, pred=0.0302, align=0.0155]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 38 avg 0.0320\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 39/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0219, pred=0.0166, align=0.0106]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 39 avg 0.0318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 40/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0184, pred=0.0147, align=0.0073]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 40 avg 0.0255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 41/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0288, pred=0.0241, align=0.0094]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 41 avg 0.0289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 42/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0368, pred=0.0253, align=0.0231]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 42 avg 0.0285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 43/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0215, pred=0.0170, align=0.0090]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 43 avg 0.0251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 44/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0227, pred=0.0163, align=0.0129]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 44 avg 0.0231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 45/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0206, pred=0.0160, align=0.0091]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 45 avg 0.0255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 46/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0497, pred=0.0304, align=0.0387]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 46 avg 0.0257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 47/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0245, pred=0.0139, align=0.0212]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 47 avg 0.0277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 48/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0254, pred=0.0197, align=0.0115]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 48 avg 0.0208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 49/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0142, pred=0.0115, align=0.0054]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 49 avg 0.0195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 50/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0139, pred=0.0107, align=0.0065]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 50 avg 0.0181\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 51/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0240, pred=0.0143, align=0.0194]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 51 avg 0.0183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 52/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0176, pred=0.0132, align=0.0090]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 52 avg 0.0212\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 53/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0342, pred=0.0287, align=0.0109]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 53 avg 0.0207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 54/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0190, pred=0.0152, align=0.0076]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 54 avg 0.0214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 55/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0109, pred=0.0081, align=0.0056]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 55 avg 0.0178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 56/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0197, pred=0.0143, align=0.0107]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 56 avg 0.0175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 57/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0182, pred=0.0106, align=0.0151]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 57 avg 0.0215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 58/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0174, pred=0.0100, align=0.0147]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 58 avg 0.0179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 59/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0174, pred=0.0132, align=0.0084]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 59 avg 0.0193\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 60/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0142, pred=0.0099, align=0.0085]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 60 avg 0.0183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 61/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0109, pred=0.0079, align=0.0061]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 61 avg 0.0167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 62/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0119, pred=0.0086, align=0.0067]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 62 avg 0.0162\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 63/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0172, pred=0.0139, align=0.0065]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 63 avg 0.0153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 64/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0132, pred=0.0082, align=0.0099]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 64 avg 0.0183\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 65/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0130, pred=0.0108, align=0.0045]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 65 avg 0.0131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 66/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0084, pred=0.0054, align=0.0061]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 66 avg 0.0117\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 67/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0135, pred=0.0070, align=0.0131]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 67 avg 0.0139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 68/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0113, pred=0.0096, align=0.0035]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 68 avg 0.0122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 69/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0102, pred=0.0077, align=0.0049]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 69 avg 0.0125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 70/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0152, pred=0.0116, align=0.0072]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 70 avg 0.0132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 71/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0163, pred=0.0120, align=0.0086]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 71 avg 0.0155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 72/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0110, pred=0.0086, align=0.0048]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 72 avg 0.0159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 73/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0119, pred=0.0094, align=0.0050]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 73 avg 0.0129\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 74/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0218, pred=0.0134, align=0.0167]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 74 avg 0.0156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 75/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0098, pred=0.0066, align=0.0063]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 75 avg 0.0134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 76/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0284, pred=0.0221, align=0.0126]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 76 avg 0.0156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 77/100: 100%|██████████| 78/78 [00:26<00:00,  2.90it/s, loss=0.0189, pred=0.0096, align=0.0185]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 77 avg 0.0202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 78/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0109, pred=0.0089, align=0.0041]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 78 avg 0.0131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 79/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0096, pred=0.0078, align=0.0037]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 79 avg 0.0100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 80/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0092, pred=0.0072, align=0.0041]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 80 avg 0.0102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 81/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0187, pred=0.0142, align=0.0091]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 81 avg 0.0136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 82/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0212, pred=0.0188, align=0.0049]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 82 avg 0.0114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 83/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0104, pred=0.0085, align=0.0037]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 83 avg 0.0124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 84/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0179, pred=0.0125, align=0.0107]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 84 avg 0.0122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 85/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0140, pred=0.0124, align=0.0032]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 85 avg 0.0097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 86/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0118, pred=0.0093, align=0.0052]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 86 avg 0.0116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 87/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0111, pred=0.0079, align=0.0064]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 87 avg 0.0110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 88/100: 100%|██████████| 78/78 [00:26<00:00,  2.94it/s, loss=0.0094, pred=0.0076, align=0.0037]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 88 avg 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 89/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0163, pred=0.0131, align=0.0066]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 89 avg 0.0110\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 90/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0137, pred=0.0099, align=0.0076]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 90 avg 0.0125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 91/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0075, pred=0.0055, align=0.0040]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 91 avg 0.0105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 92/100: 100%|██████████| 78/78 [00:26<00:00,  2.90it/s, loss=0.0112, pred=0.0075, align=0.0075]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 92 avg 0.0092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 93/100: 100%|██████████| 78/78 [00:26<00:00,  2.92it/s, loss=0.0131, pred=0.0105, align=0.0052]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 93 avg 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 94/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0061, pred=0.0043, align=0.0035]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 94 avg 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 95/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0069, pred=0.0055, align=0.0029]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 95 avg 0.0069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 96/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0091, pred=0.0071, align=0.0039]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 96 avg 0.0101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 97/100: 100%|██████████| 78/78 [00:26<00:00,  2.91it/s, loss=0.0129, pred=0.0097, align=0.0063]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 97 avg 0.0147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 98/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0100, pred=0.0078, align=0.0044]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 98 avg 0.0118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 99/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0064, pred=0.0046, align=0.0035]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 99 avg 0.0146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "REG Epoch 100/100: 100%|██████████| 78/78 [00:26<00:00,  2.93it/s, loss=0.0063, pred=0.0049, align=0.0028]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "REG Epoch 100 avg 0.0097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1/100:   0%|          | 0/78 [00:00<?, ?it/s]/tmp/ipython-input-1031646778.py:420: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
            "UNet Epoch 1/100: 100%|██████████| 78/78 [00:07<00:00, 11.11it/s, loss=0.2352]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 1 avg 0.5069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2/100: 100%|██████████| 78/78 [00:06<00:00, 12.75it/s, loss=0.1495]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 2 avg 0.1744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3/100: 100%|██████████| 78/78 [00:07<00:00, 10.94it/s, loss=0.0964]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 3 avg 0.1153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4/100: 100%|██████████| 78/78 [00:06<00:00, 12.56it/s, loss=0.0685]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 4 avg 0.0868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5/100: 100%|██████████| 78/78 [00:07<00:00, 10.83it/s, loss=0.0653]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 5 avg 0.0772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6/100: 100%|██████████| 78/78 [00:06<00:00, 12.72it/s, loss=0.0604]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 6 avg 0.0656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7/100: 100%|██████████| 78/78 [00:07<00:00, 10.91it/s, loss=0.0570]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 7 avg 0.0594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8/100: 100%|██████████| 78/78 [00:06<00:00, 12.62it/s, loss=0.0508]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 8 avg 0.0538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9/100: 100%|██████████| 78/78 [00:07<00:00, 10.87it/s, loss=0.0465]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 9 avg 0.0483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10/100: 100%|██████████| 78/78 [00:06<00:00, 12.53it/s, loss=0.0447]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 10 avg 0.0430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11/100: 100%|██████████| 78/78 [00:07<00:00, 10.94it/s, loss=0.0505]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 11 avg 0.0382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12/100: 100%|██████████| 78/78 [00:06<00:00, 12.57it/s, loss=0.0362]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 12 avg 0.0351\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13/100: 100%|██████████| 78/78 [00:07<00:00, 11.09it/s, loss=0.0317]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 13 avg 0.0313\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14/100: 100%|██████████| 78/78 [00:06<00:00, 12.03it/s, loss=0.0248]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 14 avg 0.0274\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15/100: 100%|██████████| 78/78 [00:06<00:00, 11.52it/s, loss=0.0265]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 15 avg 0.0255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16/100: 100%|██████████| 78/78 [00:06<00:00, 11.74it/s, loss=0.0203]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 16 avg 0.0227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17/100: 100%|██████████| 78/78 [00:06<00:00, 11.89it/s, loss=0.0233]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 17 avg 0.0223\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18/100: 100%|██████████| 78/78 [00:06<00:00, 11.37it/s, loss=0.0201]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 18 avg 0.0206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19/100: 100%|██████████| 78/78 [00:06<00:00, 12.30it/s, loss=0.0184]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 19 avg 0.0185\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20/100: 100%|██████████| 78/78 [00:07<00:00, 11.10it/s, loss=0.0158]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 20 avg 0.0174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 21/100: 100%|██████████| 78/78 [00:06<00:00, 12.73it/s, loss=0.0169]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 21 avg 0.0173\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 22/100: 100%|██████████| 78/78 [00:07<00:00, 10.97it/s, loss=0.0147]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 22 avg 0.0159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 23/100: 100%|██████████| 78/78 [00:06<00:00, 12.54it/s, loss=0.0131]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 23 avg 0.0148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 24/100: 100%|██████████| 78/78 [00:07<00:00, 10.99it/s, loss=0.0120]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 24 avg 0.0139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 25/100: 100%|██████████| 78/78 [00:06<00:00, 12.70it/s, loss=0.0122]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 25 avg 0.0127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 26/100: 100%|██████████| 78/78 [00:06<00:00, 11.20it/s, loss=0.0115]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 26 avg 0.0128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 27/100: 100%|██████████| 78/78 [00:06<00:00, 12.67it/s, loss=0.0105]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 27 avg 0.0120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 28/100: 100%|██████████| 78/78 [00:07<00:00, 10.98it/s, loss=0.0099]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 28 avg 0.0109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 29/100: 100%|██████████| 78/78 [00:06<00:00, 12.66it/s, loss=0.0100]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 29 avg 0.0108\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 30/100: 100%|██████████| 78/78 [00:06<00:00, 11.16it/s, loss=0.0094]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 30 avg 0.0104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 31/100: 100%|██████████| 78/78 [00:06<00:00, 12.71it/s, loss=0.0087]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 31 avg 0.0102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 32/100: 100%|██████████| 78/78 [00:07<00:00, 11.03it/s, loss=0.0084]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 32 avg 0.0099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 33/100: 100%|██████████| 78/78 [00:06<00:00, 12.79it/s, loss=0.0085]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 33 avg 0.0091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 34/100: 100%|██████████| 78/78 [00:07<00:00, 11.06it/s, loss=0.0078]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 34 avg 0.0088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 35/100: 100%|██████████| 78/78 [00:06<00:00, 12.95it/s, loss=0.0076]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 35 avg 0.0081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 36/100: 100%|██████████| 78/78 [00:07<00:00, 11.03it/s, loss=0.0092]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 36 avg 0.0080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 37/100: 100%|██████████| 78/78 [00:06<00:00, 12.62it/s, loss=0.0066]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 37 avg 0.0075\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 38/100: 100%|██████████| 78/78 [00:07<00:00, 11.09it/s, loss=0.0074]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 38 avg 0.0073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 39/100: 100%|██████████| 78/78 [00:06<00:00, 12.58it/s, loss=0.0068]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 39 avg 0.0071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 40/100: 100%|██████████| 78/78 [00:06<00:00, 11.30it/s, loss=0.0061]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 40 avg 0.0074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 41/100: 100%|██████████| 78/78 [00:06<00:00, 12.25it/s, loss=0.0061]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 41 avg 0.0065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 42/100: 100%|██████████| 78/78 [00:06<00:00, 11.61it/s, loss=0.0052]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 42 avg 0.0065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 43/100: 100%|██████████| 78/78 [00:06<00:00, 11.67it/s, loss=0.0052]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 43 avg 0.0062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 44/100: 100%|██████████| 78/78 [00:06<00:00, 12.23it/s, loss=0.0075]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 44 avg 0.0060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 45/100: 100%|██████████| 78/78 [00:06<00:00, 11.39it/s, loss=0.0094]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 45 avg 0.0059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 46/100: 100%|██████████| 78/78 [00:06<00:00, 12.38it/s, loss=0.0059]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 46 avg 0.0057\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 47/100: 100%|██████████| 78/78 [00:07<00:00, 11.01it/s, loss=0.0059]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 47 avg 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 48/100: 100%|██████████| 78/78 [00:06<00:00, 12.73it/s, loss=0.0043]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 48 avg 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 49/100: 100%|██████████| 78/78 [00:07<00:00, 11.03it/s, loss=0.0046]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 49 avg 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 50/100: 100%|██████████| 78/78 [00:06<00:00, 12.70it/s, loss=0.0052]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 50 avg 0.0051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 51/100: 100%|██████████| 78/78 [00:07<00:00, 10.93it/s, loss=0.0044]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 51 avg 0.0049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 52/100: 100%|██████████| 78/78 [00:06<00:00, 12.70it/s, loss=0.0036]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 52 avg 0.0047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 53/100: 100%|██████████| 78/78 [00:07<00:00, 11.11it/s, loss=0.0051]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 53 avg 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 54/100: 100%|██████████| 78/78 [00:06<00:00, 12.78it/s, loss=0.0059]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 54 avg 0.0045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 55/100: 100%|██████████| 78/78 [00:07<00:00, 10.89it/s, loss=0.0056]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 55 avg 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 56/100: 100%|██████████| 78/78 [00:06<00:00, 12.67it/s, loss=0.0056]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 56 avg 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 57/100: 100%|██████████| 78/78 [00:06<00:00, 11.17it/s, loss=0.0042]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 57 avg 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 58/100: 100%|██████████| 78/78 [00:06<00:00, 12.82it/s, loss=0.0049]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 58 avg 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 59/100: 100%|██████████| 78/78 [00:07<00:00, 11.09it/s, loss=0.0047]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 59 avg 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 60/100: 100%|██████████| 78/78 [00:06<00:00, 12.48it/s, loss=0.0035]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 60 avg 0.0041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 61/100: 100%|██████████| 78/78 [00:07<00:00, 10.93it/s, loss=0.0032]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 61 avg 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 62/100: 100%|██████████| 78/78 [00:06<00:00, 12.78it/s, loss=0.0040]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 62 avg 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 63/100: 100%|██████████| 78/78 [00:07<00:00, 11.09it/s, loss=0.0038]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 63 avg 0.0038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 64/100: 100%|██████████| 78/78 [00:06<00:00, 12.51it/s, loss=0.0034]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 64 avg 0.0039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 65/100: 100%|██████████| 78/78 [00:07<00:00, 10.95it/s, loss=0.0041]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 65 avg 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 66/100: 100%|██████████| 78/78 [00:06<00:00, 12.66it/s, loss=0.0041]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 66 avg 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 67/100: 100%|██████████| 78/78 [00:07<00:00, 11.10it/s, loss=0.0034]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 67 avg 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 68/100: 100%|██████████| 78/78 [00:06<00:00, 12.25it/s, loss=0.0036]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 68 avg 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 69/100: 100%|██████████| 78/78 [00:06<00:00, 11.28it/s, loss=0.0041]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 69 avg 0.0036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 70/100: 100%|██████████| 78/78 [00:06<00:00, 11.75it/s, loss=0.0032]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 70 avg 0.0035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 71/100: 100%|██████████| 78/78 [00:06<00:00, 12.03it/s, loss=0.0029]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 71 avg 0.0033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 72/100: 100%|██████████| 78/78 [00:06<00:00, 11.40it/s, loss=0.0027]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 72 avg 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 73/100: 100%|██████████| 78/78 [00:06<00:00, 12.23it/s, loss=0.0025]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 73 avg 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 74/100: 100%|██████████| 78/78 [00:07<00:00, 10.89it/s, loss=0.0028]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 74 avg 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 75/100: 100%|██████████| 78/78 [00:06<00:00, 12.65it/s, loss=0.0029]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 75 avg 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 76/100: 100%|██████████| 78/78 [00:07<00:00, 11.12it/s, loss=0.0033]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 76 avg 0.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 77/100: 100%|██████████| 78/78 [00:06<00:00, 12.72it/s, loss=0.0038]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 77 avg 0.0030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 78/100: 100%|██████████| 78/78 [00:07<00:00, 10.91it/s, loss=0.0027]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 78 avg 0.0030\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 79/100: 100%|██████████| 78/78 [00:06<00:00, 12.62it/s, loss=0.0024]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 79 avg 0.0029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 80/100: 100%|██████████| 78/78 [00:07<00:00, 11.13it/s, loss=0.0037]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 80 avg 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 81/100: 100%|██████████| 78/78 [00:06<00:00, 12.71it/s, loss=0.0043]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 81 avg 0.0028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 82/100: 100%|██████████| 78/78 [00:07<00:00, 11.04it/s, loss=0.0023]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 82 avg 0.0029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 83/100: 100%|██████████| 78/78 [00:06<00:00, 12.48it/s, loss=0.0023]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 83 avg 0.0029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 84/100: 100%|██████████| 78/78 [00:07<00:00, 11.06it/s, loss=0.0024]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 84 avg 0.0027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 85/100: 100%|██████████| 78/78 [00:06<00:00, 12.72it/s, loss=0.0022]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 85 avg 0.0028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 86/100: 100%|██████████| 78/78 [00:07<00:00, 11.10it/s, loss=0.0039]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 86 avg 0.0027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 87/100: 100%|██████████| 78/78 [00:06<00:00, 12.49it/s, loss=0.0023]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 87 avg 0.0027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 88/100: 100%|██████████| 78/78 [00:07<00:00, 10.92it/s, loss=0.0030]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 88 avg 0.0028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 89/100: 100%|██████████| 78/78 [00:06<00:00, 12.65it/s, loss=0.0028]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 89 avg 0.0027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 90/100: 100%|██████████| 78/78 [00:07<00:00, 10.93it/s, loss=0.0024]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 90 avg 0.0028\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 91/100: 100%|██████████| 78/78 [00:06<00:00, 12.52it/s, loss=0.0022]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 91 avg 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 92/100: 100%|██████████| 78/78 [00:07<00:00, 11.03it/s, loss=0.0020]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 92 avg 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 93/100: 100%|██████████| 78/78 [00:06<00:00, 11.91it/s, loss=0.0031]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 93 avg 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 94/100: 100%|██████████| 78/78 [00:06<00:00, 11.81it/s, loss=0.0028]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 94 avg 0.0026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 95/100: 100%|██████████| 78/78 [00:06<00:00, 11.54it/s, loss=0.0031]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 95 avg 0.0026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 96/100: 100%|██████████| 78/78 [00:06<00:00, 12.02it/s, loss=0.0024]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 96 avg 0.0026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 97/100: 100%|██████████| 78/78 [00:07<00:00, 11.05it/s, loss=0.0020]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 97 avg 0.0024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 98/100: 100%|██████████| 78/78 [00:06<00:00, 12.70it/s, loss=0.0021]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 98 avg 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 99/100: 100%|██████████| 78/78 [00:07<00:00, 11.08it/s, loss=0.0023]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 99 avg 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UNet Epoch 100/100: 100%|██████████| 78/78 [00:06<00:00, 12.58it/s, loss=0.0019]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UNet Epoch 100 avg 0.0025\n",
            "Applying EMA and evaluating with CFG...\n",
            "Generating reg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics (may take a while)...\n",
            "reg FID=401.96, IS=1.94\n",
            "Generating unet\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating metrics (may take a while)...\n",
            "unet FID=442.46, IS=1.68\n",
            "FINAL RESULTS:\n",
            "REG    | FID:   401.96 | IS:   1.94\n",
            "UNET   | FID:   442.46 | IS:   1.68\n",
            "Done. Outputs in ./outputs_improved\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Improved SiT+REG + U-Net (Colab/T4-ready) with fixed latent_hw and AMP\n",
        "\n",
        "import os, math, random, shutil\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import CIFAR10\n",
        "import torchvision\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "class CFG:\n",
        "    # Data\n",
        "    dataset_root = \"./data\"\n",
        "    classes = [\"cat\", \"dog\"]\n",
        "    image_size = 64\n",
        "    batch_size = 128\n",
        "    num_workers = 2\n",
        "\n",
        "    # Latent / patch\n",
        "    latent_hw = 16           # FIXED: match VAE output\n",
        "    latent_channels = 4\n",
        "    patch_size = 2\n",
        "    latent_patch_dim = latent_channels * patch_size * patch_size\n",
        "    num_patches = (latent_hw // patch_size) ** 2\n",
        "\n",
        "    # SiT\n",
        "    depth = 12\n",
        "    hidden_dim = 512\n",
        "    num_heads = 8\n",
        "    mlp_ratio = 4.0\n",
        "    dropout = 0.1\n",
        "\n",
        "    # U-Net baseline\n",
        "    unet_base = 128\n",
        "    unet_mult = [1,2,2,4]\n",
        "\n",
        "    # Training\n",
        "    timesteps = 250\n",
        "    lr = 1e-4\n",
        "    weight_decay = 1e-2\n",
        "    betas = (0.9, 0.999)\n",
        "    epochs = 100\n",
        "    grad_clip = 1.0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    seed = 42\n",
        "\n",
        "    # REG params\n",
        "    reg_beta = 0.03\n",
        "    reg_lambda = 0.5\n",
        "    feat_dim = 256\n",
        "    align_layer = 6\n",
        "\n",
        "    # Eval / sampling\n",
        "    sample_n = 500\n",
        "    out_dir = \"./outputs_improved\"\n",
        "    ema_decay = 0.999\n",
        "    cfg_guidance_scale = 4.0\n",
        "\n",
        "cfg = CFG()\n",
        "os.makedirs(cfg.out_dir, exist_ok=True)\n",
        "torch.manual_seed(cfg.seed)\n",
        "random.seed(cfg.seed)\n",
        "np.random.seed(cfg.seed)\n",
        "device = cfg.device\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------- utilities ----------\n",
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return betas.clamp(1e-6, 0.999)\n",
        "\n",
        "# ---------- Scheduler ----------\n",
        "class Scheduler:\n",
        "    def __init__(self, timesteps, device):\n",
        "        self.timesteps = timesteps\n",
        "        self.device = device\n",
        "        betas = cosine_beta_schedule(timesteps).to(device)\n",
        "        self.betas = betas\n",
        "        self.alphas = 1.0 - betas\n",
        "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
        "        self.alpha_cumprod_prev = F.pad(self.alpha_cumprod[:-1], (1,0), value=1.0)\n",
        "        self.sqrt_alpha_cumprod = torch.sqrt(self.alpha_cumprod)\n",
        "        self.sqrt_one_minus_alpha_cumprod = torch.sqrt(1.0 - self.alpha_cumprod)\n",
        "        self.sqrt_recip_alphas = torch.sqrt(1.0 / self.alphas)\n",
        "        self.posterior_variance = betas * (1. - self.alpha_cumprod_prev) / (1. - self.alpha_cumprod)\n",
        "\n",
        "    def sample_t(self, n):\n",
        "        return torch.randint(0, self.timesteps, (n,), device=self.device, dtype=torch.long)\n",
        "\n",
        "    def add_noise(self, x0, t, noise=None):\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "        a = self.sqrt_alpha_cumprod[t].view(-1,1,1,1)\n",
        "        b = self.sqrt_one_minus_alpha_cumprod[t].view(-1,1,1,1)\n",
        "        return a * x0 + b * noise, noise\n",
        "\n",
        "    def v_target(self, x0, eps):\n",
        "        return eps\n",
        "\n",
        "scheduler = Scheduler(cfg.timesteps, device)\n",
        "\n",
        "# ---------- Data ----------\n",
        "def load_cifar_subset(classes=cfg.classes):\n",
        "    class_names = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "    idx_map = {n:i for i,n in enumerate(class_names)}\n",
        "    target_idxs = {idx_map[c] for c in classes}\n",
        "    tfs = T.Compose([\n",
        "        T.Resize((cfg.image_size, cfg.image_size)),\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "    ds = CIFAR10(cfg.dataset_root, train=True, download=True, transform=tfs)\n",
        "    indices = [i for i,(_,y) in enumerate(ds) if y in target_idxs]\n",
        "    sub = Subset(ds, indices)\n",
        "    print(f\"Loaded {len(sub)} images ({classes})\")\n",
        "    return sub\n",
        "\n",
        "dataset = load_cifar_subset()\n",
        "dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers, drop_last=True)\n",
        "\n",
        "# ---------- VAE ----------\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, latent_channels=cfg.latent_channels):\n",
        "        super().__init__()\n",
        "        # Encoder 64 -> 16\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, latent_channels, 3, 1, 1)\n",
        "        )\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.Conv2d(latent_channels, 256, 3, 1, 1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64, 3, 3, 1, 1), nn.Tanh()\n",
        "        )\n",
        "    def encode(self, x): return self.enc(x)\n",
        "    def decode(self, z): return self.dec(z)\n",
        "\n",
        "vae = VAE().to(device)\n",
        "vae_opt = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "\n",
        "print(\"Pretraining VAE (2 epochs)...\")\n",
        "vae.train()\n",
        "for ep in range(2):\n",
        "    pbar = tqdm(dataloader, desc=f\"VAE warmup {ep+1}/2\")\n",
        "    for imgs,_ in pbar:\n",
        "        imgs = imgs.to(device)\n",
        "        z = vae.encode(imgs)\n",
        "        recon = vae.decode(z)\n",
        "        loss = F.mse_loss(recon, imgs)\n",
        "        vae_opt.zero_grad(); loss.backward(); vae_opt.step()\n",
        "        pbar.set_postfix({'loss':f\"{loss.item():.4f}\"})\n",
        "print(\"VAE warmup done\")\n",
        "\n",
        "# ---------- timestep embedding ----------\n",
        "def timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(-math.log(max_period) * torch.arange(half, dtype=torch.float32) / half).to(device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2: emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n",
        "    return emb\n",
        "\n",
        "# ---------- Transformer blocks ----------\n",
        "class MHA(nn.Module):\n",
        "    def __init__(self, dim, heads): super().__init__(); self.heads=heads; self.to_qkv=nn.Linear(dim,dim*3,bias=False); self.scale=(dim//heads)**-0.5; self.to_out=nn.Linear(dim,dim)\n",
        "    def forward(self,x):\n",
        "        B,N,C=x.shape\n",
        "        qkv=self.to_qkv(x).reshape(B,N,3,self.heads,C//self.heads).permute(2,0,3,1,4)\n",
        "        q,k,v=qkv[0],qkv[1],qkv[2]\n",
        "        attn=(q@k.transpose(-2,-1))*self.scale\n",
        "        attn=attn.softmax(dim=-1)\n",
        "        out=(attn@v).transpose(1,2).reshape(B,N,C)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.norm1=nn.LayerNorm(dim)\n",
        "        self.attn=MHA(dim, cfg.num_heads)\n",
        "        self.norm2=nn.LayerNorm(dim)\n",
        "        mlp_dim=int(dim*cfg.mlp_ratio)\n",
        "        self.mlp=nn.Sequential(nn.Linear(dim,mlp_dim), nn.GELU(), nn.Linear(mlp_dim,dim))\n",
        "    def forward(self,x):\n",
        "        x=x+self.attn(self.norm1(x))\n",
        "        x=x+self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "# ---------- REGSiT ----------\n",
        "class REGSiT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden_dim=cfg.hidden_dim\n",
        "        self.patch_embed=nn.Linear(cfg.latent_patch_dim,self.hidden_dim)\n",
        "        self.class_embed=nn.Linear(cfg.feat_dim,self.hidden_dim)\n",
        "        self.pos=nn.Parameter(torch.zeros(1,cfg.num_patches+1,self.hidden_dim))\n",
        "        self.time_mlp=nn.Sequential(nn.Linear(self.hidden_dim,self.hidden_dim*4), nn.SiLU(), nn.Linear(self.hidden_dim*4,self.hidden_dim))\n",
        "        self.blocks=nn.ModuleList([TransformerBlock(self.hidden_dim) for _ in range(cfg.depth)])\n",
        "        self.norm=nn.LayerNorm(self.hidden_dim)\n",
        "        self.patch_out=nn.Linear(self.hidden_dim,cfg.latent_patch_dim)\n",
        "        self.cls_out=nn.Linear(self.hidden_dim,cfg.feat_dim)\n",
        "        self.align_proj=nn.Linear(self.hidden_dim,cfg.feat_dim)\n",
        "        self._init_weights()\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LayerNorm):\n",
        "                nn.init.zeros_(m.bias); nn.init.ones_(m.weight)\n",
        "    def forward(self, z_patched, cls_token, t):\n",
        "        B=z_patched.shape[0]\n",
        "        patch_emb=self.patch_embed(z_patched)\n",
        "        cls_emb=self.class_embed(cls_token).unsqueeze(1)\n",
        "        x=torch.cat([cls_emb,patch_emb],dim=1)+self.pos\n",
        "        t_emb=timestep_embedding(t,self.hidden_dim).to(x.device)\n",
        "        t_emb=self.time_mlp(t_emb).unsqueeze(1)\n",
        "        x=x+t_emb\n",
        "        intermediate=None\n",
        "        for i,blk in enumerate(self.blocks):\n",
        "            x=blk(x)\n",
        "            if i==cfg.align_layer: intermediate=x\n",
        "        x=self.norm(x)\n",
        "        cls_pred=self.cls_out(x[:,0])\n",
        "        patch_pred=self.patch_out(x[:,1:])\n",
        "        h_phi=self.align_proj(intermediate) if intermediate is not None else None\n",
        "        return patch_pred, cls_pred, h_phi\n",
        "\n",
        "reg_sit=REGSiT().to(device)\n",
        "print(\"SiT params:\", sum(p.numel() for p in reg_sit.parameters()))\n",
        "\n",
        "# ---------- rest of code (VisionFoundation, REGModel, UNet, EMA, training, sampling, evaluation) ----------\n",
        "# Keep your original code, but everywhere `latent_hw` is used, it is now 16\n",
        "# Update GradScaler / autocast:\n",
        "# scaler = torch.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "# with torch.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "\n",
        "\n",
        "# ---------- Vision foundation (small frozen conv, produce class token and patch targets) ----------\n",
        "class VisionFoundation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.proj = nn.Linear(128, cfg.feat_dim)\n",
        "        for p in self.parameters(): p.requires_grad = False\n",
        "    def extract(self, x):\n",
        "        B = x.shape[0]\n",
        "        f = self.backbone(x).view(B,-1)\n",
        "        feat = F.normalize(self.proj(f), dim=-1)\n",
        "        cls = feat\n",
        "        patch = feat.unsqueeze(1).repeat(1, cfg.num_patches, 1)\n",
        "        return cls, patch\n",
        "\n",
        "vision = VisionFoundation().to(device)\n",
        "\n",
        "# ---------- REG wrapper computing loss ----------\n",
        "class REGModel(nn.Module):\n",
        "    def __init__(self, sit, vae, vision):\n",
        "        super().__init__()\n",
        "        self.sit = sit\n",
        "        self.vae = vae\n",
        "        self.vision = vision\n",
        "    def forward(self, imgs, t_idx):\n",
        "        B = imgs.shape[0]\n",
        "        z_star = self.vae.encode(imgs)\n",
        "        cls_star, f_star = self.vision.extract(imgs)\n",
        "        eps_z = torch.randn_like(z_star)\n",
        "        eps_cls = torch.randn_like(cls_star)\n",
        "        zt, _ = scheduler.add_noise(z_star, t_idx, noise=eps_z)\n",
        "        # class noise: use same coef forms as scheduler\n",
        "        a = scheduler.sqrt_alpha_cumprod[t_idx].view(B,1)\n",
        "        b = scheduler.sqrt_one_minus_alpha_cumprod[t_idx].view(B,1)\n",
        "        clst = a * cls_star + b * eps_cls\n",
        "        z_patched = rearrange(zt, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                              p=cfg.patch_size, q=cfg.patch_size,\n",
        "                              h=cfg.latent_hw//cfg.patch_size,\n",
        "                              w=cfg.latent_hw//cfg.patch_size)\n",
        "        v_patch, v_cls, h_phi = self.sit(z_patched, clst, t_idx)\n",
        "        v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                        p=cfg.patch_size, q=cfg.patch_size,\n",
        "                        h=cfg.latent_hw//cfg.patch_size,\n",
        "                        w=cfg.latent_hw//cfg.patch_size,\n",
        "                        c=cfg.latent_channels)\n",
        "        v_target_z = scheduler.v_target(z_star, eps_z)\n",
        "        v_target_cls = scheduler.v_target(cls_star, eps_cls)\n",
        "        loss_pred = F.mse_loss(v_z, v_target_z) + cfg.reg_beta * F.mse_loss(v_cls, v_target_cls)\n",
        "        loss_align = torch.tensor(0.0, device=device)\n",
        "        if h_phi is not None:\n",
        "            y_star = torch.cat([cls_star.unsqueeze(1), f_star], dim=1)\n",
        "            loss_align = F.mse_loss(h_phi, y_star.detach())\n",
        "        total_loss = loss_pred + cfg.reg_lambda * loss_align\n",
        "        return total_loss, loss_pred.detach().item(), loss_align.detach().item()\n",
        "\n",
        "reg_model = REGModel(reg_sit, vae, vision).to(device)\n",
        "\n",
        "# ---------- U-Net baseline (wider) ----------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, 1, 1), nn.GroupNorm(8, out_ch), nn.SiLU())\n",
        "    def forward(self,x): return self.net(x)\n",
        "\n",
        "class UNetSmall(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = cfg.unet_base\n",
        "        self.time_dim = 256\n",
        "        self.time_mlp = nn.Sequential(nn.Linear(self.time_dim, self.time_dim*4), nn.SiLU(), nn.Linear(self.time_dim*4, self.time_dim))\n",
        "        chs = [base * m for m in cfg.unet_mult]\n",
        "        self.enc1 = ConvBlock(cfg.latent_channels, chs[0])\n",
        "        self.enc2 = ConvBlock(chs[0], chs[1])\n",
        "        self.enc3 = ConvBlock(chs[1], chs[2])\n",
        "        self.mid = ConvBlock(chs[2], chs[2])\n",
        "        self.dec1 = nn.ConvTranspose2d(chs[2], chs[1], 4, 2, 1)\n",
        "        self.dec2 = nn.ConvTranspose2d(chs[1]*2, chs[0], 4, 2, 1)\n",
        "        self.out = nn.Conv2d(chs[0]*2, cfg.latent_channels, 3, 1, 1)\n",
        "        self.time_projs = nn.ModuleList([nn.Linear(self.time_dim, c) for c in (chs[0], chs[1], chs[2], chs[2], chs[1], chs[0])])\n",
        "    def forward(self, x, t):\n",
        "        B = x.shape[0]\n",
        "        t_emb = timestep_embedding(t, self.time_dim).to(x.device)\n",
        "        t_emb = self.time_mlp(t_emb)\n",
        "        x1 = F.silu(self.enc1(x) + self.time_projs[0](t_emb).view(B, -1, 1, 1))\n",
        "        x2 = F.silu(self.enc2(F.avg_pool2d(x1,2)) + self.time_projs[1](t_emb).view(B, -1, 1, 1))\n",
        "        x3 = F.silu(self.enc3(F.avg_pool2d(x2,2)) + self.time_projs[2](t_emb).view(B, -1, 1, 1))\n",
        "        m = F.silu(self.mid(x3) + self.time_projs[3](t_emb).view(B, -1, 1, 1))\n",
        "        d1 = F.silu(self.dec1(m) + self.time_projs[4](t_emb).view(B, -1, 1, 1))\n",
        "        d1 = torch.cat([d1, x2], dim=1)\n",
        "        d2 = F.silu(self.dec2(d1) + self.time_projs[5](t_emb).view(B, -1, 1, 1))\n",
        "        d2 = torch.cat([d2, x1], dim=1)\n",
        "        out = self.out(d2)\n",
        "        return out\n",
        "\n",
        "unet = UNetSmall().to(device)\n",
        "\n",
        "# ---------- Optimizers, EMA, AMP ----------\n",
        "opt_reg = torch.optim.AdamW(reg_model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "opt_unet = torch.optim.AdamW(unet.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay, betas=cfg.betas)\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model, decay=0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {}\n",
        "        for k, v in model.state_dict().items():\n",
        "            if v.dtype.is_floating_point:  # only float tensors\n",
        "                self.shadow[k] = v.detach().cpu().clone()\n",
        "\n",
        "    def update(self, model):\n",
        "        for k, v in model.state_dict().items():\n",
        "            if v.dtype.is_floating_point:\n",
        "                self.shadow[k].mul_(self.decay)\n",
        "                self.shadow[k].add_(v.detach().cpu(), alpha=1.0 - self.decay)\n",
        "\n",
        "    def apply_to(self, model):\n",
        "        ms = model.state_dict()\n",
        "        for k, v in self.shadow.items():\n",
        "            ms[k].copy_(v.to(ms[k].device))\n",
        "\n",
        "ema_reg = EMA(reg_model, cfg.ema_decay)\n",
        "ema_unet = EMA(unet, cfg.ema_decay)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "\n",
        "# ---------- Training loops ----------\n",
        "reg_loss_hist, unet_loss_hist = [], []\n",
        "\n",
        "def train_reg(epochs):\n",
        "    reg_model.train()\n",
        "    for ep in range(epochs):\n",
        "        total, tot_pred, tot_align = 0.0, 0.0, 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"REG Epoch {ep+1}/{epochs}\")\n",
        "        for imgs,_ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            t_idx = scheduler.sample_t(B)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                loss, lp, la = reg_model(imgs, t_idx)\n",
        "            opt_reg.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_reg)\n",
        "            nn.utils.clip_grad_norm_(reg_model.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_reg); scaler.update()\n",
        "            ema_reg.update(reg_model)\n",
        "            total += loss.item(); tot_pred += lp; tot_align += la\n",
        "            pbar.set_postfix({'loss':f\"{loss.item():.4f}\", 'pred':f\"{lp:.4f}\", 'align':f\"{la:.4f}\"})\n",
        "        avg = total / len(dataloader)\n",
        "        reg_loss_hist.append(avg)\n",
        "        print(f\"REG Epoch {ep+1} avg {avg:.4f}\")\n",
        "\n",
        "def train_unet(epochs):\n",
        "    unet.train()\n",
        "    for ep in range(epochs):\n",
        "        total = 0.0\n",
        "        pbar = tqdm(dataloader, desc=f\"UNet Epoch {ep+1}/{epochs}\")\n",
        "        for imgs,_ in pbar:\n",
        "            imgs = imgs.to(device)\n",
        "            B = imgs.shape[0]\n",
        "            with torch.no_grad(): z_star = vae.encode(imgs)\n",
        "            t_idx = scheduler.sample_t(B)\n",
        "            eps = torch.randn_like(z_star)\n",
        "            zt, _ = scheduler.add_noise(z_star, t_idx, noise=eps)\n",
        "            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "                v_pred = unet(zt, t_idx)\n",
        "                loss = F.mse_loss(v_pred, eps)\n",
        "            opt_unet.zero_grad()\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt_unet)\n",
        "            nn.utils.clip_grad_norm_(unet.parameters(), cfg.grad_clip)\n",
        "            scaler.step(opt_unet); scaler.update()\n",
        "            ema_unet.update(unet)\n",
        "            total += loss.item()\n",
        "            pbar.set_postfix({'loss':f\"{loss.item():.4f}\"})\n",
        "        avg = total / len(dataloader)\n",
        "        unet_loss_hist.append(avg)\n",
        "        print(f\"UNet Epoch {ep+1} avg {avg:.4f}\")\n",
        "\n",
        "# ---------- EM sampler (v-pred) ----------\n",
        "@torch.no_grad()\n",
        "def em_update(z, v_pred, t_idx, t_prev_idx):\n",
        "    # z: (B,C,H,W), v_pred: same\n",
        "    alpha = scheduler.alpha_cumprod[t_idx].view(-1,1,1,1)\n",
        "    alpha_prev = scheduler.alpha_cumprod[t_prev_idx].view(-1,1,1,1)\n",
        "    sigma = scheduler.sqrt_one_minus_alpha_cumprod[t_idx].view(-1,1,1,1)\n",
        "    sigma_prev = scheduler.sqrt_one_minus_alpha_cumprod[t_prev_idx].view(-1,1,1,1)\n",
        "    # x0_hat estimate for v-pred: x0 = (z - sigma * v) / alpha\n",
        "    x0_hat = (z - sigma * v_pred) / (alpha + 1e-12)\n",
        "    if (t_prev_idx==t_idx).all():\n",
        "        return alpha_prev * x0_hat\n",
        "    noise = torch.randn_like(z)\n",
        "    z_prev = alpha_prev * x0_hat + sigma_prev * noise\n",
        "    return z_prev\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_unet(n, batch_size=64):\n",
        "    all_imgs = []\n",
        "    for i in range(0, n, batch_size):\n",
        "        b = min(batch_size, n - i)\n",
        "        z = torch.randn(b, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "        for t in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"UNet Sampling\", leave=False):\n",
        "            t_idx = torch.full((b,), t, device=device, dtype=torch.long)\n",
        "            v = unet(z, t_idx)\n",
        "            t_prev = torch.clamp(t_idx - 1, min=0)\n",
        "            z = em_update(z, v, t_idx, t_prev)\n",
        "        imgs = vae.decode(z)\n",
        "        all_imgs.append(torch.clamp((imgs + 1)/2, 0, 1).cpu())\n",
        "    return torch.cat(all_imgs, dim=0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_reg(n, cfg_guidance=cfg.cfg_guidance_scale, batch_size=64):\n",
        "    all_imgs = []\n",
        "    for i in range(0, n, batch_size):\n",
        "        b = min(batch_size, n - i)\n",
        "        z = torch.randn(b, cfg.latent_channels, cfg.latent_hw, cfg.latent_hw, device=device)\n",
        "        cls = torch.randn(b, cfg.feat_dim, device=device)\n",
        "        for t in tqdm(range(cfg.timesteps-1, -1, -1), desc=\"REG Sampling\", leave=False):\n",
        "            t_idx = torch.full((b,), t, device=device, dtype=torch.long)\n",
        "            z_patched = rearrange(z, 'b c (h p) (w q) -> b (h w) (c p q)',\n",
        "                                  p=cfg.patch_size, q=cfg.patch_size,\n",
        "                                  h=cfg.latent_hw//cfg.patch_size,\n",
        "                                  w=cfg.latent_hw//cfg.patch_size)\n",
        "            v_patch, v_cls, _ = reg_sit(z_patched, cls, t_idx)\n",
        "            v_z = rearrange(v_patch, 'b (h w) (c p q) -> b c (h p) (w q)',\n",
        "                            p=cfg.patch_size, q=cfg.patch_size,\n",
        "                            h=cfg.latent_hw//cfg.patch_size,\n",
        "                            w=cfg.latent_hw//cfg.patch_size,\n",
        "                            c=cfg.latent_channels)\n",
        "            # classifier-free guidance: scale v_cls\n",
        "            v_cls = v_cls * cfg_guidance\n",
        "            t_prev = torch.clamp(t_idx - 1, min=0)\n",
        "            z = em_update(z, v_z, t_idx, t_prev)\n",
        "            # update class token\n",
        "            cls = cls - 0.01 * v_cls\n",
        "        imgs = vae.decode(z)\n",
        "        all_imgs.append(torch.clamp((imgs + 1)/2, 0, 1).cpu())\n",
        "    return torch.cat(all_imgs, dim=0)\n",
        "\n",
        "# ---------- Evaluation ----------\n",
        "def save_grid(imgs, path, nrow=10):\n",
        "    torchvision.utils.save_image(imgs, path, nrow=nrow, padding=2)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(num_samples=cfg.sample_n):\n",
        "    results = {}\n",
        "    real_dir = os.path.join(cfg.out_dir, f\"real_{num_samples}\")\n",
        "    if os.path.exists(real_dir): shutil.rmtree(real_dir)\n",
        "    os.makedirs(real_dir, exist_ok=True)\n",
        "    cnt = 0\n",
        "    for imgs,_ in dataloader:\n",
        "        for im in imgs:\n",
        "            torchvision.utils.save_image((im+1)/2, os.path.join(real_dir, f\"{cnt:05d}.png\"))\n",
        "            cnt += 1\n",
        "            if cnt >= num_samples: break\n",
        "        if cnt >= num_samples: break\n",
        "\n",
        "    for typ in ['reg','unet']:\n",
        "        print(\"Generating\", typ)\n",
        "        if typ == 'reg':\n",
        "            ema_reg.apply_to(reg_model)\n",
        "            gen = sample_reg(num_samples, cfg_guidance=cfg.cfg_guidance_scale, batch_size=64)\n",
        "            save_grid(gen, os.path.join(cfg.out_dir, \"reg_samples.png\"), nrow=10)\n",
        "        else:\n",
        "            ema_unet.apply_to(unet)\n",
        "            gen = sample_unet(num_samples, batch_size=64)\n",
        "            save_grid(gen, os.path.join(cfg.out_dir, \"unet_samples.png\"), nrow=10)\n",
        "        gen_dir = os.path.join(cfg.out_dir, f\"{typ}_gen\")\n",
        "        if os.path.exists(gen_dir): shutil.rmtree(gen_dir)\n",
        "        os.makedirs(gen_dir, exist_ok=True)\n",
        "        for i,im in enumerate(gen):\n",
        "            torchvision.utils.save_image(im, os.path.join(gen_dir, f\"{i:05d}.png\"))\n",
        "        print(\"Calculating metrics (may take a while)...\")\n",
        "        try:\n",
        "            metrics = calculate_metrics(input1=gen_dir, input2=real_dir, cuda=torch.cuda.is_available(), isc=True, fid=True, kid=False, verbose=False)\n",
        "            results[typ] = metrics\n",
        "            print(f\"{typ} FID={metrics['frechet_inception_distance']:.2f}, IS={metrics['inception_score_mean']:.2f}\")\n",
        "        except Exception as e:\n",
        "            print(\"Metric error:\", e)\n",
        "            results[typ] = {'frechet_inception_distance': float('inf'), 'inception_score_mean': 0.0}\n",
        "    return results\n",
        "\n",
        "# ---------- Plot losses ----------\n",
        "def plot_losses():\n",
        "    plt.figure(figsize=(8,5))\n",
        "    if reg_loss_hist: plt.plot(reg_loss_hist, label='SiT+REG')\n",
        "    if unet_loss_hist: plt.plot(unet_loss_hist, label='U-Net')\n",
        "    plt.legend(); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.grid(True)\n",
        "    plt.savefig(os.path.join(cfg.out_dir, \"losses.png\"), dpi=200)\n",
        "\n",
        "# ---------- MAIN ----------\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\"START TRAINING: SiT+REG and U-Net (improved config)\")\n",
        "    print(\"=\"*60)\n",
        "    # Train\n",
        "    train_reg(cfg.epochs)\n",
        "    train_unet(cfg.epochs)\n",
        "    plot_losses()\n",
        "    print(\"Applying EMA and evaluating with CFG...\")\n",
        "    ema_reg.apply_to(reg_model)\n",
        "    ema_unet.apply_to(unet)\n",
        "    results = evaluate(cfg.sample_n)\n",
        "    print(\"FINAL RESULTS:\")\n",
        "    for k,v in results.items():\n",
        "        fid = v.get('frechet_inception_distance', float('inf'))\n",
        "        is_ = v.get('inception_score_mean', 0.0)\n",
        "        print(f\"{k.upper():<6} | FID: {fid:8.2f} | IS: {is_:6.2f}\")\n",
        "    print(\"Done. Outputs in\", cfg.out_dir)\n",
        "\n",
        "# ---------- END ----------\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
